{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d3f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "LSTMAutoencoder(\n",
      "  (encoder_lstm1): LSTM(2, 50, batch_first=True)\n",
      "  (self_attention): SelfAttentionLayer(\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=50, out_features=50, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder_lstm2): LSTM(50, 50, batch_first=True)\n",
      "  (decoder_lstm1): LSTM(50, 50, batch_first=True)\n",
      "  (decoder_lstm2): LSTM(50, 50, batch_first=True)\n",
      "  (decoder_linear): Linear(in_features=50, out_features=2, bias=True)\n",
      ")\n",
      "Using device: cpu\n",
      "Epoch 1/2\n",
      "Batch 0/1000, Loss: 1.0011194944381714\n",
      "Batch 100/1000, Loss: 0.5144996047019958\n",
      "Batch 200/1000, Loss: 0.5126659274101257\n",
      "Batch 300/1000, Loss: 0.417408287525177\n",
      "Batch 400/1000, Loss: 0.5153365135192871\n",
      "Batch 500/1000, Loss: 0.5585072040557861\n",
      "Batch 600/1000, Loss: 0.47219857573509216\n",
      "Batch 700/1000, Loss: 0.0650944858789444\n",
      "Batch 800/1000, Loss: 0.013517450541257858\n",
      "Batch 900/1000, Loss: 0.03913147747516632\n",
      "Epoch 1, Average Loss: 0.3189507292723283\n",
      "\n",
      "Using device: cpu\n",
      "Epoch 2/2\n",
      "Batch 0/1000, Loss: 0.0354028083384037\n",
      "Batch 100/1000, Loss: 0.0282417144626379\n",
      "Batch 200/1000, Loss: 0.02880280651152134\n",
      "Batch 300/1000, Loss: 0.004984473809599876\n",
      "Batch 400/1000, Loss: 0.00516907125711441\n",
      "Batch 500/1000, Loss: 0.002178242662921548\n",
      "Batch 600/1000, Loss: 0.0014268062077462673\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_62404\\257743504.py\u001b[0m in \u001b[0;36m<cell line: 214>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Assuming autoencoder where input = target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m         \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_chunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_62404\\257743504.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'data1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_data1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'data2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_data2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_62404\\257743504.py\u001b[0m in \u001b[0;36mprocess_data1\u001b[1;34m(self, sequence_samples)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;31m# Combining real and imaginary parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag_parts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Shape: (sequence_length, 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_data2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft\n",
    "from scipy.stats import skew, kurtosis \n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import struct\n",
    "from numpy.fft import fft\n",
    "from scipy.stats import skew, kurtosis\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Check if CUDA is available and set the device to GPU if it is, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ComplexNumbersDataset(Dataset):\n",
    "    def __init__(self, filepath, sequence_length, max_samples=None, for_training=True, process_method='data1'):\n",
    "        self.filepath = filepath\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_samples = max_samples\n",
    "        self.for_training = for_training\n",
    "        self.process_method = process_method\n",
    "        self.samples = self.load_samples()\n",
    "        self.samples_per_sequence = self.sequence_length\n",
    "        #self.samples_per_sequence = self.sequence_length if for_training else 1\n",
    "\n",
    "    def load_samples(self):\n",
    "        samples = []\n",
    "        with open(self.filepath, 'rb') as binary_file:\n",
    "            while True:\n",
    "                if self.max_samples and len(samples) >= self.max_samples:\n",
    "                    break\n",
    "                binary_data = binary_file.read(8)\n",
    "                if not binary_data:\n",
    "                    break\n",
    "                decoded_data = struct.unpack('ff', binary_data)\n",
    "                if decoded_data[0] == 0 and decoded_data[1] == 0:\n",
    "                    continue\n",
    "                samples.append(f\"{decoded_data[0]}+{decoded_data[1]}j\")\n",
    "        return samples\n",
    "\n",
    "    def process_data1(self, sequence_samples):\n",
    "        #print('sequence_samples:', sequence_samples)\n",
    "        #print('len(sequence_samples):', len(sequence_samples))\n",
    "        real_parts = []\n",
    "        imag_parts = []\n",
    "        for sample in sequence_samples:\n",
    "            # Remove potential unwanted characters (spaces, etc.)\n",
    "            sample = sample.replace(\" \", \"\").replace(\"+-\", \"-\")\n",
    "            try:\n",
    "                c = complex(sample)\n",
    "                real_parts.append(c.real)\n",
    "                imag_parts.append(c.imag)\n",
    "            except ValueError:\n",
    "                print(f\"Failed to convert: {sample}\")  # This will show which string failed\n",
    "                raise\n",
    "        real_parts = np.array(real_parts)\n",
    "        imag_parts = np.array(imag_parts)\n",
    "        # Normalize\n",
    "        real_parts = (real_parts - np.mean(real_parts)) / np.std(real_parts)\n",
    "        imag_parts = (imag_parts - np.mean(imag_parts)) / np.std(imag_parts)\n",
    "\n",
    "        # Combining real and imaginary parts\n",
    "        X = np.stack((real_parts, imag_parts), axis=1)  # Shape: (sequence_length, 2)\n",
    "        return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def process_data2(self, sequence_samples):\n",
    "        samples_array = np.array([complex(sample) for sample in sequence_samples], dtype=np.complex64)\n",
    "        samples_fft = fft(samples_array)\n",
    "        real_parts = np.real(samples_fft)\n",
    "        imag_parts = np.imag(samples_fft)\n",
    "        \n",
    "        # Normalization\n",
    "        epsilon = 1e-10\n",
    "        real_parts_normalized = (real_parts - np.mean(real_parts)) / (np.std(real_parts) + epsilon)\n",
    "        imag_parts_normalized = (imag_parts - np.mean(imag_parts)) / (np.std(imag_parts) + epsilon)\n",
    "        \n",
    "        # Feature extraction\n",
    "        features = np.column_stack((\n",
    "            np.mean(real_parts_normalized), np.std(real_parts_normalized), skew(real_parts_normalized),\n",
    "            kurtosis(real_parts_normalized), np.mean(imag_parts_normalized), np.std(imag_parts_normalized),\n",
    "            skew(imag_parts_normalized), kurtosis(imag_parts_normalized)\n",
    "        ))\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32).reshape(self.samples_per_sequence, -1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples) // self.samples_per_sequence\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.samples_per_sequence\n",
    "        end_idx = start_idx + self.samples_per_sequence\n",
    "        sequence_samples = self.samples[start_idx:end_idx]\n",
    "        \n",
    "        if self.process_method == 'data1':\n",
    "            X = self.process_data1(sequence_samples)\n",
    "        elif self.process_method == 'data2':\n",
    "            X = self.process_data2(sequence_samples)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid process method specified.\")\n",
    "        if self.for_training:\n",
    "            return X, X\n",
    "        else:\n",
    "            return X\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Expecting inputs of shape (sequence_length, batch_size, embed_size)\n",
    "        attn_output, _ = self.multihead_attention(inputs, inputs, inputs)\n",
    "        # Output shape is the same as input shape (sequence_length, batch_size, embed_size)\n",
    "        return attn_output\n",
    "\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, sequence_length, input_dim, lstm_dim=50, num_heads=2):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm_dim = lstm_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_lstm1 = nn.LSTM(input_dim, lstm_dim, batch_first=True)\n",
    "        self.self_attention = SelfAttentionLayer(embed_size=lstm_dim, num_heads=num_heads)\n",
    "        self.encoder_lstm2 = nn.LSTM(lstm_dim, lstm_dim, batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_lstm1 = nn.LSTM(lstm_dim, lstm_dim, batch_first=True)\n",
    "        self.decoder_lstm2 = nn.LSTM(lstm_dim, lstm_dim, batch_first=True)\n",
    "        self.decoder_linear = nn.Linear(lstm_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x, (hidden_state, cell_state) = self.encoder_lstm1(x)\n",
    "        # Permute x to match MultiheadAttention input shape expectations\n",
    "        x = x.permute(1, 0, 2)  # Shape: (sequence_length, batch_size, embed_size)\n",
    "        x = self.self_attention(x)\n",
    "        # Permute x back to match LSTM input shape expectations\n",
    "        x = x.permute(1, 0, 2)  # Shape: (batch_size, sequence_length, embed_size)\n",
    "        x, (hidden_state, cell_state) = self.encoder_lstm2(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x, (hidden_state, cell_state) = self.decoder_lstm1(x)\n",
    "        x, (hidden_state, cell_state) = self.decoder_lstm2(x)\n",
    "        # Apply Linear layer to each time step\n",
    "        x = self.decoder_linear(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example of initializing the model\n",
    "sequence_length = 10\n",
    "\n",
    "feature_dim = 2\n",
    "lstm_dim = 50\n",
    "num_heads = 2\n",
    "epsilon_std = 0.1\n",
    "model = LSTMAutoencoder(sequence_length=10, input_dim=feature_dim).to(device)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Model Training\n",
    "batch_size = 100\n",
    "max_train_samples = 1000000\n",
    "train_steps = max_train_samples // (batch_size * sequence_length)\n",
    "max_samples = 1000000  # Maximum samples to read (or None to read all)\n",
    "max_test_samples = 1000000\n",
    "\n",
    "# pure_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/pure_data/pure_iq_samples_*.csv'\n",
    "# mixed_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/mixed_data/mixed_iq_samples_*.csv'\n",
    "# pure_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_pure'\n",
    "# mixed_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_MIX'\n",
    "# pure_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_no_jamming_0924.dat'\n",
    "# mixed_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_with_periodic_jamming_0928_02.dat'\n",
    "\n",
    "\n",
    "pure_file_new = r\"C:\\Users\\Mohammadreza\\Desktop\\My Class\\Proj-DC\\My Works\\My Papers\\intrusion\\data generator\\New Data-Collection\\rx_IQ_pure\"\n",
    "mixed_file_new = r\"C:\\Users\\Mohammadreza\\Desktop\\My Class\\Proj-DC\\My Works\\My Papers\\intrusion\\data generator\\New Data-Collection\\rx_IQ_MIX\"\n",
    "\n",
    "\n",
    "# Creating dataset instances for training and validation/testing\n",
    "train_gen_instance  = ComplexNumbersDataset(filepath=pure_file_new, \n",
    "                                            sequence_length=sequence_length, \n",
    "                                            max_samples=max_train_samples, for_training=True, \n",
    "                                            process_method='data1')\n",
    "\n",
    "combined_gen_instance = ComplexNumbersDataset(filepath=mixed_file_new, \n",
    "                                              sequence_length=sequence_length, \n",
    "                                              max_samples=max_samples, for_training=False, \n",
    "                                              process_method='data1')\n",
    "\n",
    "# Creating DataLoader instances for batching\n",
    "train_loader = DataLoader(train_gen_instance, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "combined_loader = DataLoader(combined_gen_instance, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "\n",
    "# Custom training loop in PyTorch\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    total_loss = 0\n",
    "    for batch_idx, (X_chunk, _) in enumerate(train_loader):  # Assuming autoencoder where input = target\n",
    "        X_chunk = X_chunk.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_x = model(X_chunk)\n",
    "        #print('X_chunk.shape:', X_chunk.shape)\n",
    "        #print('reconstructed_x.shape:', reconstructed_x.shape)\n",
    "        loss = loss_function(reconstructed_x, X_chunk)  # Use X_chunk as both input and target\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss}\\n\")\n",
    "\n",
    "num_predictions = 200  # or any other large number\n",
    "print(f\"Number of predictions to be performed: {num_predictions}\")\n",
    "reconstruction_errors = []\n",
    "all_X_chunk_test = []\n",
    "all_X_chunk_pred = []\n",
    "all_intrusion_flags = []\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, X_chunk_test in enumerate(combined_loader):\n",
    "        X_chunk_test = X_chunk_test.to(device)\n",
    "        X_chunk_pred = model(X_chunk_test)\n",
    "        \n",
    "        chunk_errors = torch.mean((X_chunk_test - X_chunk_pred) ** 2, dim=1)\n",
    "        reconstruction_errors.extend(chunk_errors.cpu().numpy())\n",
    "        all_X_chunk_test.append(X_chunk_test)\n",
    "        all_X_chunk_pred.append(X_chunk_pred)\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Evaluating Batch {batch_idx}/{len(combined_loader)}\")\n",
    "\n",
    "reconstruction_error = np.array(reconstruction_errors)\n",
    "print(f\"Completed predictions. Total number of batches: {len(combined_loader)}\")\n",
    "\n",
    "#reconstruction_error = np.array(reconstruction_errors)\n",
    "print('reconstruction_error.shape:', reconstruction_error.shape)\n",
    "print('Number of NaNs in reconstruction_error:', np.isnan(reconstruction_error).sum())\n",
    "max_error_per_sequence = reconstruction_error.max(axis=1) # Max error for each sequence\n",
    "#print('max_error_per_sequence:', max_error_per_sequence)\n",
    "\n",
    "print('max_error_per_sequence.shape:', max_error_per_sequence.shape)\n",
    "\n",
    "threshold1 = np.percentile(max_error_per_sequence, 98)\n",
    "print('threshold1:', threshold1)\n",
    "threshold2 = np.percentile(reconstruction_error, 95)\n",
    "print('threshold percentile:', threshold2)\n",
    "\n",
    "is_intrusion_detected = max_error_per_sequence > threshold1  # Boolean array for sequences\n",
    "print('len(is_intrusion_detected):', len(is_intrusion_detected))\n",
    "print('is_intrusion_detected.shape:', is_intrusion_detected.shape)\n",
    "\n",
    "#is_intrusion_detected2 = error_per_sequence > threshold1\n",
    "\n",
    "num_total_sequences = len(max_error_per_sequence)\n",
    "num_total_sequences2 = num_predictions * batch_size - num_predictions\n",
    "print('num_total_sequences:', num_total_sequences)\n",
    "print('num_total_sequences2:', num_total_sequences2)\n",
    "\n",
    "#---------------------------------------finish 111-----------------------------------\n",
    "flat_error_per_sequence = max_error_per_sequence.flatten()\n",
    "#flat_error_per_sequence2 = error_per_sequence.flatten()\n",
    "# Determine if intrusion detected for each sequence\n",
    "for error in flat_error_per_sequence:\n",
    "    all_intrusion_flags.append(error > threshold1)\n",
    "all_X_chunk_test = [x.cpu() for x in all_X_chunk_test]\n",
    "all_X_chunk_pred = [x.cpu() for x in all_X_chunk_pred]\n",
    "\n",
    "all_X_chunk_test = np.concatenate(all_X_chunk_test, axis=0)\n",
    "all_X_chunk_pred = np.concatenate(all_X_chunk_pred, axis=0)\n",
    "\n",
    "#save_path = 'C:\\\\Users\\\\Mohammadreza\\\\Desktop\\\\My Class\\\\Proj-DC\\\\My Works\\\\My Papers\\\\intrusion\\\\data generator\\\\intrusion_detected'\n",
    "#plot_with_intrusions8(all_X_chunk_test, all_X_chunk_pred, all_intrusion_flags, sequence_length, save_path)\n",
    "\n",
    "jamming_detected = reconstruction_error > threshold1\n",
    "#train_gen_instance.close()\n",
    "#combined_gen_instance.close()\n",
    "#Table\n",
    "flattened_jamming_detected = jamming_detected.flatten()\n",
    "real_part_detected = jamming_detected[:, 0]\n",
    "imag_part_detected = jamming_detected[:, 1]\n",
    "\n",
    "real_true_count = np.sum(real_part_detected)\n",
    "real_false_count = len(real_part_detected) - real_true_count\n",
    "\n",
    "imag_true_count = np.sum(imag_part_detected)\n",
    "imag_false_count = len(imag_part_detected) - imag_true_count\n",
    "# Overall\n",
    "overall_true_count = np.sum(flattened_jamming_detected)\n",
    "overall_false_count = len(flattened_jamming_detected) - overall_true_count\n",
    "# Table-DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Part': ['Real', 'Imaginary', 'Overall'],\n",
    "    'True Count': [real_true_count, imag_true_count, overall_true_count],\n",
    "    'False Count': [real_false_count, imag_false_count, overall_false_count]\n",
    "})\n",
    "print(df)\n",
    "num_jamming_detected = np.sum(jamming_detected)\n",
    "print(f\"Number of jamming sequences detected: {num_jamming_detected} out of {len(flattened_jamming_detected)} sequences\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "# Ensure n sequences are available\n",
    "n = min(n, len(X_chunk_test) - sequence_index)\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays\n",
    "original_sample_np = X_chunk_test[sequence_index:sequence_index + n].detach().cpu().numpy()\n",
    "reconstructed_sample_np = X_chunk_pred[sequence_index:sequence_index + n].detach().cpu().numpy()\n",
    "\n",
    "# Since your data is 3-dimensional (batch, sequence, features), you'll want to concatenate along the sequence axis (axis=1)\n",
    "original_sample_concat = np.concatenate(original_sample_np, axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(reconstructed_sample_np, axis=0)\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')  # Assuming first feature is the real part\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')  # Assuming first feature is the real part\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of sequences to plot together\n",
    "n = 4  # Change this to desired number of sequences\n",
    "\n",
    "# Ensure that we have enough samples for the desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays and concatenate selected sequences\n",
    "original_sample_concat = np.concatenate(X_chunk_test[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "\n",
    "# Plot concatenated sequences for n = 4\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample_concat[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for n = 2\n",
    "n = 2  # Change this to a different desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample_concat = np.concatenate(X_chunk_test[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "\n",
    "# Plot concatenated sequences for n = 2\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample_concat[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4348bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error_flat, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a86f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error_flat, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4005b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_chunk_test and X_chunk_pred are tensors on the GPU\n",
    "# First, move the selected samples to CPU and convert to NumPy for plotting\n",
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index].cpu().numpy()\n",
    "reconstructed_sample = X_chunk_pred[sample_index].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch tensors to NumPy arrays before calculating means\n",
    "avg_real = np.mean(X_chunk_test.cpu().numpy(), axis=1)[:, 0]\n",
    "avg_imag = np.mean(X_chunk_test.cpu().numpy(), axis=1)[:, 1]\n",
    "\n",
    "# Assuming reconstruction_errors is a NumPy array or a list of errors\n",
    "# If reconstruction_errors is a tensor, ensure to convert it with .cpu().numpy() as well\n",
    "last_errors = np.mean(reconstruction_errors[-len(X_chunk_test):], axis=1)\n",
    "\n",
    "print(\"Shape of avg_real:\", avg_real.shape)\n",
    "print(\"Shape of avg_imag:\", avg_imag.shape)\n",
    "print(\"Shape of last_errors:\", last_errors.shape)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_real, last_errors, label='Real Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Real Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_imag, last_errors, label='Imaginary Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Imaginary Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming `z_mean` and `z_log_var` are obtained from your model's encoder\n",
    "\n",
    "# Function to sample using standard VAE sampling method\n",
    "def sample_vae(z_mean, z_log_var):\n",
    "    std = torch.exp(0.5 * z_log_var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return z_mean + eps * std\n",
    "\n",
    "# Function to sample using your MEC-based method (_sampling3)\n",
    "def sample_mec(z_mean, device):\n",
    "    # Example of processing z_mean with MEC. You will replace this with your actual _sampling3 function\n",
    "    # This is a placeholder to illustrate the workflow\n",
    "    z_mean_transformed = z_mean  # Placeholder for actual transformation\n",
    "    eps = torch.randn_like(z_mean_transformed) * 0.1  # Example std deviation\n",
    "    return z_mean_transformed + eps\n",
    "\n",
    "# Assuming device is defined (e.g., \"cuda\" or \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "z_mean = z_mean.to(device)\n",
    "z_log_var = z_log_var.to(device)\n",
    "\n",
    "# Sampling\n",
    "z_sampled_vae = sample_vae(z_mean, z_log_var)\n",
    "z_sampled_mec = sample_mec(z_mean, device)\n",
    "\n",
    "# Plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_distribution(tensor, label, color):\n",
    "    # Ensure tensor is on CPU and flatten it for histogramming\n",
    "    tensor = tensor.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    # Histogram\n",
    "    plt.hist(tensor, bins=30, density=True, alpha=0.6, label=label, color=color)\n",
    "    \n",
    "    # KDE plot\n",
    "    kde = gaussian_kde(tensor)\n",
    "    kde_x = np.linspace(tensor.min(), tensor.max(), 500)\n",
    "    kde_y = kde.evaluate(kde_x)\n",
    "    plt.plot(kde_x, kde_y, color=color, alpha=0.7)\n",
    "\n",
    "# Visualization setup\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Call the plotting function for z_mean and sampled distributions\n",
    "plot_distribution(z_mean, \"z_mean distribution\", \"blue\")\n",
    "plot_distribution(z_sampled_vae, \"Sampled VAE z distribution\", \"red\")\n",
    "plot_distribution(z_sampled_mec, \"Sampled MEC z distribution\", \"green\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Variable Distributions Before and After Sampling')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plot(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, label=label)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean is of shape (n_samples, n_latent_dims)\n",
    "# And you have z_sampled_vae and z_sampled_mec with the same shape\n",
    "# We'll take the first two dimensions for plotting\n",
    "z_mean_2d = z_mean[:, :2].detach().cpu().numpy()  # Take first two dimensions for 2D scatter plot\n",
    "z_sampled_vae_2d = z_sampled_vae[:, :2].detach().cpu().numpy()\n",
    "z_sampled_mec_2d = z_sampled_mec[:, :2].detach().cpu().numpy()\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_plot(latent_variables, labels, 'Latent Space 2D Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e5031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_plot(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Define distinct colors for visibility: red for z_mean, orange for Sampled VAE, and limegreen for Sampled MEC\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "    \n",
    "    # Plot each set of points with the new colors\n",
    "    for i, (label, color) in enumerate(zip(labels, colors)):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, label=label, color=color)\n",
    "\n",
    "    # Print the range of z_mean data points\n",
    "    print(f\"z_mean Latent Dimension 1 range: {latent_variables[:, 0, 0].min()} to {latent_variables[:, 0, 0].max()}\")\n",
    "    print(f\"z_mean Latent Dimension 2 range: {latent_variables[:, 0, 1].min()} to {latent_variables[:, 0, 1].max()}\")\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set the x and y axes limits\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_plot(latent_variables, labels, 'Latent Space 2D Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cae26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_subplots(latent_variables, labels, title):\n",
    "    # Set up a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 8), sharey=True)\n",
    "    \n",
    "    # Define distinct colors for visibility\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points in its own subplot\n",
    "    for i, (ax, label, color) in enumerate(zip(axs, labels, colors)):\n",
    "        ax.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, color=color)\n",
    "        ax.set_title(f\"{label} Distribution\")\n",
    "        ax.grid(True)\n",
    "        # Set the same x and y limits for all subplots based on overall data\n",
    "        all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "        x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "        y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "        ax.set_xlim(x_min - 1, x_max + 1)\n",
    "        ax.set_ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.04, 'Latent Dimension 1', ha='center')\n",
    "    fig.text(0.04, 0.5, 'Latent Dimension 2', va='center', rotation='vertical')\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_subplots(latent_variables, labels, 'Separate Latent Space 2D Distributions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe900cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_dual_plots(latent_variables, labels, title):\n",
    "    # Set up a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "\n",
    "    # Define distinct colors for visibility: red for z_mean, green for Sampled MEC, and orange for Sampled VAE\n",
    "    colors = ['red', 'limegreen', 'orange']\n",
    "\n",
    "    # Scatter plot for z_mean and Sampled MEC\n",
    "    axs[0].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "    axs[0].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[2], s=90, label=labels[2])\n",
    "    axs[0].set_title(f\"{labels[0]} and {labels[2]} Distribution\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Scatter plot for z_mean and Sampled VAE\n",
    "    axs[1].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "    axs[1].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[1], s=90, label=labels[1])\n",
    "    axs[1].set_title(f\"{labels[0]} and {labels[1]} Distribution\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    # Scatter plot for z_mean and Sampled VAE\n",
    "#     axs[1].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "#     axs[1].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[1], s=90, label=labels[1])\n",
    "#     axs[1].set_title(f\"{labels[1]} and {labels[2]} Distribution\")\n",
    "#     axs[1].legend()\n",
    "#     axs[1].grid(True)\n",
    "\n",
    "    # Set the same x and y limits for all subplots based on overall data\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    for ax in axs:\n",
    "        ax.set_xlim(x_min - 1, x_max + 1)\n",
    "        ax.set_ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.04, 'Latent Dimension 1', ha='center')\n",
    "    fig.text(0.04, 0.5, 'Latent Dimension 2', va='center', rotation='vertical')\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    plt.show()\n",
    "def scatter_all_plots(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Define distinct colors for visibility: red for z_mean, orange for Sampled VAE, and limegreen for Sampled MEC\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points with the new colors\n",
    "    for i, (label, color) in enumerate(zip(labels, colors)):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, color=color, s=100, label=label)\n",
    "\n",
    "    # Set the x and y axes limits based on overall data\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "def scatter_vae_mec(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Define colors for visibility: orange for Sampled VAE and limegreen for Sampled MEC\n",
    "    colors = ['orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points with the colors\n",
    "    plt.scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[0], s=80, label=labels[1])\n",
    "    plt.scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[1], s=80, label=labels[2])\n",
    "\n",
    "    # Set the x and y axes limits based on the plotted data\n",
    "    vae_mec_latent_vars = np.concatenate((latent_variables[:, 1], latent_variables[:, 2]), axis=0)\n",
    "    x_min, x_max = vae_mec_latent_vars[:, 0].min(), vae_mec_latent_vars[:, 0].max()\n",
    "    y_min, y_max = vae_mec_latent_vars[:, 1].min(), vae_mec_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_dual_plots(latent_variables, labels, 'Latent Space 2D Distributions')\n",
    "scatter_all_plots(latent_variables, labels, 'Combined Latent Space 2D Distribution')\n",
    "scatter_vae_mec(latent_variables, labels, 'Sampled VAE vs Sampled MEC Latent Space 2D Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b690ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# We'll assume z_mean, z_sampled_vae, and z_sampled_mec are tensors with at least 2 dimensions.\n",
    "# Convert PyTorch tensors to numpy arrays and then to a pandas DataFrame for Seaborn.\n",
    "z_mean_np = z_mean[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "z_sampled_vae_np = z_sampled_vae[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "z_sampled_mec_np = z_sampled_mec[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Use Seaborn to plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='Latent Dimension 1', y='Latent Dimension 2', hue='Type', alpha=0.7)\n",
    "plt.title('Latent Space 2D Distribution with Seaborn')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83045b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_size=150, \n",
    "                          context='talk', style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn'):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    scatter = sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                              hue=hue, s=marker_size, alpha=0.8)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "z_mean_np = z_mean[:, :2].detach().cpu().numpy()\n",
    "z_sampled_vae_np = z_sampled_vae[:, :2].detach().cpu().numpy()\n",
    "z_sampled_mec_np = z_sampled_mec[:, :2].detach().cpu().numpy()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np),\n",
    "    'Size': [120] * len(z_mean_np) + [100] * len(z_sampled_vae_np) + [200] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "# Call the function with the custom color palette\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Define default marker size if not provided\n",
    "    default_marker_size = 150\n",
    "\n",
    "    # Plot each category with its specified or default marker size\n",
    "    if marker_sizes_dict:\n",
    "        for category, msize in marker_sizes_dict.items():\n",
    "            subset = dataframe[dataframe[hue] == category]\n",
    "            sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                            hue=hue, s=msize, alpha=0.8, legend=False)\n",
    "    else:\n",
    "        sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        hue=hue, s=default_marker_size, alpha=0.8)\n",
    "\n",
    "    # Get current axis limits\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "\n",
    "    # Extend the x and y axes\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "# Define custom marker sizes for each category\n",
    "custom_marker_sizes = {\n",
    "    'z_mean': 200,        # Bigger marker size for z_mean\n",
    "    'Sampled VAE': 150,   # Bigger marker size for Sampled VAE\n",
    "    'Sampled MEC': 100    # Bigger marker size for Sampled MEC\n",
    "}\n",
    "\n",
    "# Call the function with the custom color palette and custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_colors, marker_sizes_dict=custom_marker_sizes, extend_axis_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(14, 8), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette=None,\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Define default marker size if not provided\n",
    "    default_marker_size = 150\n",
    "\n",
    "    # Check if a custom palette is provided, otherwise use Seaborn's default\n",
    "    if palette is None:\n",
    "        palette = sns.color_palette(\"husl\", len(dataframe[hue].unique()))\n",
    "\n",
    "    # Plot each category with its specified or default marker size\n",
    "    if marker_sizes_dict:\n",
    "        for category, msize in marker_sizes_dict.items():\n",
    "            subset = dataframe[dataframe[hue] == category]\n",
    "            sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                            hue=hue, s=msize, alpha=0.8, palette=palette, legend='full')\n",
    "    else:\n",
    "        sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        hue=hue, s=default_marker_size, alpha=0.8, palette=palette, legend='full')\n",
    "\n",
    "    # Get current axis limits\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "\n",
    "    # Extend the x and y axes\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Place the legend outside the plot\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Define custom marker sizes for each category\n",
    "custom_marker_sizes = {\n",
    "    'z_mean': 300,        # Bigger marker size for z_mean\n",
    "    'Sampled VAE': 200,   # Bigger marker size for Sampled VAE\n",
    "    'Sampled MEC': 200    # Bigger marker size for Sampled MEC\n",
    "}\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_palette = {\n",
    "    'z_mean': \"#e74c3c\",  # Red color for z_mean\n",
    "    'Sampled VAE': \"#3498db\",  # Blue color for Sampled VAE\n",
    "    'Sampled MEC': \"#2ecc71\"   # Green color for Sampled MEC\n",
    "}\n",
    "\n",
    "# Call the function with the custom color palette and custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_palette, marker_sizes_dict=custom_marker_sizes, extend_axis_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), \n",
    "                          marker_sizes=None, context='talk', \n",
    "                          style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn'):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # If marker_sizes is not specified, default to 100 for all\n",
    "    if not marker_sizes:\n",
    "        marker_sizes = {category: 100 for category in dataframe[hue].unique()}\n",
    "    \n",
    "    # Plot each category with its own marker size\n",
    "    unique_categories = dataframe[hue].unique()\n",
    "    for category in unique_categories:\n",
    "        subset = dataframe[dataframe[hue] == category]\n",
    "        sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        label=category, s=marker_sizes[category], alpha=0.8)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12')\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Define marker sizes for each category\n",
    "marker_sizes = {\n",
    "    'z_mean': 150,\n",
    "    'Sampled VAE': 100,\n",
    "    'Sampled MEC': 150\n",
    "}\n",
    "\n",
    "# Call the function with custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', marker_sizes=marker_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5f23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and converted to numpy arrays\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np),\n",
    "    'Size': [120] * len(z_mean_np) + [100] * len(z_sampled_vae_np) + [120] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"colorblind\")\n",
    "\n",
    "# Create a FacetGrid object to control the size of each point individually\n",
    "g = sns.FacetGrid(df, hue=\"Type\", height=6, aspect=1.5, legend_out=True)\n",
    "\n",
    "# Use the 'Size' column to set the size of each point\n",
    "g = g.map(plt.scatter, \"Latent Dimension 1\", \"Latent Dimension 2\", \"Size\", edgecolor=\"w\", alpha=0.7)\n",
    "\n",
    "# Adjust the axis limits to add some padding around the points\n",
    "padding = 0.2\n",
    "x_min, x_max = df['Latent Dimension 1'].min(), df['Latent Dimension 1'].max()\n",
    "y_min, y_max = df['Latent Dimension 2'].min(), df['Latent Dimension 2'].max()\n",
    "plt.xlim(x_min - (x_max - x_min) * padding, x_max + (x_max - x_min) * padding)\n",
    "plt.ylim(y_min - (y_max - y_min) * padding, y_max + (y_max - y_min) * padding)\n",
    "\n",
    "# Add the legend and titles\n",
    "g.add_legend(title=\"Type\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Latent Space 2D Distribution with Seaborn')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.random.normal(size=z_mean.shape)\n",
    "z_sampled = z_mean + np.exp(0.5 * z_log_var) * eps\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot z_mean distribution\n",
    "sns.histplot(z_mean.detach().numpy().flatten(), color=\"blue\", kde=True, stat=\"density\", label=\"z_mean distribution\")\n",
    "\n",
    "# Plot sampled z distribution\n",
    "sns.histplot(z_sampled.detach().numpy().flatten(), color=\"red\", kde=True, stat=\"density\", alpha=0.6, label=\"Sampled z distribution\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Variable Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e87830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4235d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction error\n",
    "reconstruction_error_real = reconstruction_error[:, 0]\n",
    "reconstruction_error_imag = reconstruction_error[:, 1]\n",
    "\n",
    "# Plot for Real Part\n",
    "plt.figure(figsize=(14, 6))\n",
    "mellow_green = '#89C997' \n",
    "plt.plot(reconstruction_error_real, label='Reconstruction Error', color=mellow_green)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Intrusion Detected by Reconstruction Error',fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sequence Number (10)', fontsize=16, fontweight='bold')\n",
    "#plt.xlabel('Sequence Number(*1000)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Reconstruction Error', fontsize=16, fontweight='bold')\n",
    "for label in (plt.gca().get_xticklabels() + plt.gca().get_yticklabels()):\n",
    "    label.set_fontsize(12)\n",
    "    label.set_fontweight('bold')\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "# plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "# plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "# plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "# plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "# plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "# plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad266e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_real_parts = reconstruction_error[:, 0]\n",
    "reconstruction_error_real_std = reconstruction_error[:, 1]\n",
    "reconstruction_error_real_skew = reconstruction_error[:, 2]\n",
    "reconstruction_error_real_kurtosis = reconstruction_error[:, 3]\n",
    "reconstruction_error_imag_parts = reconstruction_error[:, 4]\n",
    "reconstruction_error_imag_std = reconstruction_error[:, 5]\n",
    "reconstruction_error_imag_skew = reconstruction_error[:, 6]\n",
    "reconstruction_error_imag_kurtosis = reconstruction_error[:, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "# plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "# plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "# plt.plot(original_sample[:, 4], 'g-', label='Original Imaginary Part')\n",
    "# plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'orange', label='Original Real STD')\n",
    "plt.plot(reconstructed_sample[:, 1], 'orange', label='Reconstructed Real STD', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 4], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.plot(original_sample[:, 5], 'pink', label='Original Imaginary STD')\n",
    "plt.plot(reconstructed_sample[:, 5], 'pink', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 2], 'b-', label='Original Real Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'r--', label='Reconstructed Real Part Skew')\n",
    "plt.plot(original_sample[:, 6], 'g-', label='Original Imaginary Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'y--', label='Reconstructed Imaginary Part Skew')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 3], 'b-', label='Original Real Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'r--', label='Reconstructed Real Part Kurtosis')\n",
    "plt.plot(original_sample[:, 7], 'g-', label='Original Imaginary Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'y--', label='Reconstructed Imaginary Part Kurtosis')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671af7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
