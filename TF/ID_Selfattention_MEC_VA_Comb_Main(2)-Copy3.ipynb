{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d3f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 14:00:05.568226: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-17 14:00:05.569240: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-17 14:00:05.593769: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-17 14:00:05.594277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 14:00:05.988844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (5.2.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 14:00:06.963052: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-04-17 14:00:06.963069: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: mreza\n",
      "2024-04-17 14:00:06.963072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: mreza\n",
      "2024-04-17 14:00:06.963114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.171.4\n",
      "2024-04-17 14:00:06.963124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.161.7\n",
      "2024-04-17 14:00:06.963126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:312] kernel version 535.161.7 does not match DSO version 535.171.4 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape in apply mec: (None, 50)\n",
      "WARNING:tensorflow:From /home/mreza/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "data.shape in apply mec: (None, 50)\n",
      "File extension detected: \n",
      "File extension detected: \n",
      "Epoch 1/4\n",
      "File extension detected: \n",
      "data.shape in apply mec: (990, 50)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['z_log_var/kernel:0', 'z_log_var/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['z_log_var/kernel:0', 'z_log_var/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "data.shape in apply mec: (990, 50)\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['z_log_var/kernel:0', 'z_log_var/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['z_log_var/kernel:0', 'z_log_var/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "Step 1/3000, Loss: 0.9990031123161316\n",
      "Step 101/3000, Loss: 0.9877882599830627\n",
      "Step 201/3000, Loss: 0.9825665950775146\n",
      "Step 301/3000, Loss: 0.9637296795845032\n",
      "Step 401/3000, Loss: 0.9819257259368896\n",
      "Step 501/3000, Loss: 0.9418531060218811\n",
      "Step 601/3000, Loss: 0.9834035634994507\n",
      "Step 701/3000, Loss: 0.8937065005302429\n",
      "Step 801/3000, Loss: 0.8562383651733398\n",
      "Step 901/3000, Loss: 0.9653851985931396\n",
      "Step 1001/3000, Loss: 0.9724705815315247\n",
      "Step 1101/3000, Loss: 0.8303353786468506\n",
      "Step 1201/3000, Loss: 0.9797831773757935\n",
      "Step 1301/3000, Loss: 0.9903014302253723\n",
      "Step 1401/3000, Loss: 1.0249546766281128\n",
      "Step 1501/3000, Loss: 0.8320584893226624\n",
      "Step 1601/3000, Loss: 0.9523743391036987\n",
      "Step 1701/3000, Loss: 0.955583393573761\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Layer, MultiHeadAttention\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Masking, Input, Lambda\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse\n",
    "from numpy.fft import fft\n",
    "from scipy.stats import skew, kurtosis \n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, accuracy_score\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "class DataGenerator:        \n",
    "    def __init__(self, filepath, batch_size, sequence_length, max_samples=None, for_training=True):\n",
    "        self.filepath = filepath\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_samples = max_samples\n",
    "        self.for_training = for_training\n",
    "        self.samples = []\n",
    "        self.binary_file = open(self.filepath, 'rb')  # Initialize the binary_file here\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.total_samples_processed = 0\n",
    "        _, self.file_extension = os.path.splitext(self.filepath)\n",
    "        print(f\"File extension detected: {self.file_extension}\")  # Add this line\n",
    "    def __iter__(self):\n",
    "        self.binary_file.seek(0)  # reset file pointer\n",
    "        self.samples = []\n",
    "        return self    \n",
    "    def close(self):\n",
    "        if not self.binary_file.closed:\n",
    "            self.binary_file.close()\n",
    "    def process_data1(self, samples):\n",
    "        real_parts = []\n",
    "        imag_parts = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                cnum = complex(sample.replace('j', 'j'))\n",
    "                real_parts.append(np.real(cnum))\n",
    "                imag_parts.append(np.imag(cnum))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        real_parts = (real_parts - np.mean(real_parts)) / np.std(real_parts)\n",
    "        imag_parts = (imag_parts - np.mean(imag_parts)) / np.std(imag_parts)\n",
    "\n",
    "        X = [list(zip(real_parts[i:i+self.sequence_length], imag_parts[i:i+self.sequence_length])) for i in range(len(real_parts) - self.sequence_length)]\n",
    "        return np.array(X)\n",
    "    def process_data2(self, samples):\n",
    "        # Convert samples list to a NumPy array and check the total number of samples\n",
    "        samples_array = np.array(samples, dtype=np.complex64)\n",
    "        total_samples = samples_array.size\n",
    "\n",
    "        # Ensure that the total number of samples matches self.batch_size * self.sequence_length\n",
    "        if total_samples != self.batch_size * self.sequence_length:\n",
    "            # Handle this scenario: you might want to raise an error or handle it in some way\n",
    "            raise ValueError(\"Total number of samples does not match batch_size * sequence_length\")\n",
    "\n",
    "        # Check for invalid values in samples_array before processing\n",
    "        if np.isnan(samples_array).any() or np.isinf(samples_array).any():\n",
    "            print(f\"Invalid values found in samples_array: {samples_array}\")\n",
    "        # Reshape the samples array\n",
    "        samples_array = samples_array.reshape(self.batch_size, self.sequence_length)\n",
    "        #print('samples_array.shape:', samples_array.shape)\n",
    "\n",
    "        # Apply FFT to convert time-domain signals into frequency domain\n",
    "        samples_fft = fft(samples_array)\n",
    "        # Extract real and imaginary parts\n",
    "        real_parts = np.real(samples_fft)\n",
    "        imag_parts = np.imag(samples_fft)     \n",
    "        # Normalize the real and imaginary parts\n",
    "        epsilon = 1e-10\n",
    "        real_parts_mean = np.mean(real_parts, axis=1, keepdims=True)\n",
    "        real_parts_std = np.std(real_parts, axis=1, keepdims=True)\n",
    "        real_parts_std[real_parts_std == 0] = epsilon  # Avoid division by zero\n",
    "        real_parts = (real_parts - real_parts_mean) / real_parts_std\n",
    "\n",
    "        imag_parts_mean = np.mean(imag_parts, axis=1, keepdims=True)\n",
    "        imag_parts_std = np.std(imag_parts, axis=1, keepdims=True)\n",
    "        imag_parts_std[imag_parts_std == 0] = epsilon  # Avoid division by zero\n",
    "        imag_parts = (imag_parts - imag_parts_mean) / imag_parts_std\n",
    "\n",
    "        # Extract statistical features from the real and imaginary parts\n",
    "        features = np.column_stack((\n",
    "            np.mean(real_parts, axis=1),\n",
    "            np.std(real_parts, axis=1),\n",
    "            skew(real_parts, axis=1),\n",
    "            kurtosis(real_parts, axis=1),\n",
    "            np.mean(imag_parts, axis=1),\n",
    "            np.std(imag_parts, axis=1),\n",
    "            skew(imag_parts, axis=1),\n",
    "            kurtosis(imag_parts, axis=1)\n",
    "        ))\n",
    "\n",
    "        # Reshape features to match the input shape of the model\n",
    "        X = features.reshape(-1, self.sequence_length, features.shape[1])\n",
    "        return X\n",
    "\n",
    "    def __next__(self):\n",
    "        chunksize = self.batch_size * self.sequence_length\n",
    "        global totalMagnitude  # Access the global variable\n",
    "        global totalnumberofsamples  # Access the global variable        \n",
    "        #if self.file_extension == '.dat':        \n",
    "        samples = []\n",
    "        while True:\n",
    "            binary_data = self.binary_file.read(8)\n",
    "            if not binary_data:\n",
    "                break  # End of file\n",
    "            decoded_data = struct.unpack('ff', binary_data)            \n",
    "            # Skip samples that are exactly zero (0 + 0j)\n",
    "            if decoded_data[0] == 0 and decoded_data[1] == 0:\n",
    "                continue\n",
    "            # Convert the binary data to a complex number string\n",
    "            decoded_line = f\"{decoded_data[0]}+{decoded_data[1]}j\\n\" if decoded_data[1] >= 0 else f\"{decoded_data[0]}{decoded_data[1]}j\\n\"\n",
    "            samples.append(decoded_line)\n",
    "            # Check if we have enough samples for a batch\n",
    "            if len(samples) == chunksize:\n",
    "                X_chunk = self.process_data1(samples)\n",
    "                #X_chunk = self.process_data2(samples)\n",
    "                if self.for_training:\n",
    "                    return X_chunk, X_chunk\n",
    "                else:\n",
    "                    return X_chunk\n",
    "                # Clear samples for the next batch (optional, depends on your logic)\n",
    "                samples = []\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "# Minimum Entropy Coupling (MEC) Functions\n",
    "def mec_kocaoglu_np(p, q):\n",
    "    \"\"\"\n",
    "    Compute the joint distribution matrix with minimal entropy between two given distributions.\n",
    "    \"\"\"\n",
    "    p = tf.cast(p, tf.float64) / tf.reduce_sum(p)\n",
    "    q = tf.cast(q, tf.float64) / tf.reduce_sum(q)\n",
    "    J = tf.zeros((tf.size(q), tf.size(p)), dtype=tf.float64)\n",
    "    M = tf.stack([p, q], axis=0)\n",
    "    r = tf.reduce_min(tf.reduce_max(M, axis=1))\n",
    "    #print('Input shapes to mec_kocaoglu_np:', p.shape, q.shape)\n",
    "    def body(r, M, J):\n",
    "        a_i = tf.argmax(M, axis=1)\n",
    "        r_updated = tf.reduce_min(tf.reduce_max(M, axis=1))\n",
    "        update_values = tf.stack([r, r])\n",
    "        # ensure tensors have same datatype\n",
    "        a_i = tf.cast(a_i, dtype=tf.int32)\n",
    "        indices_range = tf.range(tf.size(a_i), dtype=tf.int32)\n",
    "        #prepare indices for scatter update\n",
    "        indices = tf.stack([indices_range, a_i], axis=1)\n",
    "        #now update\n",
    "        M_updates = tf.scatter_nd(indices, -update_values, tf.shape(M))\n",
    "        M = M + M_updates\n",
    "        J_updates = tf.scatter_nd(indices, [r, r], tf.shape(J))\n",
    "        J = J + J_updates\n",
    "        return r_updated, M, J\n",
    "\n",
    "    def condition(r, M, J):\n",
    "        return r > 0\n",
    "    r, M, J = tf.while_loop(condition, body, loop_vars=[r, M, J])\n",
    "    return J\n",
    "\n",
    "def apply_mec_to_data(data, num_bins=10, latent_dim=50):\n",
    "    print('data.shape in apply mec:', data.shape)\n",
    "    \"\"\"\n",
    "    Apply the MEC transformation to each sample in the data using tf.map_fn.\n",
    "    \"\"\"\n",
    "    def process_sample(sample):\n",
    "        min_val = tf.reduce_min(sample)\n",
    "        max_val = tf.reduce_max(sample)\n",
    "        sample_distribution = tf.histogram_fixed_width(sample, [min_val, max_val], nbins=num_bins)\n",
    "        sample_distribution = tf.cast(sample_distribution, tf.float64)\n",
    "        sum_distribution = tf.cast(tf.reduce_sum(sample_distribution), tf.float64)\n",
    "        sample_distribution /= sum_distribution\n",
    "\n",
    "        mec_transformed = mec_kocaoglu_np(sample_distribution, sample_distribution)\n",
    "\n",
    "        # Flatten the 2D to 1D\n",
    "        if len(mec_transformed.shape) > 1:\n",
    "            transformed_sample = tf.reshape(mec_transformed, [-1])\n",
    "\n",
    "        # slice/pad to match the latent_dim\n",
    "        if transformed_sample.shape[0] > latent_dim:\n",
    "            transformed_sample = transformed_sample[:latent_dim]\n",
    "        elif transformed_sample.shape[0] < latent_dim:\n",
    "            padding = tf.zeros(latent_dim - transformed_sample.shape[0], dtype=tf.float64)\n",
    "            transformed_sample = tf.concat([transformed_sample, padding], axis=0)\n",
    "\n",
    "        return tf.reshape(transformed_sample, (latent_dim,))\n",
    "    # apply function to each sample in the batch\n",
    "    transformed_batch = tf.map_fn(process_sample, data, dtype=tf.float64, parallel_iterations=10)\n",
    "    return transformed_batch\n",
    "\n",
    "def process_latent_variables(z):\n",
    "    z_transformed = apply_mec_to_data(z)\n",
    "    #print('Output of MEC transformation shape:', z_transformed.shape)\n",
    "    return z_transformed\n",
    "class SelfAttentionLayer(Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.multi_head_attention(inputs, inputs, inputs)\n",
    "# Variational Autoencoder (VAE) Class\n",
    "class VAE:\n",
    "    def __init__(self, sequence_length, feature_dim, original_dim, intermediate_dim, latent_dim,\n",
    "                 epsilon_std=0.1, dropout_rate=0.2):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_dim = feature_dim\n",
    "        self.original_dim = original_dim\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.epsilon_std = epsilon_std\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.vae = None\n",
    "        self._build()\n",
    "        #self._build2()\n",
    "    def _sampling3(self, args):\n",
    "        z_mean, _ = args  # Ignore z_log_var for simplicity\n",
    "        z_mean_transformed = process_latent_variables(z_mean)\n",
    "        epsilon_std = 0.1  # Use a fixed small std deviation to reduce variability\n",
    "        #epsilon = K.random_normal(shape=K.shape(z_mean), mean=0., stddev=epsilon_std)\n",
    "        epsilon = K.random_normal(shape=K.shape(z_mean_transformed), mean=0., stddev=epsilon_std)\n",
    "        #epsilon = process_latent_variables(epsilon)\n",
    "        epsilon = tf.cast(epsilon, 'float64')  # Cast epsilon to float64        \n",
    "        #a = z_mean_transformed + epsilon\n",
    "        #return a\n",
    "        return z_mean_transformed\n",
    "    def _sampling(self, args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim), mean=0., stddev=self.epsilon_std)\n",
    "        output = z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "        return output\n",
    "        \n",
    "    def _build(self):\n",
    "        # Encoder\n",
    "        inputs = Input(shape=(self.sequence_length, self.feature_dim), name='encoder_input')\n",
    "        x = LSTM(50, activation='tanh', return_sequences=True)(inputs)\n",
    "        self_attention = SelfAttentionLayer(num_heads=2, key_dim=50)  # Adjust num_heads and key_dim as needed\n",
    "        x = self_attention(x)\n",
    "        x = LSTM(50, activation='tanh', return_sequences=False)(x)\n",
    "        z_mean = Dense(50, name='z_mean')(x)\n",
    "        z_log_var = Dense(50, name='z_log_var')(x)\n",
    "\n",
    "        #z = Lambda(self._sampling, output_shape=(self.latent_dim,), name='z')([z_mean, z_log_var])\n",
    "        z = Lambda(self._sampling3, output_shape=(50,))([z_mean, z_mean])\n",
    "        self.encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')        \n",
    "        # Decoder\n",
    "        latent_inputs = Input(shape=(50,), name='z_sampling')\n",
    "        x = RepeatVector(self.sequence_length)(latent_inputs)\n",
    "        x = LSTM(50, activation='tanh', return_sequences=True)(x)\n",
    "        x = LSTM(50, activation='tanh', return_sequences=True)(x)\n",
    "        final_activation = 'sigmoid' #'linear' if data is not normalized\n",
    "        outputs = TimeDistributed(Dense(self.feature_dim))(x)\n",
    "        # Instantiate the decoder model\n",
    "        self.decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "        # VAE model\n",
    "        outputs = self.decoder(self.encoder(inputs)[2])\n",
    "        self.vae = Model(inputs, outputs, name='vae_mlp')\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean, z_mean, z_log_var):\n",
    "        mse = tf.reduce_mean(tf.square(x - x_decoded_mean), axis=(1, 2))\n",
    "        xent_loss = mse\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return K.mean(xent_loss + kl_loss)\n",
    "    def simplified_vae_loss(self, x, x_decoded_mean, z_mean):\n",
    "        mse = tf.reduce_mean(tf.square(x - x_decoded_mean), axis=(1, 2))\n",
    "        mean_loss = tf.reduce_mean(tf.square(z_mean))\n",
    "        total_loss = mse + mean_loss\n",
    "        return K.mean(total_loss)\n",
    "    \n",
    "    def compile(self, learning_rate=0.001, optimizer='adam'):\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        def vae_loss_wrapper(x, x_decoded_mean):\n",
    "            z_mean, z_log_var, _ = self.encoder(x)\n",
    "            return self.vae_loss(x, x_decoded_mean, z_mean, z_log_var)\n",
    "\n",
    "        self.vae.compile(optimizer=optimizer, loss=vae_loss_wrapper)\n",
    "\n",
    "    def compile2(self, learning_rate=0.0005, optimizer='adam'):\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "        # Define a wrapper function for the custom loss\n",
    "        def custom_loss_wrapper(x, x_decoded_mean):\n",
    "            z_mean, z_log_var, _ = self.encoder(x)\n",
    "            return self.custom_loss(x, x_decoded_mean, z_mean, z_log_var)\n",
    "\n",
    "        self.vae.compile(optimizer=optimizer, loss=custom_loss_wrapper)\n",
    "    def compile_custom(self, learning_rate=0.001, optimizer='adam'):\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        def custom_loss_wrapper(x, x_decoded_mean):\n",
    "            z_mean, _, _ = self.encoder(x)\n",
    "            return self.simplified_vae_loss(x, x_decoded_mean, z_mean)\n",
    "\n",
    "        self.vae.compile(optimizer=optimizer, loss=custom_loss_wrapper)\n",
    "    def compile_simple_autoencoder(self, learning_rate=0.005, optimizer='adam'):\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)        \n",
    "        # Simple reconstruction loss\n",
    "        self.vae.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# Instantiate and Compile the VAE\n",
    "sequence_length = 10\n",
    "feature_dim = 2\n",
    "original_dim = 100\n",
    "intermediate_dim = 100\n",
    "latent_dim = 50\n",
    "\n",
    "vae_model = VAE(sequence_length, feature_dim, original_dim, intermediate_dim, latent_dim)\n",
    "#vae_model.vae.compile(optimizer='adam', loss=vae_model.vae_loss)\n",
    "#vae_model.compile2(learning_rate=0.005)\n",
    "vae_model.compile_simple_autoencoder(learning_rate=0.005)\n",
    "#vae_model.compile_custom(learning_rate=0.005)\n",
    "\n",
    "# Model Training\n",
    "batch_size = 100\n",
    "max_train_samples = 3000000\n",
    "train_steps = max_train_samples // (batch_size * sequence_length)\n",
    "max_samples = 3000000  # Maximum samples to read (or None to read all)\n",
    "max_test_samples = 3000000\n",
    "\n",
    "pure_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/pure_data/pure_iq_samples_*.csv'\n",
    "mixed_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/mixed_data/mixed_iq_samples_*.csv'\n",
    "pure_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_pure'\n",
    "mixed_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_MIX'\n",
    "pure_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_no_jamming_0924.dat'\n",
    "mixed_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_with_periodic_jamming_0928_02.dat'\n",
    "# Example file patterns\n",
    "#pure_file_pattern = 'C:\\\\Users\\\\Mohammadreza\\\\Desktop\\\\My Class\\\\Proj-DC\\\\My Works\\\\My Papers\\\\intrusion\\\\data generator\\\\pure_data\\\\pure_iq_samples_*.csv'\n",
    "#mixed_file_pattern = 'C:\\\\Users\\\\Mohammadreza\\\\Desktop\\\\My Class\\\\Proj-DC\\\\My Works\\\\My Papers\\\\intrusion\\\\data generator\\\\mixed_data\\\\mixed_iq_samples_*.csv'\n",
    "\n",
    "# Data Generator Instances\n",
    "train_gen_instance = DataGenerator(pure_file_new,batch_size=batch_size, sequence_length=sequence_length, \n",
    "                                   max_samples=max_train_samples, for_training=True)\n",
    "combined_gen_instance = DataGenerator(mixed_file_new,batch_size=batch_size, sequence_length=sequence_length, \n",
    "                                      for_training=False)\n",
    "\n",
    "num_epochs = 4  # You can adjust the number of epochs as needed\n",
    "steps_per_epoch = train_steps  # Assuming one epoch processes all the data\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_gen_instance.reset()  # Reset the generator at the beginning of each epoch\n",
    "    for step in range(steps_per_epoch):\n",
    "        try:\n",
    "            X_chunk, Y_chunk = next(train_gen_instance)\n",
    "        except StopIteration:\n",
    "            train_gen_instance.reset()  # Reset the generator when it runs out of data\n",
    "            X_chunk, Y_chunk = next(train_gen_instance)\n",
    "\n",
    "        #loss = model.train_on_batch(X_chunk, Y_chunk)\n",
    "        loss = vae_model.vae.train_on_batch(X_chunk, Y_chunk)\n",
    "        #print(f\"Step {step + 1}/{steps_per_epoch}\", end='\\r')\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step + 1}/{train_steps}, Loss: {loss}\")\n",
    "    print()\n",
    "\n",
    "num_predictions = 500  # or any other large number\n",
    "print(f\"Number of predictions to be performed: {num_predictions}\")\n",
    "\n",
    "\n",
    "reconstruction_errors = []\n",
    "all_X_chunk_test = []\n",
    "all_X_chunk_pred = []\n",
    "all_intrusion_flags = []\n",
    "try:\n",
    "    for _ in range(num_predictions):\n",
    "        print('prediction number:', _)\n",
    "        X_chunk_test = next(combined_gen_instance)\n",
    "        #X_chunk_pred = model.predict(X_chunk_test)\n",
    "        X_chunk_pred = vae_model.vae.predict(X_chunk_test)\n",
    "        chunk_errors = np.mean(np.square(X_chunk_test - X_chunk_pred), axis=1)\n",
    "        reconstruction_errors.extend(chunk_errors)        \n",
    "        all_X_chunk_test.append(X_chunk_test)\n",
    "        all_X_chunk_pred.append(X_chunk_pred)\n",
    "except StopIteration:\n",
    "    print(\"All samples processed.\")\n",
    "\n",
    "\n",
    "reconstruction_error = np.array(reconstruction_errors)\n",
    "print('reconstruction_error.shape:', reconstruction_error.shape)\n",
    "print('Number of NaNs in reconstruction_error:', np.isnan(reconstruction_error).sum())\n",
    "max_error_per_sequence = reconstruction_error.max(axis=1) # Max error for each sequence\n",
    "print('max_error_per_sequence:', max_error_per_sequence)\n",
    "\n",
    "print('max_error_per_sequence.shape:', max_error_per_sequence.shape)\n",
    "\n",
    "threshold1 = np.percentile(max_error_per_sequence, 98)\n",
    "print('threshold1:', threshold1)\n",
    "threshold2 = np.percentile(reconstruction_error, 95)\n",
    "print('threshold percentile:', threshold2)\n",
    "\n",
    "is_intrusion_detected = max_error_per_sequence > threshold1  # Boolean array for sequences\n",
    "print('len(is_intrusion_detected):', len(is_intrusion_detected))\n",
    "print('is_intrusion_detected.shape:', is_intrusion_detected.shape)\n",
    "\n",
    "#is_intrusion_detected2 = error_per_sequence > threshold1\n",
    "\n",
    "num_total_sequences = len(max_error_per_sequence)\n",
    "num_total_sequences2 = num_predictions * batch_size - num_predictions\n",
    "print('num_total_sequences:', num_total_sequences)\n",
    "print('num_total_sequences2:', num_total_sequences2)\n",
    "\n",
    "#---------------------------------------finish 111-----------------------------------\n",
    "flat_error_per_sequence = max_error_per_sequence.flatten()\n",
    "#flat_error_per_sequence2 = error_per_sequence.flatten()\n",
    "# Determine if intrusion detected for each sequence\n",
    "for error in flat_error_per_sequence:\n",
    "    all_intrusion_flags.append(error > threshold1)    \n",
    "all_X_chunk_test = np.concatenate(all_X_chunk_test, axis=0)\n",
    "all_X_chunk_pred = np.concatenate(all_X_chunk_pred, axis=0)\n",
    "\n",
    "#save_path = 'C:\\\\Users\\\\Mohammadreza\\\\Desktop\\\\My Class\\\\Proj-DC\\\\My Works\\\\My Papers\\\\intrusion\\\\data generator\\\\intrusion_detected'\n",
    "#plot_with_intrusions8(all_X_chunk_test, all_X_chunk_pred, all_intrusion_flags, sequence_length, save_path)\n",
    "\n",
    "jamming_detected = reconstruction_error > threshold1\n",
    "train_gen_instance.close()\n",
    "combined_gen_instance.close()\n",
    "#Table\n",
    "flattened_jamming_detected = jamming_detected.flatten()\n",
    "real_part_detected = jamming_detected[:, 0]\n",
    "imag_part_detected = jamming_detected[:, 1]\n",
    "\n",
    "real_true_count = np.sum(real_part_detected)\n",
    "real_false_count = len(real_part_detected) - real_true_count\n",
    "\n",
    "imag_true_count = np.sum(imag_part_detected)\n",
    "imag_false_count = len(imag_part_detected) - imag_true_count\n",
    "# Overall\n",
    "overall_true_count = np.sum(flattened_jamming_detected)\n",
    "overall_false_count = len(flattened_jamming_detected) - overall_true_count\n",
    "# Table-DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Part': ['Real', 'Imaginary', 'Overall'],\n",
    "    'True Count': [real_true_count, imag_true_count, overall_true_count],\n",
    "    'False Count': [real_false_count, imag_false_count, overall_false_count]\n",
    "})\n",
    "print(df)\n",
    "num_jamming_detected = np.sum(jamming_detected)\n",
    "print(f\"Number of jamming sequences detected: {num_jamming_detected} out of {len(flattened_jamming_detected)} sequences\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 4  # Change this to desired number of sequences\n",
    "\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'orange', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'orange', label='Reconstructed Real STD', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'pink', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'pink', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for n = 9\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure compatibility for TensorFlow 2.x\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "# Dummy data assuming z_mean and z_log_var have been obtained\n",
    "z_mean = tf.random.normal([100, 50])  # 100 samples, 50 dimensions\n",
    "z_log_var = tf.random.normal([100, 50])\n",
    "\n",
    "# Simplified version of your model's sampling functions for visualization purposes\n",
    "def sample_vae(z_mean, z_log_var, epsilon_std=0.1):\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.random.normal(shape=(batch, dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def sample_mec(z_mean, epsilon_std=0.1):\n",
    "    # Assuming process_latent_variables mimics the actual MEC transformation process\n",
    "    z_transformed = process_latent_variables(z_mean)  # Your actual MEC function\n",
    "    # Ensure epsilon has the same dtype as z_transformed\n",
    "    epsilon = tf.random.normal(shape=tf.shape(z_transformed), mean=0., stddev=epsilon_std, dtype=z_transformed.dtype)\n",
    "    return z_transformed + epsilon\n",
    "\n",
    "# Function to plot distributions\n",
    "def plot_distribution(tensor, label, color):\n",
    "    print('tensor:', tensor)\n",
    "    if isinstance(tensor, tf.Tensor):\n",
    "        tensor = tensor.numpy()  # Convert TensorFlow tensor to numpy array\n",
    "    tensor = tensor.flatten()  # Flatten the tensor/array\n",
    "    \n",
    "    plt.hist(tensor, bins=30, density=True, alpha=0.6, label=label, color=color)\n",
    "    \n",
    "    kde = gaussian_kde(tensor)\n",
    "    kde_x = np.linspace(tensor.min(), tensor.max(), 500)\n",
    "    kde_y = kde.evaluate(kde_x)\n",
    "    plt.plot(kde_x, kde_y, color=color, alpha=0.7)\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "z_sampled_vae = sample_vae(z_mean, z_log_var)\n",
    "z_sampled_mec = sample_mec(z_mean)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "plot_distribution(z_mean.numpy().flatten(), \"z_mean distribution\", \"blue\")\n",
    "plot_distribution(z_sampled_vae.numpy().flatten(), \"Sampled VAE z distribution\", \"red\")\n",
    "plot_distribution(z_sampled_mec.numpy().flatten(), \"Sampled MEC z distribution\", \"green\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Variable Distributions Before and After Sampling')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa42b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def extract_first_two_dimensions(latent_vars):\n",
    "    return latent_vars[:, :2].numpy()  # Extract first two dimensions and convert to numpy\n",
    "\n",
    "# Prepare the latent variables\n",
    "z_mean_2d = extract_first_two_dimensions(z_mean)\n",
    "z_sampled_vae_2d = extract_first_two_dimensions(z_sampled_vae)\n",
    "z_sampled_mec_2d = extract_first_two_dimensions(z_sampled_mec)\n",
    "\n",
    "def scatter_plots(latent_variables, labels, titles):\n",
    "    # Set up a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(24, 10))\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "\n",
    "    # First plot: z_mean vs. Sampled VAE\n",
    "    axs[0].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], color='red', s=50, label='z_mean')\n",
    "    axs[0].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], color='orange', s=50, label='Sampled VAE')\n",
    "    axs[0].set_title(titles[0])\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Second plot: z_mean vs. Sampled MEC\n",
    "    axs[1].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], color='red', s=50, label='z_mean')\n",
    "    axs[1].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], color='limegreen', s=50, label='Sampled MEC')\n",
    "    axs[1].set_title(titles[1])\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    # Third plot: Combined Latent Space\n",
    "    axs[2].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], color='red', s=50, label='z_mean')\n",
    "    axs[2].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], color='orange', s=50, label='Sampled VAE')\n",
    "    axs[2].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], color='limegreen', s=50, label='Sampled MEC')\n",
    "    axs[2].set_title(titles[2])\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "\n",
    "    # Set axes labels\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('Latent Dimension 1')\n",
    "        ax.set_ylabel('Latent Dimension 2')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare the latent variables for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "titles = ['z_mean vs. Sampled VAE', 'z_mean vs. Sampled MEC', 'Combined Latent Space']\n",
    "\n",
    "# Call the plotting function\n",
    "scatter_plots(latent_variables, labels, titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fa3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert TensorFlow tensors to numpy arrays\n",
    "z_mean_np = z_mean.numpy()\n",
    "z_sampled_vae_np = z_sampled_vae.numpy()\n",
    "z_sampled_mec_np = z_sampled_mec.numpy()\n",
    "\n",
    "# Only use the first two dimensions for the 2D scatter plot\n",
    "z_mean_np = z_mean_np[:, :2]\n",
    "z_sampled_vae_np = z_sampled_vae_np[:, :2]\n",
    "z_sampled_mec_np = z_sampled_mec_np[:, :2]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    default_marker_size = 150\n",
    "\n",
    "    if marker_sizes_dict:\n",
    "        for category, msize in marker_sizes_dict.items():\n",
    "            subset = dataframe[dataframe[hue] == category]\n",
    "            sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                            hue=hue, s=msize, alpha=0.8, legend=False)\n",
    "    else:\n",
    "        sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        hue=hue, s=default_marker_size, alpha=0.8)\n",
    "\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "    sns.despine(trim=True)\n",
    "    plt.show()\n",
    "    \n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette=None,\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Define the color palette manually if not provided\n",
    "    if palette is None:\n",
    "        palette = {\n",
    "            'z_mean': 'red',\n",
    "            'Sampled VAE': 'orange',\n",
    "            'Sampled MEC': 'limegreen'\n",
    "        }\n",
    "    \n",
    "    # Define default marker size if not provided\n",
    "    if marker_sizes_dict is None:\n",
    "        marker_sizes_dict = {\n",
    "            'z_mean': 100,        # Default marker size for z_mean\n",
    "            'Sampled VAE': 100,   # Default marker size for Sampled VAE\n",
    "            'Sampled MEC': 150    # Default marker size for Sampled MEC\n",
    "        }\n",
    "\n",
    "    # Plot each subset with its specified marker size\n",
    "    for category, msize in marker_sizes_dict.items():\n",
    "        subset = dataframe[dataframe[hue] == category]\n",
    "        sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2',\n",
    "                        hue=hue, palette=palette, s=msize, alpha=0.8, legend=False)\n",
    "    \n",
    "    # Plot the legend separately\n",
    "    for category in marker_sizes_dict.keys():\n",
    "        plt.scatter([], [], color=palette[category], s=marker_sizes_dict[category],\n",
    "                    label=category, alpha=0.8)\n",
    "    \n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "    sns.despine(trim=True)\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with custom settings\n",
    "enhanced_scatter_plot(df, hue='Type', extend_axis_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4348bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error_flat, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a86f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error_flat, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4005b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Series Plot of IQ Samples:\n",
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('5-Original vs Reconstructed IQ Data.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e87830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot of Reconstruction Errors vs. Real and Imaginary Parts:\n",
    "avg_real = np.mean(X_chunk_test, axis=1)[:, 0]\n",
    "avg_imag = np.mean(X_chunk_test, axis=1)[:, 1]\n",
    "\n",
    "last_errors = np.mean(reconstruction_errors[-len(X_chunk_test):], axis=1)\n",
    "\n",
    "print(\"Shape of avg_real:\", avg_real.shape)\n",
    "print(\"Shape of avg_imag:\", avg_imag.shape)\n",
    "print(\"Shape of last_errors:\", len(last_errors))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_real, last_errors, label='Real Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Real Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('6-Reconstruction Error vs. Average Real Part.png')\n",
    "# plt.close()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_imag, last_errors, label='Imaginary Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Imaginary Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('7-Reconstruction Error vs. Average Imaginary Part.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Img Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Img Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640153f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'orange', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'orange', label='Reconstructed Real STD', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'pink', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'pink', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for n = 9\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd97dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63145cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 1  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction error\n",
    "reconstruction_error_real = reconstruction_error[:, 0]\n",
    "reconstruction_error_imag = reconstruction_error[:, 1]\n",
    "\n",
    "# Plot for Real Part\n",
    "plt.figure(figsize=(14, 6))\n",
    "mellow_green = '#89C997' \n",
    "plt.plot(reconstruction_error_real, label='Reconstruction Error', color=mellow_green)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Intrusion Detected by Reconstruction Error',fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sequence Number (×10³)', fontsize=16, fontweight='bold')\n",
    "#plt.xlabel('Sequence Number(*1000)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Reconstruction Error', fontsize=16, fontweight='bold')\n",
    "for label in (plt.gca().get_xticklabels() + plt.gca().get_yticklabels()):\n",
    "    label.set_fontsize(12)\n",
    "    label.set_fontweight('bold')\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "# plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "# plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "# plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "# plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "# plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "# plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad266e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_real_parts = reconstruction_error[:, 0]\n",
    "reconstruction_error_real_std = reconstruction_error[:, 1]\n",
    "reconstruction_error_real_skew = reconstruction_error[:, 2]\n",
    "reconstruction_error_real_kurtosis = reconstruction_error[:, 3]\n",
    "reconstruction_error_imag_parts = reconstruction_error[:, 4]\n",
    "reconstruction_error_imag_std = reconstruction_error[:, 5]\n",
    "reconstruction_error_imag_skew = reconstruction_error[:, 6]\n",
    "reconstruction_error_imag_kurtosis = reconstruction_error[:, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "# plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "# plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "# plt.plot(original_sample[:, 4], 'g-', label='Original Imaginary Part')\n",
    "# plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'orange', label='Original Real STD')\n",
    "plt.plot(reconstructed_sample[:, 1], 'orange', label='Reconstructed Real STD', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 4], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.plot(original_sample[:, 5], 'pink', label='Original Imaginary STD')\n",
    "plt.plot(reconstructed_sample[:, 5], 'pink', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 2], 'b-', label='Original Real Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'r--', label='Reconstructed Real Part Skew')\n",
    "plt.plot(original_sample[:, 6], 'g-', label='Original Imaginary Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'y--', label='Reconstructed Imaginary Part Skew')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 3], 'b-', label='Original Real Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'r--', label='Reconstructed Real Part Kurtosis')\n",
    "plt.plot(original_sample[:, 7], 'g-', label='Original Imaginary Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'y--', label='Reconstructed Imaginary Part Kurtosis')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671af7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
