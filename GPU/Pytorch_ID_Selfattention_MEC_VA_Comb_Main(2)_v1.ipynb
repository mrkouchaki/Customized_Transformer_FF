{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d3f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:33:54.232143: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 16:33:54.233185: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 16:33:54.257200: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 16:33:54.257624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 16:33:54.653648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (5.2.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/6\n",
      "X_chunk.shape: tensor([[[ 1.2300, -1.8079],\n",
      "         [-0.6736, -0.6628],\n",
      "         [-0.8200, -0.4337],\n",
      "         ...,\n",
      "         [ 2.1085,  0.4681],\n",
      "         [ 0.6443,  0.9405],\n",
      "         [-0.2343,  1.6275]],\n",
      "\n",
      "        [[-0.8704,  0.2526],\n",
      "         [-1.0445, -0.8702],\n",
      "         [ 0.5222, -1.7124],\n",
      "         ...,\n",
      "         [-0.8704,  0.2526],\n",
      "         [ 0.6963, -1.4317],\n",
      "         [ 0.3482,  0.2526]],\n",
      "\n",
      "        [[-1.4235,  0.5623],\n",
      "         [-1.2284,  0.0556],\n",
      "         [ 0.3330, -0.4675],\n",
      "         ...,\n",
      "         [-0.2525, -0.9906],\n",
      "         [-0.2525,  0.0556],\n",
      "         [-0.6428,  0.3171]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0487,  0.7830],\n",
      "         [-0.7751, -0.4468],\n",
      "         [-1.4591,  0.0514],\n",
      "         ...,\n",
      "         [-1.2311, -0.1977],\n",
      "         [-0.0912, -0.4468],\n",
      "         [ 0.5927,  1.7948]],\n",
      "\n",
      "        [[-0.6222,  0.7681],\n",
      "         [ 1.0074, -1.2976],\n",
      "         [ 2.0445,  0.5782],\n",
      "         ...,\n",
      "         [ 0.7111,  1.9197],\n",
      "         [ 0.4148,  0.5900],\n",
      "         [-1.5112, -0.9296]],\n",
      "\n",
      "        [[ 0.6020,  0.5135],\n",
      "         [ 0.1615,  0.5135],\n",
      "         [-1.1507,  1.3449],\n",
      "         ...,\n",
      "         [-0.8571,  1.1976],\n",
      "         [-0.1413,  0.3750],\n",
      "         [ 1.0424, -0.7335]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "Step 1/4000, Loss: 2498.81396484375\n",
      "X_chunk.shape: tensor([[[ 0.3544,  0.7192],\n",
      "         [-0.2710,  0.8498],\n",
      "         [-1.3134,  0.3273],\n",
      "         ...,\n",
      "         [ 0.5629, -1.6318],\n",
      "         [ 1.3967, -1.8930],\n",
      "         [-0.0625,  0.4580]],\n",
      "\n",
      "        [[ 0.7425, -1.2585],\n",
      "         [ 0.7425, -0.3112],\n",
      "         [-0.3971,  0.6360],\n",
      "         ...,\n",
      "         [ 1.3123, -0.0406],\n",
      "         [-0.3971,  1.5833],\n",
      "         [-1.8394, -0.7172]],\n",
      "\n",
      "        [[ 2.0230, -0.6111],\n",
      "         [-0.6545, -0.2710],\n",
      "         [-0.6359,  0.7386],\n",
      "         ...,\n",
      "         [-1.5470,  0.2391],\n",
      "         [-0.6545,  0.4092],\n",
      "         [-0.3570,  1.0893]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2251, -0.2838],\n",
      "         [ 1.4117, -0.7594],\n",
      "         [-0.0205,  0.4295],\n",
      "         ...,\n",
      "         [ 0.5933,  1.3657],\n",
      "         [-0.2251,  0.1917],\n",
      "         [-1.6572,  1.8561]],\n",
      "\n",
      "        [[-0.5160,  1.5055],\n",
      "         [-0.1720,  1.6591],\n",
      "         [-1.5480, -0.0297],\n",
      "         ...,\n",
      "         [ 1.2040, -1.2580],\n",
      "         [-0.1720,  0.4308],\n",
      "         [ 0.5160, -0.7974]],\n",
      "\n",
      "        [[-1.8588,  0.7926],\n",
      "         [-0.1377, -0.3384],\n",
      "         [ 0.2065, -1.0453],\n",
      "         ...,\n",
      "         [ 0.8950,  0.9340],\n",
      "         [ 1.5834, -1.4694],\n",
      "         [ 0.5507,  0.3685]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.6399e+00, -9.6376e-01],\n",
      "         [ 6.9024e-01,  1.5687e+00],\n",
      "         [ 2.3594e-01,  1.5766e+00],\n",
      "         ...,\n",
      "         [ 1.4654e-03,  5.2396e-02],\n",
      "         [-1.4054e+00, -9.7170e-01],\n",
      "         [ 7.0490e-01,  1.7942e-01]],\n",
      "\n",
      "        [[-1.3920e+00,  6.6431e-01],\n",
      "         [-2.0107e+00, -4.0500e-01],\n",
      "         [-2.2125e-08, -1.6882e+00],\n",
      "         ...,\n",
      "         [ 3.0934e-01,  2.3659e-01],\n",
      "         [ 1.5467e-01,  4.3708e-01],\n",
      "         [-6.1869e-01,  1.5198e+00]],\n",
      "\n",
      "        [[ 2.2696e-01,  5.3668e-01],\n",
      "         [-1.8363e+00, -8.1082e-02],\n",
      "         [ 2.2696e-01, -2.8700e-01],\n",
      "         ...,\n",
      "         [ 2.0633e-02, -4.9292e-01],\n",
      "         [ 6.3962e-01, -1.7285e+00],\n",
      "         [-3.9202e-01, -2.8700e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.4641e-01,  1.2228e+00],\n",
      "         [ 1.4107e-01,  9.7851e-01],\n",
      "         [ 4.9374e-01, -4.8696e-01],\n",
      "         ...,\n",
      "         [ 3.1741e-01, -1.2197e+00],\n",
      "         [-1.0933e+00,  1.4670e+00],\n",
      "         [-1.2696e+00, -2.4272e-01]],\n",
      "\n",
      "        [[ 7.2808e-01, -4.4853e-02],\n",
      "         [-2.0949e-01, -5.5746e-01],\n",
      "         [-2.0846e+00,  1.9735e+00],\n",
      "         ...,\n",
      "         [-4.4388e-01, -1.0701e+00],\n",
      "         [ 2.4904e-02,  1.4609e+00],\n",
      "         [-4.4388e-01, -4.4853e-02]],\n",
      "\n",
      "        [[ 1.8770e+00,  5.4370e-01],\n",
      "         [-8.2573e-01,  3.6867e-01],\n",
      "         [-3.4877e-01,  1.7690e+00],\n",
      "         ...,\n",
      "         [ 9.2311e-01, -1.2066e+00],\n",
      "         [-4.0740e-02, -1.3926e+00],\n",
      "         [ 9.2311e-01, -5.0651e-01]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 2.3135e+00, -2.9642e-01],\n",
      "         [-3.4833e-01,  2.9890e-01],\n",
      "         [ 1.5077e-01,  2.9890e-01],\n",
      "         ...,\n",
      "         [ 8.0584e-01,  4.9735e-01],\n",
      "         [ 3.1714e-01, -1.4871e+00],\n",
      "         [-8.4743e-01,  1.8864e+00]],\n",
      "\n",
      "        [[ 3.3352e-02,  2.0814e+00],\n",
      "         [-4.6693e-01, -5.7725e-01],\n",
      "         [-1.6342e+00, -3.5329e-01],\n",
      "         ...,\n",
      "         [ 1.5342e+00, -1.3864e+00],\n",
      "         [ 7.0039e-01,  7.2246e-04],\n",
      "         [-1.3007e+00,  9.2548e-01]],\n",
      "\n",
      "        [[ 1.0489e-01,  6.3185e-01],\n",
      "         [ 1.0489e-01,  9.0056e-01],\n",
      "         [ 2.5783e+00, -5.3252e-01],\n",
      "         ...,\n",
      "         [-7.2388e-01, -1.4168e-01],\n",
      "         [-7.2388e-01,  1.1530e+00],\n",
      "         [-1.3455e+00, -1.5748e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.8643e+00,  1.4980e-01],\n",
      "         [-5.6740e-01,  1.6170e+00],\n",
      "         [-1.8643e+00, -2.3127e+00],\n",
      "         ...,\n",
      "         [ 8.1057e-02, -5.0686e-01],\n",
      "         [-4.0529e-01,  7.9620e-01],\n",
      "         [ 8.1057e-02, -6.7102e-01]],\n",
      "\n",
      "        [[-1.0855e+00,  9.6391e-01],\n",
      "         [-6.1446e-02, -8.0507e-02],\n",
      "         [ 8.1173e-01, -1.9373e+00],\n",
      "         ...,\n",
      "         [-5.6811e-01,  1.0800e+00],\n",
      "         [ 9.8422e-01,  3.8368e-01],\n",
      "         [ 1.3292e+00,  3.5539e-02]],\n",
      "\n",
      "        [[-1.1848e+00,  5.8904e-01],\n",
      "         [-1.7632e+00,  1.9144e+00],\n",
      "         [ 5.5039e-01, -4.4178e-01],\n",
      "         ...,\n",
      "         [ 8.3959e-01, -1.4890e+00],\n",
      "         [ 9.8419e-01, -9.6537e-01],\n",
      "         [-8.9562e-01,  6.0540e-01]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.6819,  0.2585],\n",
      "         [-0.6819,  1.0293],\n",
      "         [ 0.8548, -1.7968],\n",
      "         ...,\n",
      "         [ 0.5133,  0.5154],\n",
      "         [-1.0234,  0.7723],\n",
      "         [-1.1942,  0.2585]],\n",
      "\n",
      "        [[ 0.0629, -1.8515],\n",
      "         [-0.5661, -0.6637],\n",
      "         [ 1.3209,  0.1200],\n",
      "         ...,\n",
      "         [-1.5096, -1.2515],\n",
      "         [-0.8806, -0.2718],\n",
      "         [ 1.3209,  1.0996]],\n",
      "\n",
      "        [[ 1.0189,  0.8385],\n",
      "         [ 0.2799,  1.0329],\n",
      "         [-0.2233, -1.5068],\n",
      "         ...,\n",
      "         [ 1.0346,  1.4218],\n",
      "         [ 0.7673, -0.9114],\n",
      "         [-0.2233,  0.8263]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5086,  0.7025],\n",
      "         [ 1.1847, -0.3287],\n",
      "         [ 0.0952, -1.1665],\n",
      "         ...,\n",
      "         [-0.6900, -0.3287],\n",
      "         [ 1.5086,  1.3212],\n",
      "         [-0.6900,  0.7025]],\n",
      "\n",
      "        [[-0.2130,  1.1969],\n",
      "         [ 0.6310, -1.3117],\n",
      "         [-1.2848, -0.7717],\n",
      "         ...,\n",
      "         [-0.6417,  0.3082],\n",
      "         [-1.2848, -1.1317],\n",
      "         [ 1.0731,  1.0282]],\n",
      "\n",
      "        [[ 0.6156,  0.7384],\n",
      "         [-0.4140, -0.2779],\n",
      "         [-0.9343, -0.0238],\n",
      "         ...,\n",
      "         [ 0.2796,  0.7384],\n",
      "         [-0.2406, -1.5482],\n",
      "         [-1.6280,  0.4843]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.0935,  0.6293],\n",
      "         [ 0.8985, -1.5464],\n",
      "         [-0.4669,  1.3545],\n",
      "         ...,\n",
      "         [ 0.5084, -0.4586],\n",
      "         [-1.4422, -0.2168],\n",
      "         [-0.2719,  1.8380]],\n",
      "\n",
      "        [[-0.0879,  1.5165],\n",
      "         [ 2.0060, -0.6187],\n",
      "         [-0.6861, -0.4367],\n",
      "         ...,\n",
      "         [-0.3870, -0.6187],\n",
      "         [-1.8826,  0.9341],\n",
      "         [-0.6861,  0.7279]],\n",
      "\n",
      "        [[-0.4310,  1.5514],\n",
      "         [ 0.1865, -0.1090],\n",
      "         [-0.4310,  0.9980],\n",
      "         ...,\n",
      "         [-1.6659,  0.1678],\n",
      "         [ 1.8332, -0.4030],\n",
      "         [-1.0484, -0.1090]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6696, -0.3848],\n",
      "         [-0.4719, -0.3968],\n",
      "         [ 1.1589,  0.0133],\n",
      "         ...,\n",
      "         [-0.6350,  2.1240],\n",
      "         [-0.6350,  0.7731],\n",
      "         [ 1.1589, -1.3497]],\n",
      "\n",
      "        [[ 1.2987,  0.2215],\n",
      "         [ 0.6277,  0.9547],\n",
      "         [-0.5047, -1.0158],\n",
      "         ...,\n",
      "         [ 1.0750,  0.7103],\n",
      "         [ 0.6277, -0.2673],\n",
      "         [-1.3854, -1.4893]],\n",
      "\n",
      "        [[ 0.1495,  1.1058],\n",
      "         [-2.4384, -0.2752],\n",
      "         [ 1.2537,  1.0962],\n",
      "         ...,\n",
      "         [-0.5866,  0.6454],\n",
      "         [-0.0460,  1.4127],\n",
      "         [ 0.7016, -1.8097]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.7421,  0.0872],\n",
      "         [ 1.4485,  1.0945],\n",
      "         [-0.3039,  0.8067],\n",
      "         ...,\n",
      "         [ 1.2158,  1.8140],\n",
      "         [-1.1665,  0.5189],\n",
      "         [-1.4129, -1.2078]],\n",
      "\n",
      "        [[-0.8589,  0.0498],\n",
      "         [ 1.8124,  0.5328],\n",
      "         [-1.1557, -1.6407],\n",
      "         ...,\n",
      "         [-1.4710,  0.5328],\n",
      "         [-0.5621,  1.9819],\n",
      "         [ 0.9220,  0.2762]],\n",
      "\n",
      "        [[-0.3605,  0.9802],\n",
      "         [ 0.8475,  1.5053],\n",
      "         [ 0.5455,  0.4551],\n",
      "         ...,\n",
      "         [-0.0774, -1.8204],\n",
      "         [-0.9646, -1.1202],\n",
      "         [ 0.8475, -1.1202]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.4619,  0.9716],\n",
      "         [ 1.2919, -0.2263],\n",
      "         [-0.2571, -1.6904],\n",
      "         ...,\n",
      "         [ 0.0871,  0.1730],\n",
      "         [ 0.4314,  1.5040],\n",
      "         [-0.6013, -0.6256]],\n",
      "\n",
      "        [[-0.6813,  1.6476],\n",
      "         [ 0.8261, -0.8847],\n",
      "         [-1.4409, -1.3912],\n",
      "         ...,\n",
      "         [-0.3015,  0.1282],\n",
      "         [ 1.4076,  0.1282],\n",
      "         [ 0.8261, -1.6444]],\n",
      "\n",
      "        [[ 1.4869,  1.0735],\n",
      "         [ 0.9999,  0.6831],\n",
      "         [-0.2176,  0.0976],\n",
      "         ...,\n",
      "         [-0.7047,  0.2928],\n",
      "         [-2.1657,  1.4639],\n",
      "         [-0.4611, -0.0976]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.0808, -0.8222],\n",
      "         [ 0.5740, -0.6542],\n",
      "         [ 0.7376, -0.9902],\n",
      "         ...,\n",
      "         [ 0.7376, -1.4942],\n",
      "         [-1.2267,  0.3539],\n",
      "         [-1.7178,  1.6980]],\n",
      "\n",
      "        [[-0.8554, -0.7196],\n",
      "         [-1.4395,  1.1415],\n",
      "         [-0.2713,  0.1489],\n",
      "         ...,\n",
      "         [ 0.5074,  1.3896],\n",
      "         [ 0.7021, -1.7122],\n",
      "         [ 0.7021, -0.2233]],\n",
      "\n",
      "        [[-1.4680, -0.5829],\n",
      "         [-0.6099, -0.8676],\n",
      "         [-0.1875, -0.8676],\n",
      "         ...,\n",
      "         [ 0.2350,  0.8409],\n",
      "         [ 2.5585, -0.4405],\n",
      "         [ 0.2350,  0.9833]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1708,  2.1155],\n",
      "         [-0.7025,  0.6797],\n",
      "         [ 0.4683, -1.5437],\n",
      "         ...,\n",
      "         [ 1.8733, -0.3240],\n",
      "         [-1.4196, -1.5437],\n",
      "         [-0.6878,  0.2859]],\n",
      "\n",
      "        [[-0.4581,  0.3642],\n",
      "         [-0.4786, -2.0168],\n",
      "         [ 0.1992, -0.1371],\n",
      "         ...,\n",
      "         [ 1.5139,  1.8680],\n",
      "         [-0.7867,  0.1057],\n",
      "         [-1.7727, -0.1371]],\n",
      "\n",
      "        [[ 1.1130, -1.3893],\n",
      "         [-1.2699, -1.2399],\n",
      "         [-1.4287,  2.0466],\n",
      "         ...,\n",
      "         [-1.1011, -0.1942],\n",
      "         [ 0.3088,  0.1046],\n",
      "         [ 0.1599,  1.2997]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 9.3562e-01, -4.3749e-01],\n",
      "         [-2.5720e-01, -1.1116e+00],\n",
      "         [-4.5601e-01, -1.9784e+00],\n",
      "         ...,\n",
      "         [-2.5720e-01,  6.6312e-01],\n",
      "         [ 1.1344e+00,  4.2924e-01],\n",
      "         [-1.0524e+00,  4.4300e-01]],\n",
      "\n",
      "        [[-1.0096e+00, -1.1037e+00],\n",
      "         [-7.7443e-01, -9.4592e-01],\n",
      "         [-6.9067e-02, -1.2616e+00],\n",
      "         ...,\n",
      "         [ 4.0118e-01,  1.1057e+00],\n",
      "         [-7.7443e-01,  1.1057e+00],\n",
      "         [ 2.0470e+00, -7.8810e-01]],\n",
      "\n",
      "        [[-1.8597e-01, -5.6994e-01],\n",
      "         [-4.5282e-01, -1.7688e-01],\n",
      "         [-2.1874e+00,  1.3954e+00],\n",
      "         ...,\n",
      "         [-7.1968e-01, -9.6301e-01],\n",
      "         [-5.2537e-02, -5.6994e-01],\n",
      "         [ 6.1460e-01, -3.7341e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.8483e-02, -5.3193e-01],\n",
      "         [ 4.5329e-01,  1.7668e+00],\n",
      "         [ 2.3665e+00,  1.7879e-01],\n",
      "         ...,\n",
      "         [-2.4241e-01,  1.1105e-03],\n",
      "         [-1.2860e+00, -1.4203e+00],\n",
      "         [-9.3811e-01, -1.0650e+00]],\n",
      "\n",
      "        [[ 4.2700e-01, -6.3537e-01],\n",
      "         [-6.3718e-01,  1.3891e+00],\n",
      "         [-2.1151e-01,  2.2324e-01],\n",
      "         ...,\n",
      "         [-6.3718e-01, -3.4616e-01],\n",
      "         [-8.5002e-01, -2.0155e-01],\n",
      "         [ 6.3984e-01,  1.3891e+00]],\n",
      "\n",
      "        [[ 6.9869e-01, -1.5099e+00],\n",
      "         [-1.2976e+00,  9.0110e-01],\n",
      "         [ 1.1978e+00, -5.4548e-01],\n",
      "         ...,\n",
      "         [ 6.9869e-01,  2.5817e-01],\n",
      "         [-2.9944e-01, -1.1884e+00],\n",
      "         [-4.2421e-01, -8.6694e-01]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.4350, -1.9008],\n",
      "         [ 0.7975, -0.5431],\n",
      "         [ 0.4350,  1.8021],\n",
      "         ...,\n",
      "         [-1.5587,  0.1975],\n",
      "         [ 0.2537, -1.1602],\n",
      "         [ 0.7975, -0.2962]],\n",
      "\n",
      "        [[ 0.1104, -1.1299],\n",
      "         [ 0.1211,  1.7394],\n",
      "         [-1.9264,  0.9613],\n",
      "         ...,\n",
      "         [-0.2219,  0.1832],\n",
      "         [ 2.0079, -0.5949],\n",
      "         [ 0.1211,  0.9613]],\n",
      "\n",
      "        [[-1.7112,  0.4999],\n",
      "         [-0.8964,  0.4915],\n",
      "         [ 1.2223,  0.2301],\n",
      "         ...,\n",
      "         [ 0.2445, -1.1102],\n",
      "         [-0.4074,  0.8961],\n",
      "         [-0.0815, -1.6498]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2832,  0.5802],\n",
      "         [-0.6896, -0.9051],\n",
      "         [-1.0960, -1.2022],\n",
      "         ...,\n",
      "         [-0.0800, -0.6080],\n",
      "         [-0.2832, -0.6080],\n",
      "         [ 2.5615,  1.9077]],\n",
      "\n",
      "        [[ 1.8801, -0.0858],\n",
      "         [-0.9296, -0.9546],\n",
      "         [ 0.2996,  0.7722],\n",
      "         ...,\n",
      "         [-0.2382,  0.7830],\n",
      "         [ 0.4752, -0.2596],\n",
      "         [ 0.6509,  1.9994]],\n",
      "\n",
      "        [[ 0.7480, -0.0582],\n",
      "         [-0.9349, -1.2730],\n",
      "         [ 0.1870, -1.0706],\n",
      "         ...,\n",
      "         [ 1.6829,  2.3715],\n",
      "         [ 1.1219, -0.6783],\n",
      "         [-0.3740,  0.1443]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.6171,  0.5801],\n",
      "         [-0.6171, -0.0496],\n",
      "         [-0.4646, -0.9311],\n",
      "         ...,\n",
      "         [-0.1291, -1.1830],\n",
      "         [ 0.5215, -0.0496],\n",
      "         [ 1.1722,  0.7060]],\n",
      "\n",
      "        [[-0.2345,  0.8921],\n",
      "         [ 1.6531, -1.7398],\n",
      "         [ 0.4734,  0.6896],\n",
      "         ...,\n",
      "         [-0.7064, -0.1202],\n",
      "         [ 0.7093, -1.9423],\n",
      "         [-2.1220,  1.0945]],\n",
      "\n",
      "        [[ 1.5609, -0.5512],\n",
      "         [-1.9566, -0.1153],\n",
      "         [ 0.4617,  1.1923],\n",
      "         ...,\n",
      "         [ 0.0220, -1.1324],\n",
      "         [-0.1979,  0.0300],\n",
      "         [-0.6376,  0.0300]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6581, -1.3925],\n",
      "         [ 1.4774,  0.2970],\n",
      "         [ 0.8127,  0.5082],\n",
      "         ...,\n",
      "         [-0.1180, -0.1254],\n",
      "         [-0.5168,  1.3529],\n",
      "         [ 0.8127,  0.9305]],\n",
      "\n",
      "        [[-2.0208,  0.6227],\n",
      "         [ 0.9275,  0.0753],\n",
      "         [-0.7573, -0.4836],\n",
      "         ...,\n",
      "         [ 0.5063, -1.7495],\n",
      "         [ 1.0679,  0.2578],\n",
      "         [ 1.0679,  0.6113]],\n",
      "\n",
      "        [[-0.5544,  1.3815],\n",
      "         [-1.0379,  0.3462],\n",
      "         [ 1.6059,  0.3462],\n",
      "         ...,\n",
      "         [ 0.4124, -1.8969],\n",
      "         [-1.0530,  0.3462],\n",
      "         [-1.2645,  0.5187]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.5098, -1.0770],\n",
      "         [-1.3220, -1.0770],\n",
      "         [ 0.1853,  0.0968],\n",
      "         ...,\n",
      "         [-1.6570,  0.0968],\n",
      "         [ 0.1853, -1.3118],\n",
      "         [ 0.6877,  1.4908]],\n",
      "\n",
      "        [[ 0.9626,  0.0669],\n",
      "         [-1.3251, -1.2303],\n",
      "         [ 0.9737,  1.0398],\n",
      "         ...,\n",
      "         [-1.1483, -1.8790],\n",
      "         [-1.1483,  0.0669],\n",
      "         [ 0.7968,  1.3439]],\n",
      "\n",
      "        [[-0.2966, -0.0793],\n",
      "         [-0.5450, -0.0793],\n",
      "         [ 0.4488,  2.3778],\n",
      "         ...,\n",
      "         [ 1.4425, -0.2841],\n",
      "         [ 0.4488, -0.7064],\n",
      "         [-1.7872, -1.7174]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9380,  1.2380],\n",
      "         [ 1.1524,  0.7557],\n",
      "         [ 1.2838, -0.0454],\n",
      "         ...,\n",
      "         [-1.2274, -0.2651],\n",
      "         [-1.3029,  0.7285],\n",
      "         [-1.1081,  1.7040]],\n",
      "\n",
      "        [[-2.2513,  0.9991],\n",
      "         [-1.4315,  1.2642],\n",
      "         [-0.4351,  1.1855],\n",
      "         ...,\n",
      "         [ 0.7918, -1.0232],\n",
      "         [ 0.6257, -1.2538],\n",
      "         [ 0.4380, -1.4313]],\n",
      "\n",
      "        [[ 1.7503, -0.6350],\n",
      "         [ 1.3776, -0.9207],\n",
      "         [ 0.6436, -0.9773],\n",
      "         ...,\n",
      "         [-0.9372,  1.1301],\n",
      "         [-0.2804,  1.4730],\n",
      "         [ 0.5301,  1.5493]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.2563,  2.1080],\n",
      "         [ 1.3041,  1.3873],\n",
      "         [ 1.6746,  0.5323],\n",
      "         ...,\n",
      "         [-1.0424, -0.4549],\n",
      "         [-1.0752, -0.6747],\n",
      "         [-0.5523, -1.3580]],\n",
      "\n",
      "        [[ 1.5046, -0.7078],\n",
      "         [ 1.0970, -1.0127],\n",
      "         [ 0.4100, -1.0845],\n",
      "         ...,\n",
      "         [-0.6812,  1.1012],\n",
      "         [ 0.2500,  1.4446],\n",
      "         [ 1.2542,  1.5331]],\n",
      "\n",
      "        [[-0.0055,  2.0203],\n",
      "         [ 0.9498,  1.4838],\n",
      "         [ 1.2434,  0.7167],\n",
      "         ...,\n",
      "         [-0.9227, -0.8493],\n",
      "         [-1.3282, -0.5928],\n",
      "         [-1.7044, -0.4333]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9973,  2.2879],\n",
      "         [ 1.3421,  1.3212],\n",
      "         [ 1.2531,  0.3166],\n",
      "         ...,\n",
      "         [-1.0790, -0.4307],\n",
      "         [-1.0988, -0.1644],\n",
      "         [-1.2465, -0.0555]],\n",
      "\n",
      "        [[ 0.1511, -1.2173],\n",
      "         [-0.3572, -1.4476],\n",
      "         [-0.9240, -0.8258],\n",
      "         ...,\n",
      "         [ 0.8653,  1.3132],\n",
      "         [ 1.4727,  0.2538],\n",
      "         [ 1.5743, -0.8272]],\n",
      "\n",
      "        [[-0.4050,  0.3233],\n",
      "         [-0.9068,  0.0564],\n",
      "         [-1.2683,  0.3241],\n",
      "         ...,\n",
      "         [ 1.4891, -0.4223],\n",
      "         [ 1.3619, -1.4101],\n",
      "         [ 0.4846, -2.1775]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.0053, -1.7094],\n",
      "         [-0.6655, -1.5002],\n",
      "         [-1.1513, -0.8944],\n",
      "         ...,\n",
      "         [ 1.0828,  0.9277],\n",
      "         [ 1.3631,  0.3867],\n",
      "         [ 1.4543, -0.0456]],\n",
      "\n",
      "        [[ 2.4877, -1.1780],\n",
      "         [ 1.2175, -1.3469],\n",
      "         [-0.0510, -1.1202],\n",
      "         ...,\n",
      "         [-0.3832,  0.7923],\n",
      "         [-0.3070,  1.1415],\n",
      "         [-0.2536,  1.6476]],\n",
      "\n",
      "        [[-1.7339,  0.6226],\n",
      "         [-1.3282,  0.9741],\n",
      "         [-0.8454,  1.0926],\n",
      "         ...,\n",
      "         [ 0.8732, -1.0409],\n",
      "         [ 0.3593, -1.4628],\n",
      "         [-0.4435, -1.6196]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1768, -1.0365],\n",
      "         [ 1.0197, -1.2603],\n",
      "         [ 0.4653, -1.0862],\n",
      "         ...,\n",
      "         [-0.4644,  1.1260],\n",
      "         [ 0.5125,  1.3117],\n",
      "         [ 1.4241,  1.2612]],\n",
      "\n",
      "        [[-1.2709,  1.2195],\n",
      "         [-0.8945,  0.6904],\n",
      "         [-1.1204,  0.3152],\n",
      "         ...,\n",
      "         [ 1.1615, -0.3143],\n",
      "         [ 1.2352, -1.1683],\n",
      "         [ 1.5598, -2.3991]],\n",
      "\n",
      "        [[ 1.8859, -0.4776],\n",
      "         [ 1.3633, -0.7851],\n",
      "         [ 0.8407, -1.0133],\n",
      "         ...,\n",
      "         [-1.0661,  0.7771],\n",
      "         [-0.8498,  1.4226],\n",
      "         [-0.4708,  1.9583]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-2.1500,  1.1361],\n",
      "         [-1.1239,  1.3253],\n",
      "         [-0.0978,  1.1797],\n",
      "         ...,\n",
      "         [ 0.5685, -1.1569],\n",
      "         [-0.1461, -1.1467],\n",
      "         [-0.5845, -1.0476]],\n",
      "\n",
      "        [[-1.3115,  0.4682],\n",
      "         [-1.3290,  1.0203],\n",
      "         [-0.5250,  1.1325],\n",
      "         ...,\n",
      "         [ 0.6671, -1.1378],\n",
      "         [-0.1545, -1.4381],\n",
      "         [-1.1829, -1.4750]],\n",
      "\n",
      "        [[-0.9942, -0.2723],\n",
      "         [-1.7108,  0.4374],\n",
      "         [-1.1030,  0.8031],\n",
      "         ...,\n",
      "         [ 1.1316, -0.9404],\n",
      "         [ 0.8260, -1.5198],\n",
      "         [-0.3880, -1.4553]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8883,  0.7475],\n",
      "         [-0.5979,  0.9274],\n",
      "         [-0.0698,  1.0274],\n",
      "         ...,\n",
      "         [ 0.2965, -1.1509],\n",
      "         [-0.9692, -1.5895],\n",
      "         [-1.8669, -1.3496]],\n",
      "\n",
      "        [[-0.3459, -1.5326],\n",
      "         [-0.8228, -1.1006],\n",
      "         [-1.0596, -0.3807],\n",
      "         ...,\n",
      "         [ 1.2477,  0.4808],\n",
      "         [ 1.4987, -0.2661],\n",
      "         [ 1.3214, -1.2070]],\n",
      "\n",
      "        [[ 1.3153, -0.9972],\n",
      "         [ 0.5465, -1.3472],\n",
      "         [-0.2943, -1.2715],\n",
      "         ...,\n",
      "         [ 0.2151,  1.2871],\n",
      "         [ 0.9708,  1.1801],\n",
      "         [ 1.4895,  0.7444]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.1600,  1.8231],\n",
      "         [ 0.0781,  0.3605],\n",
      "         [ 0.0128, -0.5833],\n",
      "         ...,\n",
      "         [ 0.2101,  1.0558],\n",
      "         [ 1.2103,  0.5305],\n",
      "         [ 2.2526, -0.6901]],\n",
      "\n",
      "        [[ 1.4585, -0.1456],\n",
      "         [ 1.4053, -0.5138],\n",
      "         [ 1.0758, -0.9264],\n",
      "         ...,\n",
      "         [-1.1549,  0.6957],\n",
      "         [-1.1281,  1.3925],\n",
      "         [-0.8378,  2.0634]],\n",
      "\n",
      "        [[-2.3490,  0.7578],\n",
      "         [-1.4003,  1.4152],\n",
      "         [-0.0822,  1.3030],\n",
      "         ...,\n",
      "         [ 0.4112, -1.2052],\n",
      "         [ 0.2845, -1.0769],\n",
      "         [ 0.1986, -1.0403]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.2584, -0.4195],\n",
      "         [ 0.2030, -1.9822],\n",
      "         [-0.3653, -0.8974],\n",
      "         ...,\n",
      "         [ 0.4465,  1.2873],\n",
      "         [ 1.0098, -0.0554],\n",
      "         [ 1.5832, -0.2905]],\n",
      "\n",
      "        [[ 0.8124, -1.1120],\n",
      "         [-0.4637, -1.6912],\n",
      "         [-0.6517, -1.3437],\n",
      "         ...,\n",
      "         [ 1.5415,  0.8499],\n",
      "         [ 1.2681,  1.2047],\n",
      "         [ 0.0775, -0.0695]],\n",
      "\n",
      "        [[-0.5779, -1.0840],\n",
      "         [-1.1928, -1.0778],\n",
      "         [-0.4550,  1.2749],\n",
      "         ...,\n",
      "         [ 1.3895,  0.2956],\n",
      "         [ 0.7747, -0.6960],\n",
      "         [ 0.0369, -1.6691]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.5114, -0.1038],\n",
      "         [-1.1138,  0.3608],\n",
      "         [-1.5154,  0.3608],\n",
      "         ...,\n",
      "         [ 0.7938, -1.8460],\n",
      "         [ 0.6871, -0.6845],\n",
      "         [-1.3146, -1.2653]],\n",
      "\n",
      "        [[-0.6719,  0.4194],\n",
      "         [-0.8529,  0.6680],\n",
      "         [ 0.3555,  1.0741],\n",
      "         ...,\n",
      "         [-0.1115, -0.9150],\n",
      "         [-1.7927,  0.0133],\n",
      "         [-1.0514, -1.8433]],\n",
      "\n",
      "        [[-0.5051,  0.2731],\n",
      "         [ 0.5981,  0.5072],\n",
      "         [ 1.0578,  1.4437],\n",
      "         ...,\n",
      "         [-0.8728, -0.5072],\n",
      "         [-1.5163,  0.4292],\n",
      "         [-1.4244,  0.5072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5753,  0.8382],\n",
      "         [ 1.0670,  0.0338],\n",
      "         [ 1.1622, -0.7260],\n",
      "         ...,\n",
      "         [-1.0473,  1.1736],\n",
      "         [ 0.4800,  1.3605],\n",
      "         [ 0.8703,  1.1231]],\n",
      "\n",
      "        [[ 1.4116,  0.5084],\n",
      "         [ 0.9980, -1.2020],\n",
      "         [ 0.9980, -1.1014],\n",
      "         ...,\n",
      "         [-1.1027,  1.5648],\n",
      "         [ 0.1819,  1.4108],\n",
      "         [ 0.7675,  0.0053]],\n",
      "\n",
      "        [[ 1.1040,  0.2425],\n",
      "         [ 0.6281, -0.8083],\n",
      "         [-0.7255, -1.8468],\n",
      "         ...,\n",
      "         [ 0.1597,  1.1583],\n",
      "         [ 0.6908,  0.6963],\n",
      "         [ 1.6904, -0.4771]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.1999, -1.0006],\n",
      "         [-0.9514, -1.7425],\n",
      "         [-0.3721, -0.4813],\n",
      "         ...,\n",
      "         [ 1.2196, -0.0362],\n",
      "         [ 1.8877,  0.4043],\n",
      "         [ 0.2959, -0.9264]],\n",
      "\n",
      "        [[-0.3374, -0.7308],\n",
      "         [-0.3374, -0.6349],\n",
      "         [-1.5283, -0.3699],\n",
      "         ...,\n",
      "         [ 1.2504, -0.7308],\n",
      "         [ 0.9465, -0.4601],\n",
      "         [-0.8336, -1.6330]],\n",
      "\n",
      "        [[-0.6455, -1.1172],\n",
      "         [-0.9856,  0.3461],\n",
      "         [-0.9856,  0.2429],\n",
      "         ...,\n",
      "         [ 1.8415, -1.2144],\n",
      "         [-0.4188, -0.1457],\n",
      "         [-0.6455, -0.8258]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3596,  1.0057],\n",
      "         [ 0.8024,  0.9371],\n",
      "         [ 1.5555,  0.6041],\n",
      "         ...,\n",
      "         [-1.3368, -0.3261],\n",
      "         [-1.2720,  0.8080],\n",
      "         [-0.1414,  1.1701]],\n",
      "\n",
      "        [[ 0.8782,  1.0647],\n",
      "         [ 1.0889,  0.9466],\n",
      "         [ 1.4027, -0.2939],\n",
      "         ...,\n",
      "         [-1.5428,  0.6235],\n",
      "         [-0.6297,  0.9780],\n",
      "         [ 0.3514,  0.9170]],\n",
      "\n",
      "        [[ 1.0775,  0.8011],\n",
      "         [ 1.2667, -0.0114],\n",
      "         [ 0.8067, -1.5044],\n",
      "         ...,\n",
      "         [-0.5686,  1.1607],\n",
      "         [ 0.2724,  1.3861],\n",
      "         [ 0.7324,  0.7361]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.0659, -0.2435],\n",
      "         [ 1.2095, -1.0306],\n",
      "         [ 0.1147, -1.3816],\n",
      "         ...,\n",
      "         [ 0.1900,  1.6021],\n",
      "         [ 0.8104,  1.3361],\n",
      "         [ 1.1388, -0.2435]],\n",
      "\n",
      "        [[ 2.4562, -1.1523],\n",
      "         [ 1.0539, -1.2304],\n",
      "         [-0.0479, -1.2330],\n",
      "         ...,\n",
      "         [-0.5456, -0.0671],\n",
      "         [-0.9932, -0.1478],\n",
      "         [ 0.2557,  0.9322]],\n",
      "\n",
      "        [[ 0.2298,  0.8708],\n",
      "         [ 1.0235,  1.1012],\n",
      "         [ 1.8173,  0.2453],\n",
      "         ...,\n",
      "         [-1.3995,  0.3152],\n",
      "         [-0.9791,  0.9057],\n",
      "         [-0.1854,  1.1670]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.7032,  0.8563],\n",
      "         [ 1.3395,  0.0889],\n",
      "         [ 0.8897, -0.7460],\n",
      "         ...,\n",
      "         [-1.0449,  0.9631],\n",
      "         [-0.2268,  1.1005],\n",
      "         [ 1.2276,  1.1005]],\n",
      "\n",
      "        [[ 1.1994,  0.6011],\n",
      "         [ 0.8257, -0.2157],\n",
      "         [ 0.6251, -1.2606],\n",
      "         ...,\n",
      "         [-0.3524,  1.2713],\n",
      "         [ 0.7940,  0.9757],\n",
      "         [ 1.2332,  0.6011]],\n",
      "\n",
      "        [[ 1.3411, -0.4476],\n",
      "         [ 0.5493, -0.7859],\n",
      "         [-0.0704, -1.5348],\n",
      "         ...,\n",
      "         [ 0.5859,  1.2884],\n",
      "         [ 0.9280,  0.5055],\n",
      "         [ 1.1023, -0.1732]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.9682, -0.9436],\n",
      "         [-0.3105, -1.2781],\n",
      "         [-0.9538, -1.0410],\n",
      "         ...,\n",
      "         [ 0.9702,  0.7501],\n",
      "         [ 1.1647, -0.1306],\n",
      "         [ 1.2248, -1.0770]],\n",
      "\n",
      "        [[ 0.1500, -0.8946],\n",
      "         [-1.2385, -1.0629],\n",
      "         [-1.6010, -0.1859],\n",
      "         ...,\n",
      "         [ 1.6069, -0.1901],\n",
      "         [ 1.1327, -0.9956],\n",
      "         [-0.2148, -1.0629]],\n",
      "\n",
      "        [[-0.5901, -0.9935],\n",
      "         [-1.2261, -0.2580],\n",
      "         [-1.2616,  0.7144],\n",
      "         ...,\n",
      "         [ 0.9345, -0.8636],\n",
      "         [ 0.2941, -1.4294],\n",
      "         [-0.6588, -0.9286]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9969,  0.7279],\n",
      "         [-0.3670,  1.2217],\n",
      "         [ 0.7816,  1.1209],\n",
      "         ...,\n",
      "         [-0.8225, -0.8834],\n",
      "         [-1.3805, -0.1920],\n",
      "         [-0.9250,  0.9254]],\n",
      "\n",
      "        [[-0.5576,  1.2312],\n",
      "         [ 0.6619,  1.0883],\n",
      "         [ 1.5489,  0.8773],\n",
      "         ...,\n",
      "         [-1.5553, -0.2790],\n",
      "         [-1.1119,  0.4948],\n",
      "         [-0.2227,  0.9125]],\n",
      "\n",
      "        [[ 0.6546,  1.2532],\n",
      "         [ 1.4638,  0.8229],\n",
      "         [ 1.4238, -0.3481],\n",
      "         ...,\n",
      "         [-0.9665,  0.4733],\n",
      "         [-0.7128,  0.9036],\n",
      "         [ 0.1845,  1.1774]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.5147,  0.5433],\n",
      "         [ 1.0856,  0.1756],\n",
      "         [ 0.8724, -0.9766],\n",
      "         ...,\n",
      "         [-0.7882,  1.3836],\n",
      "         [-0.2764,  1.2293],\n",
      "         [ 0.9177,  1.0160]],\n",
      "\n",
      "        [[ 1.8089, -0.5618],\n",
      "         [ 0.9464, -0.8648],\n",
      "         [ 0.0966, -0.8165],\n",
      "         ...,\n",
      "         [-0.1048,  1.4091],\n",
      "         [ 0.6034,  1.6693],\n",
      "         [ 0.8489,  0.2936]],\n",
      "\n",
      "        [[ 1.4218, -0.5761],\n",
      "         [ 0.3589, -1.2232],\n",
      "         [-0.5236, -1.9880],\n",
      "         ...,\n",
      "         [ 0.7981,  1.4203],\n",
      "         [ 1.1119,  0.9497],\n",
      "         [ 0.4805,  0.0710]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9013, -1.2601],\n",
      "         [ 0.3675, -1.4852],\n",
      "         [ 0.3675, -0.8849],\n",
      "         ...,\n",
      "         [ 0.9675,  1.0659],\n",
      "         [ 0.9013,  0.8362],\n",
      "         [ 1.1621, -0.5098]],\n",
      "\n",
      "        [[ 0.8582, -1.1212],\n",
      "         [-0.2030, -1.1784],\n",
      "         [-0.9068, -1.1212],\n",
      "         ...,\n",
      "         [ 1.1567,  0.8208],\n",
      "         [ 1.8015, -0.0948],\n",
      "         [ 0.6224, -0.6634]],\n",
      "\n",
      "        [[ 0.2415, -0.7341],\n",
      "         [-1.3141, -0.8603],\n",
      "         [-1.2037, -0.0902],\n",
      "         ...,\n",
      "         [ 1.7369,  0.2077],\n",
      "         [ 1.2017, -1.1205],\n",
      "         [-0.1867, -1.5499]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.7688, -1.1953],\n",
      "         [-1.4604, -0.4290],\n",
      "         [-1.1905,  0.6574],\n",
      "         ...,\n",
      "         [ 0.8893, -0.6735],\n",
      "         [ 0.4651, -1.0365],\n",
      "         [-0.8073, -1.2382]],\n",
      "\n",
      "        [[-0.7391, -0.5178],\n",
      "         [-1.1739, -0.0906],\n",
      "         [-0.8015,  1.4737],\n",
      "         ...,\n",
      "         [ 0.6006, -1.3389],\n",
      "         [-0.3042, -1.4435],\n",
      "         [-1.5191, -0.4110]],\n",
      "\n",
      "        [[-1.0567,  0.1443],\n",
      "         [-0.6018,  0.7564],\n",
      "         [ 0.1835,  1.3946],\n",
      "         ...,\n",
      "         [-0.3941, -1.4592],\n",
      "         [-1.0869, -0.5280],\n",
      "         [-1.4493,  0.2426]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0469,  0.7997],\n",
      "         [ 1.3107, -0.1202],\n",
      "         [ 0.8751, -0.8945],\n",
      "         ...,\n",
      "         [-0.6638,  1.1664],\n",
      "         [ 0.1803,  1.3346],\n",
      "         [ 0.9987,  0.8254]],\n",
      "\n",
      "        [[ 1.4603,  0.2624],\n",
      "         [ 0.9831, -1.3212],\n",
      "         [ 0.1527, -1.3908],\n",
      "         ...,\n",
      "         [-0.2177,  1.5678],\n",
      "         [ 0.7084,  1.1637],\n",
      "         [ 1.1103,  0.1677]],\n",
      "\n",
      "        [[ 0.9908, -0.4070],\n",
      "         [ 0.4771, -1.4306],\n",
      "         [-0.2276, -1.4789],\n",
      "         ...,\n",
      "         [ 0.4517,  1.2642],\n",
      "         [ 1.1818,  0.6401],\n",
      "         [ 1.3424, -0.4085]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.5701, -1.1122],\n",
      "         [-0.0286, -1.3845],\n",
      "         [-0.8949, -0.7770],\n",
      "         ...,\n",
      "         [ 0.9013,  0.6837],\n",
      "         [ 1.3484, -0.2000],\n",
      "         [ 1.1089, -0.9903]],\n",
      "\n",
      "        [[ 0.1303, -1.3221],\n",
      "         [-0.7505, -1.1134],\n",
      "         [-1.4432, -0.4935],\n",
      "         ...,\n",
      "         [ 1.1946,  0.0532],\n",
      "         [ 1.1579, -0.2912],\n",
      "         [ 0.5340, -1.0811]],\n",
      "\n",
      "        [[-0.7385, -1.5152],\n",
      "         [-1.0693, -0.6590],\n",
      "         [-1.3925,  0.3341],\n",
      "         ...,\n",
      "         [ 1.1494, -0.5584],\n",
      "         [ 0.6133, -0.9031],\n",
      "         [ 0.2439, -1.0015]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5520,  0.9158],\n",
      "         [ 0.8426,  0.1419],\n",
      "         [ 1.4239, -0.3349],\n",
      "         ...,\n",
      "         [-1.2374,  0.4758],\n",
      "         [-0.4623,  1.2843],\n",
      "         [ 0.9425,  1.5422]],\n",
      "\n",
      "        [[ 0.9113,  0.1862],\n",
      "         [ 1.2781, -0.5121],\n",
      "         [ 0.8380, -0.8831],\n",
      "         ...,\n",
      "         [-0.1476,  1.5137],\n",
      "         [ 0.2925,  1.5137],\n",
      "         [ 1.0947,  0.1493]],\n",
      "\n",
      "        [[ 1.2926, -0.5763],\n",
      "         [ 0.4775, -1.0259],\n",
      "         [-0.4029, -1.3852],\n",
      "         ...,\n",
      "         [ 0.6119,  1.5003],\n",
      "         [ 1.0338,  0.6576],\n",
      "         [ 1.1621, -0.4860]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.6467, -1.0852],\n",
      "         [-0.2795, -1.2013],\n",
      "         [-1.2376, -0.7884],\n",
      "         ...,\n",
      "         [ 1.3813,  0.3874],\n",
      "         [ 1.1577, -0.2024],\n",
      "         [ 0.6467, -1.2031]],\n",
      "\n",
      "        [[-0.5445, -1.0203],\n",
      "         [-1.1988, -0.5956],\n",
      "         [-1.3460,  0.1288],\n",
      "         ...,\n",
      "         [ 1.3643, -0.3739],\n",
      "         [ 0.4994, -1.1452],\n",
      "         [-0.6041, -1.3451]],\n",
      "\n",
      "        [[-0.9408, -0.5959],\n",
      "         [-1.3304,  0.5363],\n",
      "         [-0.6948,  1.3297],\n",
      "         ...,\n",
      "         [ 0.4266, -1.0551],\n",
      "         [-0.2594, -1.6543],\n",
      "         [-1.1119, -0.5959]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8793, -0.5139],\n",
      "         [ 0.1431, -1.5229],\n",
      "         [-0.4276, -1.2643],\n",
      "         ...,\n",
      "         [ 1.0729,  1.3377],\n",
      "         [ 1.1367,  0.3541],\n",
      "         [ 1.1666, -0.8593]],\n",
      "\n",
      "        [[ 0.4344, -1.1802],\n",
      "         [-0.6120, -1.2066],\n",
      "         [-1.5543, -0.3051],\n",
      "         ...,\n",
      "         [ 1.3450,  0.3674],\n",
      "         [ 0.7991, -0.7013],\n",
      "         [ 0.4344, -1.1802]],\n",
      "\n",
      "        [[-0.5347, -1.4120],\n",
      "         [-1.1925, -0.7322],\n",
      "         [-1.5332,  0.6230],\n",
      "         ...,\n",
      "         [ 1.3266, -0.3778],\n",
      "         [ 0.6386, -1.0197],\n",
      "         [-0.4333, -1.0910]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.9271, -0.7420],\n",
      "         [-1.3135,  0.2157],\n",
      "         [-0.7701,  1.3921],\n",
      "         ...,\n",
      "         [ 0.8866, -1.3705],\n",
      "         [-0.4272, -1.2945],\n",
      "         [-1.2362, -0.5946]],\n",
      "\n",
      "        [[-1.0980,  0.0971],\n",
      "         [-0.9173,  0.9811],\n",
      "         [-0.0725,  1.5704],\n",
      "         ...,\n",
      "         [-0.3893, -1.2894],\n",
      "         [-0.4755, -1.2500],\n",
      "         [-1.4092,  0.0576]],\n",
      "\n",
      "        [[-1.0114,  0.8253],\n",
      "         [ 0.1050,  1.2014],\n",
      "         [ 0.3932,  0.9936],\n",
      "         ...,\n",
      "         [-1.2572, -1.0241],\n",
      "         [-0.8203, -0.2691],\n",
      "         [-1.0114,  1.3304]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0371,  0.6504],\n",
      "         [ 1.7354, -0.5904],\n",
      "         [ 0.7866, -1.0186],\n",
      "         ...,\n",
      "         [-0.7164,  0.8122],\n",
      "         [ 0.1384,  1.3551],\n",
      "         [ 0.7365,  0.8662]],\n",
      "\n",
      "        [[ 0.8794, -0.3680],\n",
      "         [ 0.9827,  0.0162],\n",
      "         [ 0.4785, -1.9208],\n",
      "         ...,\n",
      "         [-0.0194,  1.1848],\n",
      "         [ 1.0328,  0.3397],\n",
      "         [ 1.1330,  0.3397]],\n",
      "\n",
      "        [[ 0.8857, -1.2635],\n",
      "         [ 0.2549, -1.0649],\n",
      "         [ 0.3732, -1.1311],\n",
      "         ...,\n",
      "         [ 1.0614,  0.6520],\n",
      "         [ 0.6026,  0.9168],\n",
      "         [ 1.0040, -0.4692]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.5110, -0.8718],\n",
      "         [-1.0875, -0.8198],\n",
      "         [-1.1462, -0.8198],\n",
      "         ...,\n",
      "         [ 1.1220,  0.7348],\n",
      "         [ 1.3948, -0.9270],\n",
      "         [ 0.8976, -1.0795]],\n",
      "\n",
      "        [[-0.2935, -1.0841],\n",
      "         [-1.5186, -0.9664],\n",
      "         [-0.9043, -0.1135],\n",
      "         ...,\n",
      "         [ 1.7761,  0.2255],\n",
      "         [ 1.0467, -0.9128],\n",
      "         [-0.1783, -1.3125]],\n",
      "\n",
      "        [[-0.5336, -0.3174],\n",
      "         [-1.5839, -0.3688],\n",
      "         [-1.1826,  0.7783],\n",
      "         ...,\n",
      "         [ 1.2723, -0.6495],\n",
      "         [ 0.1185, -1.5226],\n",
      "         [-0.7844, -1.3001]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6173,  1.0431],\n",
      "         [ 0.2315,  1.3362],\n",
      "         [ 1.2040,  0.4507],\n",
      "         ...,\n",
      "         [-1.2795, -0.5618],\n",
      "         [-1.2461,  0.3872],\n",
      "         [-0.5230,  1.3711]],\n",
      "\n",
      "        [[ 0.0321,  1.1612],\n",
      "         [ 0.9520,  0.7735],\n",
      "         [ 1.5179,  0.0720],\n",
      "         ...,\n",
      "         [-1.2342,  0.2678],\n",
      "         [-0.7890,  0.9054],\n",
      "         [ 0.0024,  1.2552]],\n",
      "\n",
      "        [[ 0.8522,  0.9346],\n",
      "         [ 1.3533,  0.1032],\n",
      "         [ 1.1008, -0.7908],\n",
      "         ...,\n",
      "         [-1.0252,  1.2132],\n",
      "         [ 0.0397,  1.1419],\n",
      "         [ 0.9148,  0.8655]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.0449,  0.3418],\n",
      "         [ 0.7225, -0.9527],\n",
      "         [ 0.5282, -1.4653],\n",
      "         ...,\n",
      "         [-0.2026,  1.2688],\n",
      "         [ 1.1410,  1.4012],\n",
      "         [ 1.1410,  0.6152]],\n",
      "\n",
      "        [[ 0.8929, -0.7349],\n",
      "         [ 0.7871, -1.4474],\n",
      "         [-0.2467, -1.0912],\n",
      "         ...,\n",
      "         [ 0.4137,  1.3033],\n",
      "         [ 1.2058,  0.5261],\n",
      "         [ 1.1346, -0.5103]],\n",
      "\n",
      "        [[ 0.9326, -0.9612],\n",
      "         [-0.2781, -1.2817],\n",
      "         [-1.1188, -1.0658],\n",
      "         ...,\n",
      "         [ 1.0156,  0.8882],\n",
      "         [ 1.4561, -0.5362],\n",
      "         [ 0.7715, -0.7832]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1652,  1.4603],\n",
      "         [ 1.0898,  0.6548],\n",
      "         [ 1.4073, -0.0232],\n",
      "         ...,\n",
      "         [-1.4325,  0.1970],\n",
      "         [-0.8254,  1.0624],\n",
      "         [-0.2822,  1.0894]],\n",
      "\n",
      "        [[ 0.6430,  0.6791],\n",
      "         [ 1.4903,  0.1762],\n",
      "         [ 1.4563, -0.7960],\n",
      "         ...,\n",
      "         [-1.0876,  1.4523],\n",
      "         [-0.4442,  0.9829],\n",
      "         [ 0.5071,  1.0458]],\n",
      "\n",
      "        [[ 1.0542,  0.5449],\n",
      "         [ 1.4475, -0.6246],\n",
      "         [ 0.4765, -0.9995],\n",
      "         ...,\n",
      "         [-0.5260,  0.9623],\n",
      "         [ 0.2630,  1.4504],\n",
      "         [ 1.2340,  0.9222]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.4192,  0.2448],\n",
      "         [ 1.0764, -1.2395],\n",
      "         [ 0.1240, -1.5901],\n",
      "         ...,\n",
      "         [ 0.3193,  1.2992],\n",
      "         [ 0.6193,  0.5105],\n",
      "         [ 0.9645,  0.0750]],\n",
      "\n",
      "        [[ 0.8514, -0.9237],\n",
      "         [ 0.3427, -1.2904],\n",
      "         [-0.8314, -0.9212],\n",
      "         ...,\n",
      "         [ 0.7780,  1.3069],\n",
      "         [ 1.2428,  0.2355],\n",
      "         [ 1.2819, -0.8411]],\n",
      "\n",
      "        [[ 0.0794, -1.2058],\n",
      "         [-0.8130, -1.2026],\n",
      "         [-1.1955, -0.8973],\n",
      "         ...,\n",
      "         [ 1.3118,  0.7752],\n",
      "         [ 1.3118, -0.3441],\n",
      "         [ 1.0568, -0.9514]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8738,  0.8277],\n",
      "         [-0.3299,  1.3978],\n",
      "         [ 0.7800,  1.1980],\n",
      "         ...,\n",
      "         [-0.7959, -1.1537],\n",
      "         [-1.2551, -0.3094],\n",
      "         [-1.1721,  0.7301]],\n",
      "\n",
      "        [[-0.1040,  1.2090],\n",
      "         [ 0.6441,  0.9737],\n",
      "         [ 1.3889,  0.5538],\n",
      "         ...,\n",
      "         [-1.2390, -0.3041],\n",
      "         [-1.3680,  0.5848],\n",
      "         [-0.5167,  1.1845]],\n",
      "\n",
      "        [[ 0.3936,  0.9416],\n",
      "         [ 1.1654,  0.7907],\n",
      "         [ 1.4989, -0.0914],\n",
      "         ...,\n",
      "         [-1.3593,  0.4920],\n",
      "         [-0.8422,  1.2718],\n",
      "         [ 0.3163,  1.1429]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.0509,  0.8553],\n",
      "         [ 1.4055, -0.2711],\n",
      "         [ 0.7949, -0.7125],\n",
      "         ...,\n",
      "         [-1.0830,  1.1036],\n",
      "         [ 0.3147,  1.2737],\n",
      "         [ 0.7726,  1.0039]],\n",
      "\n",
      "        [[ 1.2171,  0.2365],\n",
      "         [ 1.0589, -1.0810],\n",
      "         [ 0.1857, -1.5176],\n",
      "         ...,\n",
      "         [-0.0340,  1.3860],\n",
      "         [ 0.6601,  1.2135],\n",
      "         [ 1.2395,  0.2869]],\n",
      "\n",
      "        [[ 1.0137, -0.3713],\n",
      "         [ 0.4987, -1.2753],\n",
      "         [-0.6995, -1.4290],\n",
      "         ...,\n",
      "         [ 0.6255,  1.4917],\n",
      "         [ 1.4294,  0.3775],\n",
      "         [ 1.0870, -0.4748]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9626, -0.1223],\n",
      "         [-0.8981,  0.8632],\n",
      "         [-0.0917,  1.3755],\n",
      "         ...,\n",
      "         [-0.0958, -1.4395],\n",
      "         [-0.7731, -0.9639],\n",
      "         [-1.5754, -0.2687]],\n",
      "\n",
      "        [[-0.8950,  0.7210],\n",
      "         [-0.5050,  1.0227],\n",
      "         [ 0.3705,  1.2907],\n",
      "         ...,\n",
      "         [-0.9640, -1.4059],\n",
      "         [-1.0270, -0.5281],\n",
      "         [-1.2525,  0.5184]],\n",
      "\n",
      "        [[-0.5421,  1.1557],\n",
      "         [ 0.8358,  1.2130],\n",
      "         [ 1.0634,  0.8565],\n",
      "         ...,\n",
      "         [-1.3644, -0.7320],\n",
      "         [-1.5284,  0.2414],\n",
      "         [-0.7390,  1.0080]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.6119e-01,  1.3296e+00],\n",
      "         [ 1.1168e+00,  1.0301e+00],\n",
      "         [ 1.3177e+00, -1.6778e-01],\n",
      "         ...,\n",
      "         [-1.2797e+00, -1.3715e-01],\n",
      "         [-8.9916e-01,  1.1408e+00],\n",
      "         [-4.2243e-01,  1.0046e+00]],\n",
      "\n",
      "        [[ 5.5893e-01,  6.8297e-01],\n",
      "         [ 1.3385e+00,  2.2665e-01],\n",
      "         [ 1.4015e+00, -4.9809e-01],\n",
      "         ...,\n",
      "         [-1.1607e+00,  8.7422e-01],\n",
      "         [-3.1611e-01,  1.4346e+00],\n",
      "         [ 7.2338e-01,  1.1930e+00]],\n",
      "\n",
      "        [[ 1.0508e+00,  3.0302e-01],\n",
      "         [ 1.0491e+00, -3.8672e-01],\n",
      "         [ 1.7587e-01, -1.5057e+00],\n",
      "         ...,\n",
      "         [-5.5120e-01,  1.0251e+00],\n",
      "         [ 7.9731e-01,  1.4220e+00],\n",
      "         [ 1.3325e+00,  7.0357e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.4450e-01,  8.9537e-01],\n",
      "         [ 1.4514e+00, -3.3588e-04],\n",
      "         [ 1.0694e+00, -8.0535e-01],\n",
      "         ...,\n",
      "         [-8.8686e-01,  1.0051e+00],\n",
      "         [-1.4315e-01,  1.3634e+00],\n",
      "         [ 8.4450e-01,  1.0029e+00]],\n",
      "\n",
      "        [[ 1.1960e+00,  1.8419e-01],\n",
      "         [ 1.1949e+00, -7.1337e-01],\n",
      "         [ 3.8271e-01, -1.3851e+00],\n",
      "         ...,\n",
      "         [-1.9555e-01,  1.3486e+00],\n",
      "         [ 6.3322e-01,  1.2514e+00],\n",
      "         [ 1.1795e+00,  2.7898e-01]],\n",
      "\n",
      "        [[ 1.1437e+00, -7.5436e-01],\n",
      "         [ 5.2898e-01, -1.2561e+00],\n",
      "         [-4.7464e-01, -1.2936e+00],\n",
      "         ...,\n",
      "         [ 5.8438e-01,  1.2233e+00],\n",
      "         [ 1.1800e+00,  5.0473e-01],\n",
      "         [ 1.1608e+00, -4.0536e-01]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.5419, -1.2352],\n",
      "         [-0.1290, -1.2838],\n",
      "         [-1.0987, -0.6378],\n",
      "         ...,\n",
      "         [ 1.3108,  0.5983],\n",
      "         [ 1.2711, -0.2947],\n",
      "         [ 0.7110, -0.9882]],\n",
      "\n",
      "        [[-0.2221, -1.2753],\n",
      "         [-1.1921, -0.5103],\n",
      "         [-1.3460,  0.0386],\n",
      "         ...,\n",
      "         [ 1.4947, -0.3648],\n",
      "         [ 0.6623, -1.0456],\n",
      "         [ 0.0370, -1.2597]],\n",
      "\n",
      "        [[-0.8969, -0.9808],\n",
      "         [-1.3973, -0.1044],\n",
      "         [-1.0948,  0.8233],\n",
      "         ...,\n",
      "         [ 1.0952, -1.0389],\n",
      "         [ 0.1897, -1.4024],\n",
      "         [-0.8467, -0.7791]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2404,  0.4315],\n",
      "         [-0.1946,  1.3352],\n",
      "         [ 0.4867,  1.3352],\n",
      "         ...,\n",
      "         [-0.4812, -1.1702],\n",
      "         [-1.2027, -0.4775],\n",
      "         [-1.2806,  0.0419]],\n",
      "\n",
      "        [[-0.5957,  0.7399],\n",
      "         [-0.4578,  1.4157],\n",
      "         [ 0.9047,  0.8567],\n",
      "         ...,\n",
      "         [-0.7750, -1.0490],\n",
      "         [-1.6080,  0.3051],\n",
      "         [-0.8578,  1.0977]],\n",
      "\n",
      "        [[-0.2702,  1.0423],\n",
      "         [ 0.5620,  1.1289],\n",
      "         [ 1.3540,  0.9501],\n",
      "         ...,\n",
      "         [-0.9535, -0.7433],\n",
      "         [-1.5564,  0.3297],\n",
      "         [-1.0646,  1.0423]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.4628,  1.0304],\n",
      "         [ 0.9645,  0.8386],\n",
      "         [ 1.4325,  0.2634],\n",
      "         ...,\n",
      "         [-1.5531,  0.1716],\n",
      "         [-0.9771,  0.7468],\n",
      "         [-0.2549,  1.4458]],\n",
      "\n",
      "        [[ 0.9796,  0.9495],\n",
      "         [ 1.1200,  0.3789],\n",
      "         [ 1.1529, -0.5668],\n",
      "         ...,\n",
      "         [-1.1941,  0.6059],\n",
      "         [-0.2816,  1.2022],\n",
      "         [ 0.4203,  1.2969]],\n",
      "\n",
      "        [[ 1.3057,  0.5203],\n",
      "         [ 1.3348, -0.3183],\n",
      "         [ 0.6198, -1.0942],\n",
      "         ...,\n",
      "         [-0.7752,  1.2680],\n",
      "         [ 0.1574,  1.5246],\n",
      "         [ 0.9346,  0.7790]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5715, -0.8518],\n",
      "         [-1.4871, -1.0795],\n",
      "         [-1.2582,  0.6283],\n",
      "         ...,\n",
      "         [ 0.5729,  0.6212],\n",
      "         [ 0.9091, -0.7379],\n",
      "         [ 1.1452, -0.9727]],\n",
      "\n",
      "        [[ 0.5480, -0.2463],\n",
      "         [-1.4053, -1.3886],\n",
      "         [-1.3977,  0.2297],\n",
      "         ...,\n",
      "         [ 1.5209, -0.3475],\n",
      "         [ 1.2700,  0.3248],\n",
      "         [-0.5465, -1.5790]],\n",
      "\n",
      "        [[-0.0051, -1.2473],\n",
      "         [-0.5137, -0.8443],\n",
      "         [-0.7108, -0.4413],\n",
      "         ...,\n",
      "         [ 1.1138,  0.2791],\n",
      "         [-0.2022, -0.5219],\n",
      "         [-1.0159, -1.0055]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.4236, -0.2102],\n",
      "         [-1.0646,  0.3468],\n",
      "         [-1.3850,  1.5355],\n",
      "         ...,\n",
      "         [ 0.9334, -1.2209],\n",
      "         [-0.7491, -1.4965],\n",
      "         [-0.9844, -0.3939]],\n",
      "\n",
      "        [[-0.9490,  0.3286],\n",
      "         [-0.8822,  1.0731],\n",
      "         [ 0.4971,  0.8821],\n",
      "         ...,\n",
      "         [-0.1984, -1.6087],\n",
      "         [-1.0747, -0.7979],\n",
      "         [-1.5777,  0.3286]],\n",
      "\n",
      "        [[-0.9651,  0.2799],\n",
      "         [-0.3658,  1.3981],\n",
      "         [ 1.2833,  0.9594],\n",
      "         ...,\n",
      "         [-1.2338, -1.3313],\n",
      "         [-1.2957, -0.6480],\n",
      "         [-0.6964,  1.2738]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0433,  1.4541],\n",
      "         [ 0.8080,  0.9903],\n",
      "         [ 1.2208,  0.1056],\n",
      "         ...,\n",
      "         [-1.5799, -0.1760],\n",
      "         [-1.1656,  0.7488],\n",
      "         [-0.1894,  1.1684]],\n",
      "\n",
      "        [[ 0.5782,  1.1630],\n",
      "         [ 1.4052,  0.2590],\n",
      "         [ 1.2185, -0.5646],\n",
      "         ...,\n",
      "         [-1.2250,  0.7650],\n",
      "         [-0.4161,  1.2245],\n",
      "         [ 0.8063,  1.1027]],\n",
      "\n",
      "        [[ 1.1920,  0.3418],\n",
      "         [ 1.2328, -0.5424],\n",
      "         [ 0.4146, -1.2277],\n",
      "         ...,\n",
      "         [-0.4763,  1.4827],\n",
      "         [ 0.5828,  1.1081],\n",
      "         [ 1.1729,  0.4990]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 1.0448e+00, -4.4006e-01],\n",
      "         [ 6.6213e-01, -1.2844e+00],\n",
      "         [-1.0440e-01, -1.4985e+00],\n",
      "         ...,\n",
      "         [ 3.9785e-01,  1.2947e+00],\n",
      "         [ 1.0855e+00,  7.7427e-01],\n",
      "         [ 1.2744e+00, -3.5468e-01]],\n",
      "\n",
      "        [[ 7.5470e-01, -1.1516e+00],\n",
      "         [-4.7378e-02, -1.2863e+00],\n",
      "         [-1.0760e+00, -9.7436e-01],\n",
      "         ...,\n",
      "         [ 1.1293e+00,  6.7163e-01],\n",
      "         [ 1.3340e+00, -2.0235e-01],\n",
      "         [ 8.3709e-01, -8.8090e-01]],\n",
      "\n",
      "        [[-2.0733e-01, -1.3390e+00],\n",
      "         [-1.0347e+00, -7.0682e-01],\n",
      "         [-1.3605e+00, -2.1091e-01],\n",
      "         ...,\n",
      "         [ 1.4502e+00,  7.2296e-02],\n",
      "         [ 7.9591e-01, -9.3984e-01],\n",
      "         [ 2.5067e-01, -1.2625e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7047e-09, -1.2478e+00],\n",
      "         [-7.4726e-01, -1.1712e+00],\n",
      "         [-1.1394e+00, -5.7688e-01],\n",
      "         ...,\n",
      "         [ 1.4649e+00,  5.3277e-01],\n",
      "         [ 9.4702e-01, -4.7009e-01],\n",
      "         [ 1.6030e-01, -1.2106e+00]],\n",
      "\n",
      "        [[-3.1956e-01, -1.4814e+00],\n",
      "         [-1.4172e+00, -4.3633e-01],\n",
      "         [-1.4529e+00,  5.3910e-01],\n",
      "         ...,\n",
      "         [ 1.2794e+00, -4.4068e-01],\n",
      "         [ 5.5715e-01, -1.2746e+00],\n",
      "         [-5.4527e-01, -9.9590e-01]],\n",
      "\n",
      "        [[-1.3809e+00, -5.5449e-01],\n",
      "         [-1.2981e+00,  3.4131e-01],\n",
      "         [-5.2117e-01,  7.6130e-01],\n",
      "         ...,\n",
      "         [ 7.6227e-01, -9.8246e-01],\n",
      "         [-3.6774e-01, -1.6603e+00],\n",
      "         [-1.0302e+00, -5.9703e-01]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.3324,  0.1337],\n",
      "         [-0.5448,  1.1516],\n",
      "         [ 0.0178,  1.4409],\n",
      "         ...,\n",
      "         [-0.2893, -1.6176],\n",
      "         [-1.1472, -0.8866],\n",
      "         [-1.1472,  0.0244]],\n",
      "\n",
      "        [[-1.7293,  0.5217],\n",
      "         [ 0.3952,  1.2152],\n",
      "         [ 1.6668,  1.7253],\n",
      "         ...,\n",
      "         [-0.7121, -1.2040],\n",
      "         [-0.2935, -1.3315],\n",
      "         [-0.1187, -0.6301]],\n",
      "\n",
      "        [[-1.0777,  0.0681],\n",
      "         [-0.8227, -0.3320],\n",
      "         [-0.0579,  1.8386],\n",
      "         ...,\n",
      "         [ 0.4520, -1.7024],\n",
      "         [-0.4031, -0.8767],\n",
      "         [-1.9275,  0.0681]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1876, -0.4761],\n",
      "         [ 0.7264, -0.7451],\n",
      "         [ 0.0361, -1.4916],\n",
      "         ...,\n",
      "         [ 0.5488,  1.4607],\n",
      "         [ 1.0014,  0.6537],\n",
      "         [ 0.9585, -0.3685]],\n",
      "\n",
      "        [[ 1.8723, -1.0647],\n",
      "         [ 0.1345, -1.4647],\n",
      "         [-0.9852, -1.0583],\n",
      "         ...,\n",
      "         [ 0.5738,  0.6622],\n",
      "         [ 0.9471,  0.4114],\n",
      "         [ 0.6322, -0.4552]],\n",
      "\n",
      "        [[ 0.4062, -0.8817],\n",
      "         [-0.9581, -1.4423],\n",
      "         [-1.0162, -0.3147],\n",
      "         ...,\n",
      "         [ 1.5262,  0.1492],\n",
      "         [ 1.3363, -0.2664],\n",
      "         [ 0.2201, -1.2426]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.7787, -1.0246],\n",
      "         [-1.1444, -0.6315],\n",
      "         [-1.0212,  0.4356],\n",
      "         ...,\n",
      "         [ 1.6233, -0.1892],\n",
      "         [ 0.7610, -1.2528],\n",
      "         [-0.6555, -1.4739]],\n",
      "\n",
      "        [[-1.4112, -0.5020],\n",
      "         [-1.1409,  0.6183],\n",
      "         [-0.7354,  0.3724],\n",
      "         ...,\n",
      "         [ 1.0851, -1.2592],\n",
      "         [ 0.3417, -1.3178],\n",
      "         [-1.2802, -1.1890]],\n",
      "\n",
      "        [[-1.0040, -0.8253],\n",
      "         [-0.9481,  0.5810],\n",
      "         [-0.7772,  1.3905],\n",
      "         ...,\n",
      "         [ 0.7786, -1.3480],\n",
      "         [-0.5051, -1.0473],\n",
      "         [-1.3388, -0.7512]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3433, -0.3798],\n",
      "         [ 0.7593, -1.2226],\n",
      "         [-0.0620, -1.7244],\n",
      "         ...,\n",
      "         [ 0.1497,  1.3469],\n",
      "         [ 1.1080,  1.0313],\n",
      "         [ 1.1037, -0.1584]],\n",
      "\n",
      "        [[ 0.8743, -1.2565],\n",
      "         [ 0.0984, -1.1153],\n",
      "         [-0.8280, -0.6523],\n",
      "         ...,\n",
      "         [ 1.3607,  0.8560],\n",
      "         [ 1.0990, -0.5508],\n",
      "         [ 0.5779, -1.0448]],\n",
      "\n",
      "        [[-0.2246, -1.2435],\n",
      "         [-1.2712, -0.6738],\n",
      "         [-1.4865,  0.0772],\n",
      "         ...,\n",
      "         [ 1.6069, -0.5678],\n",
      "         [ 0.6448, -1.1681],\n",
      "         [-0.1346, -0.9021]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.3574, -0.6194],\n",
      "         [-1.4853, -0.0883],\n",
      "         [-0.6936,  0.8971],\n",
      "         ...,\n",
      "         [ 0.7868, -1.1583],\n",
      "         [-0.0379, -1.0736],\n",
      "         [-0.6956, -0.3757]],\n",
      "\n",
      "        [[-0.8888,  0.1897],\n",
      "         [-0.8449,  0.9536],\n",
      "         [ 0.1912,  1.7965],\n",
      "         ...,\n",
      "         [-0.5994, -0.8473],\n",
      "         [-1.1395, -0.8042],\n",
      "         [-1.2583,  0.2663]],\n",
      "\n",
      "        [[-0.3945,  1.2680],\n",
      "         [ 0.2160,  1.1653],\n",
      "         [ 0.9947,  0.9567],\n",
      "         ...,\n",
      "         [-1.5233, -0.5255],\n",
      "         [-1.2628, -0.1662],\n",
      "         [-0.3918,  1.2680]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6122, -1.2056],\n",
      "         [-1.4449, -0.4788],\n",
      "         [-1.1943,  0.5693],\n",
      "         ...,\n",
      "         [ 1.1766, -0.6184],\n",
      "         [ 0.4345, -1.1282],\n",
      "         [-0.2749, -1.1803]],\n",
      "\n",
      "        [[-1.0858, -0.5253],\n",
      "         [-1.2679,  0.2864],\n",
      "         [-0.7446,  1.2742],\n",
      "         ...,\n",
      "         [ 0.4133, -1.3134],\n",
      "         [-0.5050, -1.3406],\n",
      "         [-0.8117, -0.7014]],\n",
      "\n",
      "        [[-1.0795,  0.4030],\n",
      "         [-0.8796,  0.9874],\n",
      "         [ 0.3656,  1.6046],\n",
      "         ...,\n",
      "         [-0.3773, -1.4254],\n",
      "         [-0.8831, -0.7424],\n",
      "         [-1.3625,  0.1844]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.7249,  0.8889],\n",
      "         [-0.2114,  1.2356],\n",
      "         [ 1.0773,  1.0110],\n",
      "         ...,\n",
      "         [-1.2122, -0.6199],\n",
      "         [-1.1780,  0.1345],\n",
      "         [-1.0471,  0.6703]],\n",
      "\n",
      "        [[-0.1054,  1.2369],\n",
      "         [ 0.7784,  1.1044],\n",
      "         [ 1.3909,  0.2762],\n",
      "         ...,\n",
      "         [-1.3736, -0.0489],\n",
      "         [-1.0278,  0.6427],\n",
      "         [ 0.0483,  1.2059]],\n",
      "\n",
      "        [[ 0.4029,  1.1061],\n",
      "         [ 1.3954,  0.3351],\n",
      "         [ 1.1100, -1.0257],\n",
      "         ...,\n",
      "         [-1.2247,  0.8658],\n",
      "         [-0.3488,  1.4577],\n",
      "         [ 0.6014,  0.6168]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.0644, -0.5721],\n",
      "         [ 0.6517, -1.4003],\n",
      "         [-0.3313, -1.0753],\n",
      "         ...,\n",
      "         [ 0.2517,  1.1972],\n",
      "         [ 1.2006,  0.2561],\n",
      "         [ 1.2325, -0.8609]],\n",
      "\n",
      "        [[ 0.8724, -1.0697],\n",
      "         [-0.6404, -1.1268],\n",
      "         [-1.4631, -0.5485],\n",
      "         ...,\n",
      "         [ 1.3781,  0.2372],\n",
      "         [ 1.0522, -0.6436],\n",
      "         [ 0.3666, -1.0983]],\n",
      "\n",
      "        [[-0.7453, -1.0455],\n",
      "         [-1.2557, -0.5249],\n",
      "         [-0.8529,  0.3774],\n",
      "         ...,\n",
      "         [ 0.9371, -0.6681],\n",
      "         [ 0.7196, -1.2233],\n",
      "         [-0.4912, -1.2190]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.1319, -0.5236],\n",
      "         [-1.3171,  0.8430],\n",
      "         [-1.0032,  1.0365],\n",
      "         ...,\n",
      "         [ 0.5795, -1.3424],\n",
      "         [ 0.0181, -1.5705],\n",
      "         [-0.8843, -0.8841]],\n",
      "\n",
      "        [[-1.0984,  0.3778],\n",
      "         [-0.7155,  1.1062],\n",
      "         [ 0.1812,  0.8249],\n",
      "         ...,\n",
      "         [-0.4211, -1.5787],\n",
      "         [-0.9367, -0.4968],\n",
      "         [-1.3979,  0.3429]],\n",
      "\n",
      "        [[-1.1182,  0.8511],\n",
      "         [ 0.2013,  1.1663],\n",
      "         [ 1.1410,  1.0486],\n",
      "         ...,\n",
      "         [-1.0650, -0.9152],\n",
      "         [-1.4137,  0.3004],\n",
      "         [-0.7658,  0.8511]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6140, -0.1479],\n",
      "         [-1.9583, -0.5235],\n",
      "         [-1.5908, -0.5235],\n",
      "         ...,\n",
      "         [ 0.8590, -0.1479],\n",
      "         [ 0.3690,  0.5915],\n",
      "         [ 0.3613, -1.8380]],\n",
      "\n",
      "        [[-1.5221,  0.2229],\n",
      "         [ 0.4384,  0.5182],\n",
      "         [-1.3042, -0.3963],\n",
      "         ...,\n",
      "         [ 0.4248, -2.0727],\n",
      "         [-1.0864,  0.2134],\n",
      "         [-0.2151,  1.2802]],\n",
      "\n",
      "        [[-0.0786,  0.3296],\n",
      "         [ 0.8185,  0.5114],\n",
      "         [ 0.1194,  0.4234],\n",
      "         ...,\n",
      "         [-0.7653,  1.3618],\n",
      "         [-2.5532,  0.8926],\n",
      "         [ 0.0204,  0.6111]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 0.6087,  0.8038],\n",
      "         [ 1.1616,  1.3950],\n",
      "         [ 1.7145, -0.2814],\n",
      "         ...,\n",
      "         [-0.3127, -0.2739],\n",
      "         [-1.2342,  1.4025],\n",
      "         [-0.1284,  0.5568]],\n",
      "\n",
      "        [[ 1.8127, -0.7000],\n",
      "         [ 0.3356, -1.1738],\n",
      "         [ 1.4415, -0.5164],\n",
      "         ...,\n",
      "         [-0.8940,  1.9472],\n",
      "         [-0.2830,  0.8161],\n",
      "         [ 0.2119,  0.1528]],\n",
      "\n",
      "        [[ 0.8056, -0.4305],\n",
      "         [ 0.7137, -1.1498],\n",
      "         [-0.6705, -0.8780],\n",
      "         ...,\n",
      "         [-0.2271,  1.9315],\n",
      "         [ 1.0652,  0.7477],\n",
      "         [ 1.0598, -1.2405]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.8374, -1.2757],\n",
      "         [-0.0759,  0.1579],\n",
      "         [-0.4355, -1.6564],\n",
      "         ...,\n",
      "         [ 1.3911,  1.1866],\n",
      "         [ 0.4721,  0.2794],\n",
      "         [ 1.0200, -0.7492]],\n",
      "\n",
      "        [[ 1.0757, -0.9609],\n",
      "         [-0.1487, -0.3852],\n",
      "         [-0.6952,  0.6382],\n",
      "         ...,\n",
      "         [ 0.8474, -0.2786],\n",
      "         [-0.6952, -1.1741],\n",
      "         [-1.2556, -1.1812]],\n",
      "\n",
      "        [[-0.0793, -0.2365],\n",
      "         [-1.6151,  1.4334],\n",
      "         [-1.6908,  0.9899],\n",
      "         ...,\n",
      "         [ 0.9664, -1.5560],\n",
      "         [ 0.0773, -1.2823],\n",
      "         [-0.7259, -0.0613]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.2478,  0.8095],\n",
      "         [-0.2077,  0.7289],\n",
      "         [ 0.8908,  1.1797],\n",
      "         ...,\n",
      "         [-0.2660, -1.3211],\n",
      "         [-1.0316, -0.4052],\n",
      "         [-1.6907,  0.8095]],\n",
      "\n",
      "        [[-0.3479,  0.5196],\n",
      "         [ 0.4296,  1.0353],\n",
      "         [ 1.0670,  0.8796],\n",
      "         ...,\n",
      "         [-1.7171,  0.1109],\n",
      "         [-1.3725,  0.6753],\n",
      "         [ 0.0393,  1.1942]],\n",
      "\n",
      "        [[ 0.7384,  1.0710],\n",
      "         [ 1.4001,  0.6085],\n",
      "         [ 0.7356, -0.4160],\n",
      "         ...,\n",
      "         [-1.2107,  0.4382],\n",
      "         [-0.3691,  1.4273],\n",
      "         [ 0.3840,  1.1065]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.9980,  0.5122],\n",
      "         [ 1.2619, -0.2832],\n",
      "         [ 0.5970, -1.0746],\n",
      "         ...,\n",
      "         [-0.5292,  1.5662],\n",
      "         [ 0.4349,  1.1486],\n",
      "         [ 1.2972,  0.5759]],\n",
      "\n",
      "        [[ 1.2459, -0.2750],\n",
      "         [ 0.6151, -1.1284],\n",
      "         [-0.4428, -1.1924],\n",
      "         ...,\n",
      "         [ 0.4775,  1.4659],\n",
      "         [ 1.3049,  0.4739],\n",
      "         [ 1.0154, -0.3113]],\n",
      "\n",
      "        [[ 0.7572, -0.8772],\n",
      "         [-0.6416, -1.4333],\n",
      "         [-1.1610, -0.8176],\n",
      "         ...,\n",
      "         [ 1.1994,  0.7471],\n",
      "         [ 1.3606, -0.2615],\n",
      "         [ 0.6475, -0.9597]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.3091, -1.1742],\n",
      "         [-1.1212, -0.8752],\n",
      "         [-1.2819,  0.4413],\n",
      "         ...,\n",
      "         [ 1.1582, -0.1834],\n",
      "         [ 0.7654, -0.9592],\n",
      "         [-0.4740, -1.4412]],\n",
      "\n",
      "        [[-0.8997, -0.8925],\n",
      "         [-1.3209,  0.1260],\n",
      "         [-1.1326,  1.0645],\n",
      "         ...,\n",
      "         [ 1.0530, -1.2107],\n",
      "         [-0.1348, -1.3642],\n",
      "         [-0.9525, -0.7113]],\n",
      "\n",
      "        [[-0.8932,  0.0414],\n",
      "         [-1.0655,  0.7066],\n",
      "         [-0.3936,  1.1939],\n",
      "         ...,\n",
      "         [ 0.0206, -1.7557],\n",
      "         [-0.9196, -0.8820],\n",
      "         [-1.3153,  0.0927]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1039, -0.4363],\n",
      "         [-1.4609, -0.0777],\n",
      "         [-1.0955,  1.1671],\n",
      "         ...,\n",
      "         [ 0.1976, -1.1511],\n",
      "         [ 0.4225, -1.1867],\n",
      "         [-0.6541, -1.3270]],\n",
      "\n",
      "        [[-1.3343, -0.4266],\n",
      "         [-1.0041,  0.8877],\n",
      "         [-0.2462,  1.1480],\n",
      "         ...,\n",
      "         [ 0.3583, -1.6454],\n",
      "         [-1.0041, -0.8482],\n",
      "         [-1.1014, -0.1663]],\n",
      "\n",
      "        [[-1.1414,  0.6303],\n",
      "         [-0.4544,  1.0368],\n",
      "         [ 0.8623,  1.3331],\n",
      "         ...,\n",
      "         [-0.6298, -1.1314],\n",
      "         [-1.4921, -0.7280],\n",
      "         [-1.0842,  0.3813]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.6123,  1.0769],\n",
      "         [ 0.5710,  1.3120],\n",
      "         [ 0.9212,  1.1945],\n",
      "         ...,\n",
      "         [-1.6739, -0.6181],\n",
      "         [-0.9072, -0.0190],\n",
      "         [-1.0841,  0.5309]],\n",
      "\n",
      "        [[-0.7723,  0.9628],\n",
      "         [ 0.4306,  1.3953],\n",
      "         [ 2.1734,  0.5147],\n",
      "         ...,\n",
      "         [-0.9978, -0.9075],\n",
      "         [-0.8270,  0.4017],\n",
      "         [-0.3383,  1.3330]],\n",
      "\n",
      "        [[-0.1577,  1.1394],\n",
      "         [ 1.1254,  0.6742],\n",
      "         [ 1.4575,  0.0815],\n",
      "         ...,\n",
      "         [-1.0002,  0.2173],\n",
      "         [-1.5561,  1.2752],\n",
      "         [ 0.2863,  1.0076]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4295, -1.2346],\n",
      "         [-0.7601, -1.0593],\n",
      "         [-1.4979, -0.4868],\n",
      "         ...,\n",
      "         [ 1.4652, -0.0772],\n",
      "         [ 1.0135, -0.5813],\n",
      "         [ 0.4047, -1.1045]],\n",
      "\n",
      "        [[-0.7302, -1.1579],\n",
      "         [-1.3518, -0.4580],\n",
      "         [-1.2753,  0.3518],\n",
      "         ...,\n",
      "         [ 1.4186, -0.7579],\n",
      "         [ 0.3676, -1.2283],\n",
      "         [-0.4288, -1.0016]],\n",
      "\n",
      "        [[-1.1432, -0.7189],\n",
      "         [-1.1382,  0.6069],\n",
      "         [-0.8705,  1.3908],\n",
      "         ...,\n",
      "         [ 0.3450, -1.1846],\n",
      "         [-0.5329, -1.3979],\n",
      "         [-0.9553, -0.5310]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-1.0753,  0.3371],\n",
      "         [-0.6373,  1.3720],\n",
      "         [ 0.2352,  1.3141],\n",
      "         ...,\n",
      "         [-0.3988, -1.4029],\n",
      "         [-1.0770, -0.5048],\n",
      "         [-1.2934,  0.4494]],\n",
      "\n",
      "        [[-0.6269,  1.1150],\n",
      "         [ 0.3010,  1.1427],\n",
      "         [ 1.2995,  1.0562],\n",
      "         ...,\n",
      "         [-1.2622, -0.5142],\n",
      "         [-1.3265,  0.2312],\n",
      "         [-0.7951,  0.7294]],\n",
      "\n",
      "        [[ 0.4261,  1.4209],\n",
      "         [ 1.1333,  0.7446],\n",
      "         [ 1.3772, -0.2667],\n",
      "         ...,\n",
      "         [-1.8086,  0.6519],\n",
      "         [-1.1014,  0.6498],\n",
      "         [ 0.1778,  1.0838]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3941, -1.4888],\n",
      "         [-0.9659, -0.9477],\n",
      "         [-1.2322, -0.2704],\n",
      "         ...,\n",
      "         [ 1.3989,  0.3990],\n",
      "         [ 1.3883, -0.5225],\n",
      "         [ 0.9564, -1.3263]],\n",
      "\n",
      "        [[ 0.6645, -1.5480],\n",
      "         [-0.3106, -1.5204],\n",
      "         [-1.1576, -0.9677],\n",
      "         ...,\n",
      "         [ 1.0127,  0.9607],\n",
      "         [ 1.2554,  0.5110],\n",
      "         [ 1.3316, -0.0910]],\n",
      "\n",
      "        [[ 1.8071, -0.1172],\n",
      "         [ 0.2746, -0.7196],\n",
      "         [-0.9318, -0.6110],\n",
      "         ...,\n",
      "         [ 1.1606, -0.0892],\n",
      "         [ 0.5399, -1.0093],\n",
      "         [-1.2302, -1.6891]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.7578, -1.2256],\n",
      "         [-1.0974, -0.8663],\n",
      "         [-1.2373,  0.0198],\n",
      "         ...,\n",
      "         [ 1.3411,  0.2117],\n",
      "         [ 1.3468, -0.7898],\n",
      "         [ 0.9880, -1.5579]],\n",
      "\n",
      "        [[ 1.1228, -1.4453],\n",
      "         [ 0.1209, -1.4608],\n",
      "         [-0.8126, -1.0694],\n",
      "         ...,\n",
      "         [ 0.5734,  1.1798],\n",
      "         [ 1.2219,  0.9297],\n",
      "         [ 1.4485,  0.3981]],\n",
      "\n",
      "        [[ 1.7654, -0.0437],\n",
      "         [ 1.0692, -0.9489],\n",
      "         [ 0.2761, -1.3645],\n",
      "         ...,\n",
      "         [-0.4616,  1.1613],\n",
      "         [ 0.3640,  1.3600],\n",
      "         [ 0.9278,  1.1204]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.1210,  1.0635],\n",
      "         [ 1.3188,  0.3645],\n",
      "         [ 1.2400, -0.3983],\n",
      "         ...,\n",
      "         [-1.3295,  0.3266],\n",
      "         [-1.1130,  1.1164],\n",
      "         [-0.5666,  1.6205]],\n",
      "\n",
      "        [[-0.1284,  1.6304],\n",
      "         [ 0.8536,  1.1655],\n",
      "         [ 1.4219,  0.2278],\n",
      "         ...,\n",
      "         [-1.3290, -0.3203],\n",
      "         [-1.1678,  0.4418],\n",
      "         [-0.6211,  0.9956]],\n",
      "\n",
      "        [[ 0.3165,  1.5436],\n",
      "         [ 1.1189,  1.0112],\n",
      "         [ 1.3541,  0.1838],\n",
      "         ...,\n",
      "         [-1.3454, -0.3598],\n",
      "         [-1.1934,  0.6784],\n",
      "         [-0.8756,  1.1120]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[-0.1319,  1.3233],\n",
      "         [ 0.8395,  1.1638],\n",
      "         [ 1.3530,  0.3864],\n",
      "         ...,\n",
      "         [-1.3807, -0.3417],\n",
      "         [-1.3646,  0.4982],\n",
      "         [-0.7044,  1.1803]],\n",
      "\n",
      "        [[-0.5031,  1.5640],\n",
      "         [ 0.4241,  1.4899],\n",
      "         [ 0.9028,  1.0636],\n",
      "         ...,\n",
      "         [-0.7134, -1.1386],\n",
      "         [-1.2934, -0.9107],\n",
      "         [-1.8279, -0.5398]],\n",
      "\n",
      "        [[-1.2636, -1.1704],\n",
      "         [-1.3311, -0.4045],\n",
      "         [-1.0795,  0.3068],\n",
      "         ...,\n",
      "         [ 1.2340, -0.0119],\n",
      "         [ 1.2497, -0.8047],\n",
      "         [ 0.9802, -1.9061]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9617, -0.2792],\n",
      "         [ 1.3866, -0.8450],\n",
      "         [ 0.6235, -1.2563],\n",
      "         ...,\n",
      "         [-0.7306,  1.1223],\n",
      "         [-0.3201,  1.3160],\n",
      "         [ 0.2458,  1.4519]],\n",
      "\n",
      "        [[-0.0738,  2.0579],\n",
      "         [ 0.9794,  1.1990],\n",
      "         [ 1.3406,  0.5679],\n",
      "         ...,\n",
      "         [-0.2925, -0.8790],\n",
      "         [-1.1498, -1.0687],\n",
      "         [-2.2054, -1.1439]],\n",
      "\n",
      "        [[-1.0540, -0.9572],\n",
      "         [-1.2136, -0.4433],\n",
      "         [-1.1741,  0.3950],\n",
      "         ...,\n",
      "         [ 1.2884, -0.1713],\n",
      "         [ 1.2504, -1.0096],\n",
      "         [ 0.8391, -1.8461]]], device='cuda:0')\n",
      "reconstructed_x.shape: torch.Size([100, 10, 2])\n",
      "X_chunk.shape: tensor([[[ 9.0099e-01, -1.5359e+00],\n",
      "         [ 4.0250e-04, -1.4818e+00],\n",
      "         [-8.6698e-01, -1.1158e+00],\n",
      "         ...,\n",
      "         [ 2.8517e-01,  1.0522e+00],\n",
      "         [ 1.1687e+00,  9.9807e-01],\n",
      "         [ 1.8438e+00,  8.3039e-01]],\n",
      "\n",
      "        [[ 8.6904e-01,  1.5029e+00],\n",
      "         [ 1.0360e+00,  9.9259e-01],\n",
      "         [ 1.0696e+00,  2.2803e-01],\n",
      "         ...,\n",
      "         [-1.0375e+00, -7.2957e-01],\n",
      "         [-1.4925e+00,  4.1266e-01],\n",
      "         [-1.4738e+00,  1.3921e+00]],\n",
      "\n",
      "        [[-1.0368e+00,  1.1201e+00],\n",
      "         [-2.2772e-01,  1.4505e+00],\n",
      "         [ 5.0888e-01,  1.2187e+00],\n",
      "         ...,\n",
      "         [-5.1427e-01, -1.2890e+00],\n",
      "         [-1.1688e+00, -8.7545e-01],\n",
      "         [-1.5706e+00, -1.9342e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.0982e-01, -1.5464e+00],\n",
      "         [-3.3227e-01, -1.4140e+00],\n",
      "         [-1.0602e+00, -1.0196e+00],\n",
      "         ...,\n",
      "         [ 1.0230e+00,  9.9497e-01],\n",
      "         [ 1.4327e+00,  3.9709e-01],\n",
      "         [ 1.2905e+00, -2.5654e-01]],\n",
      "\n",
      "        [[ 9.6666e-02, -1.1206e+00],\n",
      "         [-4.2918e-01, -1.2105e+00],\n",
      "         [-9.9594e-01, -8.2572e-01],\n",
      "         ...,\n",
      "         [ 1.0913e+00,  9.9622e-01],\n",
      "         [ 1.4325e+00, -9.9584e-02],\n",
      "         [ 1.4385e+00, -1.1860e+00]],\n",
      "\n",
      "        [[ 1.2647e+00, -1.1036e+00],\n",
      "         [ 4.7318e-01, -1.3751e+00],\n",
      "         [-3.3096e-01, -1.2607e+00],\n",
      "         ...,\n",
      "         [ 2.0888e-01,  1.2381e+00],\n",
      "         [ 9.1997e-01,  1.0999e+00],\n",
      "         [ 1.6014e+00,  6.7692e-01]]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 329\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_chunk.shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, X_chunk)\n\u001b[1;32m    328\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 329\u001b[0m reconstructed_x, z_mean, z_log_var \u001b[38;5;241m=\u001b[39m \u001b[43mvae_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreconstructed_x.shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, reconstructed_x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m#loss = vae_loss(reconstructed_x, X_chunk, z_mean, z_log_var)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 259\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    258\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 259\u001b[0m     z, z_mean, z_log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     reconstructed_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reconstructed_x, z_mean, z_log_var\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 229\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    227\u001b[0m z_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_mean(h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    228\u001b[0m z_log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_log_var(h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 229\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampling3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use _sampling3/sampling\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z, z_mean, z_log_var\n",
      "Cell \u001b[0;32mIn[1], line 213\u001b[0m, in \u001b[0;36mEncoder._sampling3\u001b[0;34m(self, z_mean, device)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sampling3\u001b[39m(\u001b[38;5;28mself\u001b[39m, z_mean, device):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# Assuming process_latent_variables(z) is adapted for PyTorch\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     z_mean \u001b[38;5;241m=\u001b[39m z_mean\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 213\u001b[0m     z_mean_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_latent_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(z_mean_transformed) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_std\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z_mean_transformed\n",
      "Cell \u001b[0;32mIn[1], line 182\u001b[0m, in \u001b[0;36mprocess_latent_variables\u001b[0;34m(z, device)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mTransform latent variables using MEC.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Assuming 'z' is a batch of latent variables\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m z_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mapply_mec_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_transformed\n",
      "Cell \u001b[0;32mIn[1], line 172\u001b[0m, in \u001b[0;36mapply_mec_to_data\u001b[0;34m(data, device, num_bins, latent_dim)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_sample\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Process each sample in the batch\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m transformed_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([process_sample(sample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m    173\u001b[0m transformed_batch \u001b[38;5;241m=\u001b[39m transformed_batch\u001b[38;5;241m.\u001b[39mfloat() \n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_batch\n",
      "Cell \u001b[0;32mIn[1], line 172\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformed_sample\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Process each sample in the batch\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m transformed_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mprocess_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data])\n\u001b[1;32m    173\u001b[0m transformed_batch \u001b[38;5;241m=\u001b[39m transformed_batch\u001b[38;5;241m.\u001b[39mfloat() \n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_batch\n",
      "Cell \u001b[0;32mIn[1], line 159\u001b[0m, in \u001b[0;36mapply_mec_to_data.<locals>.process_sample\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m    156\u001b[0m sample_histogram \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhistc(sample, bins\u001b[38;5;241m=\u001b[39mnum_bins, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mmin_val, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mmax_val)\n\u001b[1;32m    157\u001b[0m sample_histogram \u001b[38;5;241m=\u001b[39m sample_histogram\u001b[38;5;241m.\u001b[39mfloat() \u001b[38;5;241m/\u001b[39m sample_histogram\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m--> 159\u001b[0m mec_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mmec_kocaoglu_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_histogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_histogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Flatten the 2D to 1D and adjust to match the latent_dim\u001b[39;00m\n\u001b[1;32m    162\u001b[0m transformed_sample \u001b[38;5;241m=\u001b[39m mec_transformed\u001b[38;5;241m.\u001b[39mflatten()\n",
      "Cell \u001b[0;32mIn[1], line 141\u001b[0m, in \u001b[0;36mmec_kocaoglu_np\u001b[0;34m(p, q, device)\u001b[0m\n\u001b[1;32m    139\u001b[0m update_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([r, r])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(a_i):\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m update_values[i]\n\u001b[1;32m    142\u001b[0m     J[index, i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m update_values[i]\n\u001b[1;32m    143\u001b[0m r \u001b[38;5;241m=\u001b[39m r_updated\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Layer, MultiHeadAttention\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Masking, Input, Lambda\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import mse\n",
    "from numpy.fft import fft\n",
    "from scipy.stats import skew, kurtosis \n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import struct\n",
    "from numpy.fft import fft\n",
    "from scipy.stats import skew, kurtosis\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Check if CUDA is available and set the device to GPU if it is, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ComplexNumbersDataset(Dataset):\n",
    "    def __init__(self, filepath, sequence_length, max_samples=None, for_training=True, process_method='data1'):\n",
    "        self.filepath = filepath\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_samples = max_samples\n",
    "        self.for_training = for_training\n",
    "        self.process_method = process_method\n",
    "        self.samples = self.load_samples()\n",
    "        self.samples_per_sequence = self.sequence_length\n",
    "        #self.samples_per_sequence = self.sequence_length if for_training else 1\n",
    "\n",
    "    def load_samples(self):\n",
    "        samples = []\n",
    "        with open(self.filepath, 'rb') as binary_file:\n",
    "            while True:\n",
    "                if self.max_samples and len(samples) >= self.max_samples:\n",
    "                    break\n",
    "                binary_data = binary_file.read(8)\n",
    "                if not binary_data:\n",
    "                    break\n",
    "                decoded_data = struct.unpack('ff', binary_data)\n",
    "                if decoded_data[0] == 0 and decoded_data[1] == 0:\n",
    "                    continue\n",
    "                samples.append(f\"{decoded_data[0]}+{decoded_data[1]}j\")\n",
    "        return samples\n",
    "\n",
    "    def process_data1(self, sequence_samples):\n",
    "        #print('sequence_samples:', sequence_samples)\n",
    "        #print('len(sequence_samples):', len(sequence_samples))\n",
    "        real_parts = []\n",
    "        imag_parts = []\n",
    "        for sample in sequence_samples:\n",
    "            # Remove potential unwanted characters (spaces, etc.)\n",
    "            sample = sample.replace(\" \", \"\").replace(\"+-\", \"-\")\n",
    "            try:\n",
    "                c = complex(sample)\n",
    "                real_parts.append(c.real)\n",
    "                imag_parts.append(c.imag)\n",
    "            except ValueError:\n",
    "                print(f\"Failed to convert: {sample}\")  # This will show which string failed\n",
    "                raise\n",
    "        real_parts = np.array(real_parts)\n",
    "        imag_parts = np.array(imag_parts)\n",
    "        # Normalize\n",
    "        real_parts = (real_parts - np.mean(real_parts)) / np.std(real_parts)\n",
    "        imag_parts = (imag_parts - np.mean(imag_parts)) / np.std(imag_parts)\n",
    "\n",
    "        # Combining real and imaginary parts\n",
    "        X = np.stack((real_parts, imag_parts), axis=1)  # Shape: (sequence_length, 2)\n",
    "        return torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "    def process_data2(self, sequence_samples):\n",
    "        samples_array = np.array([complex(sample) for sample in sequence_samples], dtype=np.complex64)\n",
    "        samples_fft = fft(samples_array)\n",
    "        real_parts = np.real(samples_fft)\n",
    "        imag_parts = np.imag(samples_fft)\n",
    "        \n",
    "        # Normalization\n",
    "        epsilon = 1e-10\n",
    "        real_parts_normalized = (real_parts - np.mean(real_parts)) / (np.std(real_parts) + epsilon)\n",
    "        imag_parts_normalized = (imag_parts - np.mean(imag_parts)) / (np.std(imag_parts) + epsilon)\n",
    "        \n",
    "        # Feature extraction\n",
    "        features = np.column_stack((\n",
    "            np.mean(real_parts_normalized), np.std(real_parts_normalized), skew(real_parts_normalized),\n",
    "            kurtosis(real_parts_normalized), np.mean(imag_parts_normalized), np.std(imag_parts_normalized),\n",
    "            skew(imag_parts_normalized), kurtosis(imag_parts_normalized)\n",
    "        ))\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32).reshape(self.samples_per_sequence, -1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples) // self.samples_per_sequence\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = idx * self.samples_per_sequence\n",
    "        end_idx = start_idx + self.samples_per_sequence\n",
    "        sequence_samples = self.samples[start_idx:end_idx]\n",
    "        \n",
    "        if self.process_method == 'data1':\n",
    "            X = self.process_data1(sequence_samples)\n",
    "        elif self.process_method == 'data2':\n",
    "            X = self.process_data2(sequence_samples)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid process method specified.\")\n",
    "        if self.for_training:\n",
    "            return X, X\n",
    "        else:\n",
    "            return X\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "def mec_kocaoglu_np(p, q, device):\n",
    "    \"\"\"\n",
    "    Compute the joint distribution matrix with minimal entropy between two given distributions in PyTorch.\n",
    "    \"\"\"\n",
    "    p = p.float() / p.sum()\n",
    "    q = q.float() / q.sum()\n",
    "    J = torch.zeros(q.size(0), p.size(0), dtype=torch.float64, device=device)\n",
    "    M = torch.stack([p, q], dim=0)\n",
    "    r = torch.min(torch.max(M, dim=1).values)\n",
    "\n",
    "    while r > 0:\n",
    "        a_i = torch.argmax(M, dim=1)\n",
    "        r_updated = torch.min(torch.max(M, dim=1).values)\n",
    "        update_values = torch.stack([r, r])\n",
    "        for i, index in enumerate(a_i):\n",
    "            M[i, index] -= update_values[i]\n",
    "            J[index, i] += update_values[i]\n",
    "        r = r_updated\n",
    "\n",
    "    return J\n",
    "def apply_mec_to_data(data, device, num_bins=10, latent_dim=50):\n",
    "    \"\"\"\n",
    "    Apply the MEC transformation to each sample in the data.\n",
    "    \"\"\"\n",
    "    def process_sample(sample):\n",
    "        # Find the min and max values in the sample and convert them to Python scalars\n",
    "        min_val = torch.min(sample).item()\n",
    "        max_val = torch.max(sample).item()\n",
    "        \n",
    "        # Now min_val and max_val are Python numbers, suitable for torch.histc()\n",
    "        sample_histogram = torch.histc(sample, bins=num_bins, min=min_val, max=max_val)\n",
    "        sample_histogram = sample_histogram.float() / sample_histogram.sum()\n",
    "\n",
    "        mec_transformed = mec_kocaoglu_np(sample_histogram, sample_histogram, device)\n",
    "\n",
    "        # Flatten the 2D to 1D and adjust to match the latent_dim\n",
    "        transformed_sample = mec_transformed.flatten()\n",
    "        if transformed_sample.size(0) > latent_dim:\n",
    "            transformed_sample = transformed_sample[:latent_dim]\n",
    "        else:\n",
    "            padding = torch.zeros(latent_dim - transformed_sample.size(0), dtype=torch.float64)\n",
    "            transformed_sample = torch.cat([transformed_sample, padding], dim=0)\n",
    "\n",
    "        return transformed_sample\n",
    "\n",
    "    # Process each sample in the batch\n",
    "    transformed_batch = torch.stack([process_sample(sample) for sample in data])\n",
    "    transformed_batch = transformed_batch.float() \n",
    "\n",
    "    return transformed_batch\n",
    "\n",
    "def process_latent_variables(z, device):\n",
    "    \"\"\"\n",
    "    Transform latent variables using MEC.\n",
    "    \"\"\"\n",
    "    # Assuming 'z' is a batch of latent variables\n",
    "    z_transformed = apply_mec_to_data(z, device=device)\n",
    "    return z_transformed\n",
    "\n",
    "#self Attention LSTM Autoencoder Model\n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        self.multihead_attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=num_heads)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # PyTorch's MultiheadAttention expects inputs of shape (sequence_length, batch_size, embed_size)\n",
    "        inputs = inputs.permute(1, 0, 2)\n",
    "        attn_output, _ = self.multihead_attention(inputs, inputs, inputs)\n",
    "        return attn_output.permute(1, 0, 2)  # Return to original shape (batch_size, sequence_length, embed_size)\n",
    "\n",
    "# Variational Autoencoder (VAE) Class\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, sequence_length, feature_dim, intermediate_dim, latent_dim, epsilon_std=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=feature_dim, hidden_size=intermediate_dim, batch_first=True)\n",
    "        self.self_attention = SelfAttentionLayer(embed_size=intermediate_dim, num_heads=2)  # Ensure compatibility\n",
    "        #self.self_attention = SelfAttentionLayer(num_heads=2, key_dim=intermediate_dim)\n",
    "        self.lstm2 = nn.LSTM(input_size=intermediate_dim, hidden_size=50, batch_first=True)\n",
    "        self.z_mean = nn.Linear(in_features=50, out_features=latent_dim)\n",
    "        self.z_log_var = nn.Linear(in_features=50, out_features=latent_dim)\n",
    "        self.epsilon_std = epsilon_std\n",
    "\n",
    "    def _sampling3(self, z_mean, device):\n",
    "        # Assuming process_latent_variables(z) is adapted for PyTorch\n",
    "        z_mean = z_mean.to(device)\n",
    "        z_mean_transformed = process_latent_variables(z_mean, device)\n",
    "        eps = torch.randn_like(z_mean_transformed) * self.epsilon_std\n",
    "        return z_mean_transformed\n",
    "    \n",
    "    def _sampling(self, z_mean, z_log_var):\n",
    "        # Standard sampling function, kept for compatibility\n",
    "        std = torch.exp(0.5 * z_log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return z_mean + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.self_attention(x)\n",
    "        x, (h_n, _) = self.lstm2(x)\n",
    "        z_mean = self.z_mean(h_n[-1])\n",
    "        z_log_var = self.z_log_var(h_n[-1])\n",
    "        z = self._sampling3(z_mean, device)  # Use _sampling3/sampling\n",
    "        return z, z_mean, z_log_var\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, sequence_length, feature_dim, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm1 = nn.LSTM(input_size=latent_dim, hidden_size=50, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=50, hidden_size=100, batch_first=True)\n",
    "        self.output_layer = nn.Linear(in_features=100, out_features=feature_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Repeat 'z' for 'sequence_length' times\n",
    "        # Assuming 'z' shape is [batch_size, latent_dim], we first unsqueeze it to add a sequence length dimension\n",
    "        # Then repeat across this dimension\n",
    "        z = z.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "        \n",
    "        # Now 'z' shape is [batch_size, sequence_length, latent_dim], suitable for LSTM input\n",
    "        z, _ = self.lstm1(z)\n",
    "        z, _ = self.lstm2(z)\n",
    "        return torch.sigmoid(self.output_layer(z))\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, sequence_length, feature_dim, intermediate_dim, latent_dim, epsilon_std=0.1):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(sequence_length, feature_dim, intermediate_dim, latent_dim, epsilon_std)\n",
    "        self.decoder = Decoder(sequence_length, feature_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        z, z_mean, z_log_var = self.encoder(x)\n",
    "        reconstructed_x = self.decoder(z)\n",
    "        return reconstructed_x, z_mean, z_log_var\n",
    "\n",
    "def vae_loss(reconstructed_x, x, z_mean, z_log_var):\n",
    "    reconstruction_loss = F.mse_loss(reconstructed_x, x, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "    return reconstruction_loss + kl_divergence\n",
    "\n",
    "\n",
    "# Instantiate and Compile the VAE\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# Instantiate the VAE\n",
    "sequence_length = 10\n",
    "feature_dim = 2\n",
    "intermediate_dim = 100\n",
    "latent_dim = 50\n",
    "epsilon_std = 0.1\n",
    "\n",
    "#vae_model = VAE(sequence_length, feature_dim, intermediate_dim, latent_dim, epsilon_std)\n",
    "vae_model = VAE(sequence_length, feature_dim, intermediate_dim, latent_dim, epsilon_std).to(device)\n",
    "\n",
    "optimizer = optim.Adam(vae_model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "# Model Training\n",
    "batch_size = 100\n",
    "max_train_samples = 4000000\n",
    "train_steps = max_train_samples // (batch_size * sequence_length)\n",
    "max_samples = 4000000  # Maximum samples to read (or None to read all)\n",
    "max_test_samples = 4000000\n",
    "\n",
    "pure_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/pure_data/pure_iq_samples_*.csv'\n",
    "mixed_file_pattern = '/home/mreza/5G accelerator/ID_MEC/data generator/mixed_data/mixed_iq_samples_*.csv'\n",
    "pure_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_pure'\n",
    "mixed_file_new = '/home/mreza/5G accelerator/ID_MEC/data generator/New Data-Collection/rx_IQ_MIX'\n",
    "pure_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_no_jamming_0924.dat'\n",
    "mixed_file_old = '/home/mreza/5G accelerator/IQ_samples/data collected/5G_DL_IQ_with_periodic_jamming_0928_02.dat'\n",
    "\n",
    "# Creating dataset instances for training and validation/testing\n",
    "train_gen_instance  = ComplexNumbersDataset(filepath=pure_file_new, \n",
    "                                            sequence_length=sequence_length, \n",
    "                                            max_samples=max_train_samples, for_training=True, \n",
    "                                            process_method='data1')\n",
    "\n",
    "combined_gen_instance = ComplexNumbersDataset(filepath=mixed_file_new, \n",
    "                                              sequence_length=sequence_length, \n",
    "                                              max_samples=max_samples, for_training=False, \n",
    "                                              process_method='data1')\n",
    "\n",
    "# Creating DataLoader instances for batching\n",
    "train_gen_instance = DataLoader(train_gen_instance, batch_size=batch_size, shuffle=False, \n",
    "                                drop_last=True)\n",
    "combined_gen_instance = DataLoader(combined_gen_instance, batch_size=batch_size, shuffle=False, \n",
    "                                   drop_last=True)\n",
    "\n",
    "# Custom training loop in PyTorch\n",
    "num_epochs = 6\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    vae_model.train()  # Set the model to training mode\n",
    "    \n",
    "    step = 0  # Initialize step counter if you need it for logging, etc.\n",
    "    for X_chunk, Y_chunk in train_gen_instance:\n",
    "        X_chunk, Y_chunk = X_chunk.to(device), Y_chunk.to(device)\n",
    "        print('X_chunk.shape:', X_chunk)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_x, z_mean, z_log_var = vae_model(X_chunk)\n",
    "        print('reconstructed_x.shape:', reconstructed_x.shape)\n",
    "        #loss = vae_loss(reconstructed_x, X_chunk, z_mean, z_log_var)\n",
    "        loss = F.mse_loss(reconstructed_x, X_chunk, reduction='sum')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step + 1}/{train_steps}, Loss: {loss}\")\n",
    "        step += 1  # Increment step counter\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "num_predictions = 200  # or any other large number\n",
    "print(f\"Number of predictions to be performed: {num_predictions}\")\n",
    "reconstruction_errors = []\n",
    "all_X_chunk_test = []\n",
    "all_X_chunk_pred = []\n",
    "all_intrusion_flags = []\n",
    "vae_model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Get an iterator from your DataLoader\n",
    "combined_gen_iterator = iter(combined_gen_instance)\n",
    "\n",
    "try:\n",
    "    for _ in range(num_predictions):\n",
    "        print(f\"Prediction number: {_}\")\n",
    "        X_chunk_test = next(combined_gen_iterator)  # Getting the batch\n",
    "\n",
    "        # Ensure X_chunk_test is on the correct device\n",
    "        X_chunk_test = X_chunk_test.to(device)\n",
    "\n",
    "        with torch.no_grad():  # Inference without gradient calculation\n",
    "            X_chunk_pred, _, _ = vae_model(X_chunk_test)\n",
    "\n",
    "        chunk_errors = torch.mean((X_chunk_test - X_chunk_pred) ** 2, axis=1)\n",
    "        reconstruction_errors.extend(chunk_errors.cpu().numpy())        \n",
    "        all_X_chunk_test.append(X_chunk_test)\n",
    "        all_X_chunk_pred.append(X_chunk_pred)\n",
    "except StopIteration:\n",
    "    print(\"All samples processed.\")\n",
    "\n",
    "reconstruction_error = np.array(reconstruction_errors)\n",
    "# Further processing...\n",
    "\n",
    "\n",
    "\n",
    "#reconstruction_error = np.array(reconstruction_errors)\n",
    "print('reconstruction_error.shape:', reconstruction_error.shape)\n",
    "print('Number of NaNs in reconstruction_error:', np.isnan(reconstruction_error).sum())\n",
    "max_error_per_sequence = reconstruction_error.max(axis=1) # Max error for each sequence\n",
    "#print('max_error_per_sequence:', max_error_per_sequence)\n",
    "\n",
    "print('max_error_per_sequence.shape:', max_error_per_sequence.shape)\n",
    "\n",
    "threshold1 = np.percentile(max_error_per_sequence, 98)\n",
    "print('threshold1:', threshold1)\n",
    "threshold2 = np.percentile(reconstruction_error, 95)\n",
    "print('threshold percentile:', threshold2)\n",
    "\n",
    "is_intrusion_detected = max_error_per_sequence > threshold1  # Boolean array for sequences\n",
    "print('len(is_intrusion_detected):', len(is_intrusion_detected))\n",
    "print('is_intrusion_detected.shape:', is_intrusion_detected.shape)\n",
    "\n",
    "#is_intrusion_detected2 = error_per_sequence > threshold1\n",
    "\n",
    "num_total_sequences = len(max_error_per_sequence)\n",
    "num_total_sequences2 = num_predictions * batch_size - num_predictions\n",
    "print('num_total_sequences:', num_total_sequences)\n",
    "print('num_total_sequences2:', num_total_sequences2)\n",
    "\n",
    "#---------------------------------------finish 111-----------------------------------\n",
    "flat_error_per_sequence = max_error_per_sequence.flatten()\n",
    "#flat_error_per_sequence2 = error_per_sequence.flatten()\n",
    "# Determine if intrusion detected for each sequence\n",
    "for error in flat_error_per_sequence:\n",
    "    all_intrusion_flags.append(error > threshold1)\n",
    "all_X_chunk_test = [x.cpu() for x in all_X_chunk_test]\n",
    "all_X_chunk_pred = [x.cpu() for x in all_X_chunk_pred]\n",
    "\n",
    "all_X_chunk_test = np.concatenate(all_X_chunk_test, axis=0)\n",
    "all_X_chunk_pred = np.concatenate(all_X_chunk_pred, axis=0)\n",
    "\n",
    "#save_path = 'C:\\\\Users\\\\Mohammadreza\\\\Desktop\\\\My Class\\\\Proj-DC\\\\My Works\\\\My Papers\\\\intrusion\\\\data generator\\\\intrusion_detected'\n",
    "#plot_with_intrusions8(all_X_chunk_test, all_X_chunk_pred, all_intrusion_flags, sequence_length, save_path)\n",
    "\n",
    "jamming_detected = reconstruction_error > threshold1\n",
    "#train_gen_instance.close()\n",
    "#combined_gen_instance.close()\n",
    "#Table\n",
    "flattened_jamming_detected = jamming_detected.flatten()\n",
    "real_part_detected = jamming_detected[:, 0]\n",
    "imag_part_detected = jamming_detected[:, 1]\n",
    "\n",
    "real_true_count = np.sum(real_part_detected)\n",
    "real_false_count = len(real_part_detected) - real_true_count\n",
    "\n",
    "imag_true_count = np.sum(imag_part_detected)\n",
    "imag_false_count = len(imag_part_detected) - imag_true_count\n",
    "# Overall\n",
    "overall_true_count = np.sum(flattened_jamming_detected)\n",
    "overall_false_count = len(flattened_jamming_detected) - overall_true_count\n",
    "# Table-DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Part': ['Real', 'Imaginary', 'Overall'],\n",
    "    'True Count': [real_true_count, imag_true_count, overall_true_count],\n",
    "    'False Count': [real_false_count, imag_false_count, overall_false_count]\n",
    "})\n",
    "print(df)\n",
    "num_jamming_detected = np.sum(jamming_detected)\n",
    "print(f\"Number of jamming sequences detected: {num_jamming_detected} out of {len(flattened_jamming_detected)} sequences\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "# Ensure n sequences are available\n",
    "n = min(n, len(X_chunk_test) - sequence_index)\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays\n",
    "original_sample_np = X_chunk_test[sequence_index:sequence_index + n].detach().cpu().numpy()\n",
    "reconstructed_sample_np = X_chunk_pred[sequence_index:sequence_index + n].detach().cpu().numpy()\n",
    "\n",
    "# Since your data is 3-dimensional (batch, sequence, features), you'll want to concatenate along the sequence axis (axis=1)\n",
    "original_sample_concat = np.concatenate(original_sample_np, axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(reconstructed_sample_np, axis=0)\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')  # Assuming first feature is the real part\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')  # Assuming first feature is the real part\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dd4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of sequences to plot together\n",
    "n = 4  # Change this to desired number of sequences\n",
    "\n",
    "# Ensure that we have enough samples for the desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays and concatenate selected sequences\n",
    "original_sample_concat = np.concatenate(X_chunk_test[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "\n",
    "# Plot concatenated sequences for n = 4\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample_concat[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Repeat for n = 2\n",
    "n = 2  # Change this to a different desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample_concat = np.concatenate(X_chunk_test[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "reconstructed_sample_concat = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n].cpu().numpy(), axis=0)\n",
    "\n",
    "# Plot concatenated sequences for n = 2\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample_concat[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample_concat[:, 1], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample_concat[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4348bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error_flat, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "# plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a86f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstruction_error to 1D\n",
    "reconstruction_error_flat = reconstruction_error.flatten()\n",
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error_flat, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "# plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4005b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_chunk_test and X_chunk_pred are tensors on the GPU\n",
    "# First, move the selected samples to CPU and convert to NumPy for plotting\n",
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index].cpu().numpy()\n",
    "reconstructed_sample = X_chunk_pred[sample_index].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae0391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch tensors to NumPy arrays before calculating means\n",
    "avg_real = np.mean(X_chunk_test.cpu().numpy(), axis=1)[:, 0]\n",
    "avg_imag = np.mean(X_chunk_test.cpu().numpy(), axis=1)[:, 1]\n",
    "\n",
    "# Assuming reconstruction_errors is a NumPy array or a list of errors\n",
    "# If reconstruction_errors is a tensor, ensure to convert it with .cpu().numpy() as well\n",
    "last_errors = np.mean(reconstruction_errors[-len(X_chunk_test):], axis=1)\n",
    "\n",
    "print(\"Shape of avg_real:\", avg_real.shape)\n",
    "print(\"Shape of avg_imag:\", avg_imag.shape)\n",
    "print(\"Shape of last_errors:\", last_errors.shape)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_real, last_errors, label='Real Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Real Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_imag, last_errors, label='Imaginary Part', alpha=0.5)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Imaginary Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming `z_mean` and `z_log_var` are obtained from your model's encoder\n",
    "\n",
    "# Function to sample using standard VAE sampling method\n",
    "def sample_vae(z_mean, z_log_var):\n",
    "    std = torch.exp(0.5 * z_log_var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return z_mean + eps * std\n",
    "\n",
    "# Function to sample using your MEC-based method (_sampling3)\n",
    "def sample_mec(z_mean, device):\n",
    "    # Example of processing z_mean with MEC. You will replace this with your actual _sampling3 function\n",
    "    # This is a placeholder to illustrate the workflow\n",
    "    z_mean_transformed = z_mean  # Placeholder for actual transformation\n",
    "    eps = torch.randn_like(z_mean_transformed) * 0.1  # Example std deviation\n",
    "    return z_mean_transformed + eps\n",
    "\n",
    "# Assuming device is defined (e.g., \"cuda\" or \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "z_mean = z_mean.to(device)\n",
    "z_log_var = z_log_var.to(device)\n",
    "\n",
    "# Sampling\n",
    "z_sampled_vae = sample_vae(z_mean, z_log_var)\n",
    "z_sampled_mec = sample_mec(z_mean, device)\n",
    "\n",
    "# Plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def plot_distribution(tensor, label, color):\n",
    "    # Ensure tensor is on CPU and flatten it for histogramming\n",
    "    tensor = tensor.detach().cpu().numpy().flatten()\n",
    "    \n",
    "    # Histogram\n",
    "    plt.hist(tensor, bins=30, density=True, alpha=0.6, label=label, color=color)\n",
    "    \n",
    "    # KDE plot\n",
    "    kde = gaussian_kde(tensor)\n",
    "    kde_x = np.linspace(tensor.min(), tensor.max(), 500)\n",
    "    kde_y = kde.evaluate(kde_x)\n",
    "    plt.plot(kde_x, kde_y, color=color, alpha=0.7)\n",
    "\n",
    "# Visualization setup\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Call the plotting function for z_mean and sampled distributions\n",
    "plot_distribution(z_mean, \"z_mean distribution\", \"blue\")\n",
    "plot_distribution(z_sampled_vae, \"Sampled VAE z distribution\", \"red\")\n",
    "plot_distribution(z_sampled_mec, \"Sampled MEC z distribution\", \"green\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Variable Distributions Before and After Sampling')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeb3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def scatter_plot(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, label=label)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean is of shape (n_samples, n_latent_dims)\n",
    "# And you have z_sampled_vae and z_sampled_mec with the same shape\n",
    "# We'll take the first two dimensions for plotting\n",
    "z_mean_2d = z_mean[:, :2].detach().cpu().numpy()  # Take first two dimensions for 2D scatter plot\n",
    "z_sampled_vae_2d = z_sampled_vae[:, :2].detach().cpu().numpy()\n",
    "z_sampled_mec_2d = z_sampled_mec[:, :2].detach().cpu().numpy()\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_plot(latent_variables, labels, 'Latent Space 2D Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_plot(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Define distinct colors for visibility: red for z_mean, orange for Sampled VAE, and limegreen for Sampled MEC\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "    \n",
    "    # Plot each set of points with the new colors\n",
    "    for i, (label, color) in enumerate(zip(labels, colors)):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, label=label, color=color)\n",
    "\n",
    "    # Print the range of z_mean data points\n",
    "    print(f\"z_mean Latent Dimension 1 range: {latent_variables[:, 0, 0].min()} to {latent_variables[:, 0, 0].max()}\")\n",
    "    print(f\"z_mean Latent Dimension 2 range: {latent_variables[:, 0, 1].min()} to {latent_variables[:, 0, 1].max()}\")\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "\n",
    "    # Set the x and y axes limits\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_plot(latent_variables, labels, 'Latent Space 2D Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_subplots(latent_variables, labels, title):\n",
    "    # Set up a figure with three subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 8), sharey=True)\n",
    "    \n",
    "    # Define distinct colors for visibility\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points in its own subplot\n",
    "    for i, (ax, label, color) in enumerate(zip(axs, labels, colors)):\n",
    "        ax.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, color=color)\n",
    "        ax.set_title(f\"{label} Distribution\")\n",
    "        ax.grid(True)\n",
    "        # Set the same x and y limits for all subplots based on overall data\n",
    "        all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "        x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "        y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "        ax.set_xlim(x_min - 1, x_max + 1)\n",
    "        ax.set_ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.04, 'Latent Dimension 1', ha='center')\n",
    "    fig.text(0.04, 0.5, 'Latent Dimension 2', va='center', rotation='vertical')\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_subplots(latent_variables, labels, 'Separate Latent Space 2D Distributions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def scatter_dual_plots(latent_variables, labels, title):\n",
    "    # Set up a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 7), sharey=True)\n",
    "\n",
    "    # Define distinct colors for visibility: red for z_mean, green for Sampled MEC, and orange for Sampled VAE\n",
    "    colors = ['red', 'limegreen', 'orange']\n",
    "\n",
    "    # Scatter plot for z_mean and Sampled MEC\n",
    "    axs[0].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "    axs[0].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[2], s=90, label=labels[2])\n",
    "    axs[0].set_title(f\"{labels[0]} and {labels[2]} Distribution\")\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Scatter plot for z_mean and Sampled VAE\n",
    "    axs[1].scatter(latent_variables[:, 0, 0], latent_variables[:, 0, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "    axs[1].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[1], s=90, label=labels[1])\n",
    "    axs[1].set_title(f\"{labels[0]} and {labels[1]} Distribution\")\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    # Scatter plot for z_mean and Sampled VAE\n",
    "#     axs[1].scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[0], s=90, label=labels[0])\n",
    "#     axs[1].scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[1], s=90, label=labels[1])\n",
    "#     axs[1].set_title(f\"{labels[1]} and {labels[2]} Distribution\")\n",
    "#     axs[1].legend()\n",
    "#     axs[1].grid(True)\n",
    "\n",
    "    # Set the same x and y limits for all subplots based on overall data\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    for ax in axs:\n",
    "        ax.set_xlim(x_min - 1, x_max + 1)\n",
    "        ax.set_ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.04, 'Latent Dimension 1', ha='center')\n",
    "    fig.text(0.04, 0.5, 'Latent Dimension 2', va='center', rotation='vertical')\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    plt.show()\n",
    "def scatter_all_plots(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Define distinct colors for visibility: red for z_mean, orange for Sampled VAE, and limegreen for Sampled MEC\n",
    "    colors = ['red', 'orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points with the new colors\n",
    "    for i, (label, color) in enumerate(zip(labels, colors)):\n",
    "        plt.scatter(latent_variables[:, i, 0], latent_variables[:, i, 1], alpha=0.7, color=color, s=100, label=label)\n",
    "\n",
    "    # Set the x and y axes limits based on overall data\n",
    "    all_latent_vars = latent_variables.reshape(-1, latent_variables.shape[-1])\n",
    "    x_min, x_max = all_latent_vars[:, 0].min(), all_latent_vars[:, 0].max()\n",
    "    y_min, y_max = all_latent_vars[:, 1].min(), all_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "def scatter_vae_mec(latent_variables, labels, title):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Define colors for visibility: orange for Sampled VAE and limegreen for Sampled MEC\n",
    "    colors = ['orange', 'limegreen']\n",
    "\n",
    "    # Plot each set of points with the colors\n",
    "    plt.scatter(latent_variables[:, 1, 0], latent_variables[:, 1, 1], alpha=0.7, color=colors[0], s=80, label=labels[1])\n",
    "    plt.scatter(latent_variables[:, 2, 0], latent_variables[:, 2, 1], alpha=0.7, color=colors[1], s=80, label=labels[2])\n",
    "\n",
    "    # Set the x and y axes limits based on the plotted data\n",
    "    vae_mec_latent_vars = np.concatenate((latent_variables[:, 1], latent_variables[:, 2]), axis=0)\n",
    "    x_min, x_max = vae_mec_latent_vars[:, 0].min(), vae_mec_latent_vars[:, 0].max()\n",
    "    y_min, y_max = vae_mec_latent_vars[:, 1].min(), vae_mec_latent_vars[:, 1].max()\n",
    "    plt.xlim(x_min - 1, x_max + 1)\n",
    "    plt.ylim(y_min - 1, y_max + 1)\n",
    "\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "# Example usage:\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Combine them for plotting\n",
    "latent_variables = np.stack([z_mean_2d, z_sampled_vae_2d, z_sampled_mec_2d], axis=1)\n",
    "labels = ['z_mean', 'Sampled VAE', 'Sampled MEC']\n",
    "\n",
    "scatter_dual_plots(latent_variables, labels, 'Latent Space 2D Distributions')\n",
    "scatter_all_plots(latent_variables, labels, 'Combined Latent Space 2D Distribution')\n",
    "scatter_vae_mec(latent_variables, labels, 'Sampled VAE vs Sampled MEC Latent Space 2D Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b690ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# We'll assume z_mean, z_sampled_vae, and z_sampled_mec are tensors with at least 2 dimensions.\n",
    "# Convert PyTorch tensors to numpy arrays and then to a pandas DataFrame for Seaborn.\n",
    "z_mean_np = z_mean[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "z_sampled_vae_np = z_sampled_vae[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "z_sampled_mec_np = z_sampled_mec[:, :2].detach().cpu().numpy()  # Replace with your actual data\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Use Seaborn to plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df, x='Latent Dimension 1', y='Latent Dimension 2', hue='Type', alpha=0.7)\n",
    "plt.title('Latent Space 2D Distribution with Seaborn')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d759153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_size=150, \n",
    "                          context='talk', style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn'):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    scatter = sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                              hue=hue, s=marker_size, alpha=0.8)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "z_mean_np = z_mean[:, :2].detach().cpu().numpy()\n",
    "z_sampled_vae_np = z_sampled_vae[:, :2].detach().cpu().numpy()\n",
    "z_sampled_mec_np = z_sampled_mec[:, :2].detach().cpu().numpy()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np),\n",
    "    'Size': [120] * len(z_mean_np) + [100] * len(z_sampled_vae_np) + [200] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "# Call the function with the custom color palette\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Define default marker size if not provided\n",
    "    default_marker_size = 150\n",
    "\n",
    "    # Plot each category with its specified or default marker size\n",
    "    if marker_sizes_dict:\n",
    "        for category, msize in marker_sizes_dict.items():\n",
    "            subset = dataframe[dataframe[hue] == category]\n",
    "            sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                            hue=hue, s=msize, alpha=0.8, legend=False)\n",
    "    else:\n",
    "        sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        hue=hue, s=default_marker_size, alpha=0.8)\n",
    "\n",
    "    # Get current axis limits\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "\n",
    "    # Extend the x and y axes\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and have the correct shape\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "# Define custom marker sizes for each category\n",
    "custom_marker_sizes = {\n",
    "    'z_mean': 200,        # Bigger marker size for z_mean\n",
    "    'Sampled VAE': 150,   # Bigger marker size for Sampled VAE\n",
    "    'Sampled MEC': 100    # Bigger marker size for Sampled MEC\n",
    "}\n",
    "\n",
    "# Call the function with the custom color palette and custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_colors, marker_sizes_dict=custom_marker_sizes, extend_axis_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a53d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(14, 8), marker_sizes_dict=None,\n",
    "                          context='talk', style='whitegrid', palette=None,\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn',\n",
    "                          extend_axis_factor=2):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Define default marker size if not provided\n",
    "    default_marker_size = 150\n",
    "\n",
    "    # Check if a custom palette is provided, otherwise use Seaborn's default\n",
    "    if palette is None:\n",
    "        palette = sns.color_palette(\"husl\", len(dataframe[hue].unique()))\n",
    "\n",
    "    # Plot each category with its specified or default marker size\n",
    "    if marker_sizes_dict:\n",
    "        for category, msize in marker_sizes_dict.items():\n",
    "            subset = dataframe[dataframe[hue] == category]\n",
    "            sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                            hue=hue, s=msize, alpha=0.8, palette=palette, legend='full')\n",
    "    else:\n",
    "        sns.scatterplot(data=dataframe, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        hue=hue, s=default_marker_size, alpha=0.8, palette=palette, legend='full')\n",
    "\n",
    "    # Get current axis limits\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "\n",
    "    # Extend the x and y axes\n",
    "    plt.xlim(x_min * extend_axis_factor, x_max * extend_axis_factor)\n",
    "    plt.ylim(y_min * extend_axis_factor, y_max * extend_axis_factor)\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Place the legend outside the plot\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_colors = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Define custom marker sizes for each category\n",
    "custom_marker_sizes = {\n",
    "    'z_mean': 300,        # Bigger marker size for z_mean\n",
    "    'Sampled VAE': 200,   # Bigger marker size for Sampled VAE\n",
    "    'Sampled MEC': 200    # Bigger marker size for Sampled MEC\n",
    "}\n",
    "\n",
    "# Define a custom color palette\n",
    "custom_palette = {\n",
    "    'z_mean': \"#e74c3c\",  # Red color for z_mean\n",
    "    'Sampled VAE': \"#3498db\",  # Blue color for Sampled VAE\n",
    "    'Sampled MEC': \"#2ecc71\"   # Green color for Sampled MEC\n",
    "}\n",
    "\n",
    "# Call the function with the custom color palette and custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', palette=custom_palette, marker_sizes_dict=custom_marker_sizes, extend_axis_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6323cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def enhanced_scatter_plot(dataframe, hue, figsize=(12, 9), \n",
    "                          marker_sizes=None, context='talk', \n",
    "                          style='whitegrid', palette='colorblind',\n",
    "                          title='Enhanced Latent Space 2D Distribution with Seaborn'):\n",
    "    # Set the aesthetics\n",
    "    sns.set(style=style, context=context, palette=palette)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # If marker_sizes is not specified, default to 100 for all\n",
    "    if not marker_sizes:\n",
    "        marker_sizes = {category: 100 for category in dataframe[hue].unique()}\n",
    "    \n",
    "    # Plot each category with its own marker size\n",
    "    unique_categories = dataframe[hue].unique()\n",
    "    for category in unique_categories:\n",
    "        subset = dataframe[dataframe[hue] == category]\n",
    "        sns.scatterplot(data=subset, x='Latent Dimension 1', y='Latent Dimension 2', \n",
    "                        label=category, s=marker_sizes[category], alpha=0.8)\n",
    "\n",
    "    # Enhance the legend\n",
    "    plt.legend(title=hue, title_fontsize='13', fontsize='12')\n",
    "\n",
    "    # Set labels and title with a larger font size\n",
    "    plt.xlabel('Latent Dimension 1', fontsize=15)\n",
    "    plt.ylabel('Latent Dimension 2', fontsize=15)\n",
    "    plt.title(title, fontsize=18)\n",
    "\n",
    "    # Despine the top and right spines of the plot\n",
    "    sns.despine(trim=True)\n",
    "\n",
    "    # Finally, show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Define marker sizes for each category\n",
    "marker_sizes = {\n",
    "    'z_mean': 150,\n",
    "    'Sampled VAE': 100,\n",
    "    'Sampled MEC': 150\n",
    "}\n",
    "\n",
    "# Call the function with custom marker sizes\n",
    "enhanced_scatter_plot(df, hue='Type', marker_sizes=marker_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792200d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming z_mean, z_sampled_vae, and z_sampled_mec are already defined and converted to numpy arrays\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Latent Dimension 1': np.concatenate([z_mean_np[:, 0], z_sampled_vae_np[:, 0], z_sampled_mec_np[:, 0]]),\n",
    "    'Latent Dimension 2': np.concatenate([z_mean_np[:, 1], z_sampled_vae_np[:, 1], z_sampled_mec_np[:, 1]]),\n",
    "    'Type': ['z_mean'] * len(z_mean_np) + ['Sampled VAE'] * len(z_sampled_vae_np) + ['Sampled MEC'] * len(z_sampled_mec_np),\n",
    "    'Size': [120] * len(z_mean_np) + [100] * len(z_sampled_vae_np) + [120] * len(z_sampled_mec_np)\n",
    "})\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"colorblind\")\n",
    "\n",
    "# Create a FacetGrid object to control the size of each point individually\n",
    "g = sns.FacetGrid(df, hue=\"Type\", height=6, aspect=1.5, legend_out=True)\n",
    "\n",
    "# Use the 'Size' column to set the size of each point\n",
    "g = g.map(plt.scatter, \"Latent Dimension 1\", \"Latent Dimension 2\", \"Size\", edgecolor=\"w\", alpha=0.7)\n",
    "\n",
    "# Adjust the axis limits to add some padding around the points\n",
    "padding = 0.2\n",
    "x_min, x_max = df['Latent Dimension 1'].min(), df['Latent Dimension 1'].max()\n",
    "y_min, y_max = df['Latent Dimension 2'].min(), df['Latent Dimension 2'].max()\n",
    "plt.xlim(x_min - (x_max - x_min) * padding, x_max + (x_max - x_min) * padding)\n",
    "plt.ylim(y_min - (y_max - y_min) * padding, y_max + (y_max - y_min) * padding)\n",
    "\n",
    "# Add the legend and titles\n",
    "g.add_legend(title=\"Type\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Latent Space 2D Distribution with Seaborn')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3625",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.random.normal(size=z_mean.shape)\n",
    "z_sampled = z_mean + np.exp(0.5 * z_log_var) * eps\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot z_mean distribution\n",
    "sns.histplot(z_mean.detach().numpy().flatten(), color=\"blue\", kde=True, stat=\"density\", label=\"z_mean distribution\")\n",
    "\n",
    "# Plot sampled z distribution\n",
    "sns.histplot(z_sampled.detach().numpy().flatten(), color=\"red\", kde=True, stat=\"density\", alpha=0.6, label=\"Sampled z distribution\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Latent Variable Distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e87830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4235d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction error\n",
    "reconstruction_error_real = reconstruction_error[:, 0]\n",
    "reconstruction_error_imag = reconstruction_error[:, 1]\n",
    "\n",
    "# Plot for Real Part\n",
    "plt.figure(figsize=(14, 6))\n",
    "mellow_green = '#89C997' \n",
    "plt.plot(reconstruction_error_real, label='Reconstruction Error', color=mellow_green)\n",
    "plt.axhline(y=threshold2, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Intrusion Detected by Reconstruction Error',fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sequence Number (10)', fontsize=16, fontweight='bold')\n",
    "#plt.xlabel('Sequence Number(*1000)', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Reconstruction Error', fontsize=16, fontweight='bold')\n",
    "for label in (plt.gca().get_xticklabels() + plt.gca().get_yticklabels()):\n",
    "    label.set_fontsize(12)\n",
    "    label.set_fontweight('bold')\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "# plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "# plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "# plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "# plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "# plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "# plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "# plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad266e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_real_parts = reconstruction_error[:, 0]\n",
    "reconstruction_error_real_std = reconstruction_error[:, 1]\n",
    "reconstruction_error_real_skew = reconstruction_error[:, 2]\n",
    "reconstruction_error_real_kurtosis = reconstruction_error[:, 3]\n",
    "reconstruction_error_imag_parts = reconstruction_error[:, 4]\n",
    "reconstruction_error_imag_std = reconstruction_error[:, 5]\n",
    "reconstruction_error_imag_skew = reconstruction_error[:, 6]\n",
    "reconstruction_error_imag_kurtosis = reconstruction_error[:, 7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "# plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "# plt.plot(reconstructed_sample[:, 0], 'b--', label='Reconstructed Real Part')\n",
    "# plt.plot(original_sample[:, 1], 'm-', label='Original Real STD')\n",
    "# plt.plot(reconstructed_sample[:, 1], 'm--', label='Reconstructed Real STD')\n",
    "plt.plot(original_sample[:, 2], 'c-', label='Original Real Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'c--', label='Reconstructed Real Skew')\n",
    "plt.plot(original_sample[:, 3], 'orange', label='Original Real Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'orange', label='Reconstructed Real Kurtosis', linestyle='--')\n",
    "\n",
    "# plt.plot(original_sample[:, 4], 'g-', label='Original Imaginary Part')\n",
    "# plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "# plt.plot(original_sample[:, 5], 'purple', label='Original Imaginary STD')\n",
    "# plt.plot(reconstructed_sample[:, 5], 'purple', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.plot(original_sample[:, 6], 'brown', label='Original Imaginary Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'brown', label='Reconstructed Imaginary Skew', linestyle='--')\n",
    "plt.plot(original_sample[:, 7], 'pink', label='Original Imaginary Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'pink', label='Reconstructed Imaginary Kurtosis', linestyle='--')\n",
    "plt.title('Original vs Reconstructed IQ Data')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "# Place the legend outside the plot area\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), fontsize='small', title='Legend')\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the number of sequences to plot together\n",
    "n = 2  # Change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random starting sequence for plotting\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "\n",
    "# Extract and concatenate the original and reconstructed samples\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'orange', label='Original Real STD')\n",
    "plt.plot(reconstructed_sample[:, 1], 'orange', label='Reconstructed Real STD', linestyle='--')\n",
    "\n",
    "plt.plot(original_sample[:, 4], 'y-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 4], 'g--', label='Reconstructed Imaginary Part')\n",
    "plt.plot(original_sample[:, 5], 'pink', label='Original Imaginary STD')\n",
    "plt.plot(reconstructed_sample[:, 5], 'pink', label='Reconstructed Imaginary STD', linestyle='--')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 2], 'b-', label='Original Real Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 2], 'r--', label='Reconstructed Real Part Skew')\n",
    "plt.plot(original_sample[:, 6], 'g-', label='Original Imaginary Part Skew')\n",
    "plt.plot(reconstructed_sample[:, 6], 'y--', label='Reconstructed Imaginary Part Skew')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for n = 9\n",
    "n = 4  # Change this to desired number of sequences\n",
    "sequence_index = np.random.choice(len(X_chunk_test) - n + 1)\n",
    "original_sample = np.concatenate(X_chunk_test[sequence_index:sequence_index + n])\n",
    "reconstructed_sample = np.concatenate(X_chunk_pred[sequence_index:sequence_index + n])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 3], 'b-', label='Original Real Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 3], 'r--', label='Reconstructed Real Part Kurtosis')\n",
    "plt.plot(original_sample[:, 7], 'g-', label='Original Imaginary Part Kurtosis')\n",
    "plt.plot(reconstructed_sample[:, 7], 'y--', label='Reconstructed Imaginary Part Kurtosis')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "# plt.savefig('11-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671af7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
